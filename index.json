{"hugo":{"BuildDate":"2020-01-05T18:57:23Z","CommitHash":"83e50184","Environment":"production","Version":"0.62.2"},"pages":[{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"vehicle-borne_mobile_mapping","Dir":"blog/mapping/vehicle-borne_mobile_mapping/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/mapping/vehicle-borne_mobile_mapping/index.md","TranslationBaseName":"index","UniqueID":"eb5a6869b6b14b481070dff66885d4e1"},"FuzzyWordCount":100,"GitInfo":{"hash":"c64b2b4c9eb7dd64dab6656cc994bb70ebcdbfd6","abbreviatedHash":"c64b2b4","subject":"add mobile mapping page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-04-03T15:28:26+08:00","commitDate":"2020-04-03T15:28:26+08:00"},"Kind":"page","Lastmod":"2020-04-03T15:28:26+08:00","Len":3008,"Name":"车载移动测量系统","Permalink":"https://nuhuo08.github.io/vehicle-borne_mobile_mapping/","Plain":"武汉大学测绘学院陈长军老师的博士论文：车载移动测量系统集成关键技术研究， 详细介绍了高精度地图采集车中的多项关键技术，具有很高的参考意义。\n高精度地图需要转换到WGS-84世界系中，需要建立世界系下的控制点，参考大比例尺地形图测绘。\n组合定位定姿 GPS/IMU的解算方法，可参考GPS/INS组合导航。\n立体相机High-Resolution Stereo Camera (HRSC) 相对标定：在室内高精度控制场，范围633m，点位精度0.2mm，标定主点、等效焦距、畸变系数，得到单个相机的位置和姿态\n   绝对标定：室外控制场，确定立体相机与惯导之间的相对关系\n   激光扫描仪3D LiDAR Scanner 三维标定场：寻找同名点，转到惯导坐标系下\n   2D LiDAR Scanner 道路面数据：自定义坐标系\n全景影像与激光点云Panoramic Image \u0026amp; Laser Point Clouds 内标定：平面棋盘格标定法，参考针孔相机畸变校正。\n高精度配准：系统静止，LiDAR采用3D扫描模式？？进行\n   ","PublishDate":"2020-04-03T11:29:23+08:00","ReadingTime":1,"RelPermalink":"/vehicle-borne_mobile_mapping/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-04-03T15:18:57.377616138+08:00","Mode":436,"Name":"index.md","Size":1724},"Tags":null,"Title":"车载移动测量系统","Type":"blog","Weight":0,"WordCount":27},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"deep-learning","Dir":"blog/sdc-engineer/deep-learning/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/sdc-engineer/deep-learning/index.md","TranslationBaseName":"index","UniqueID":"f4913cf116a2de595e5563c2d4f8bcf5"},"FuzzyWordCount":100,"GitInfo":{"hash":"c64b2b4c9eb7dd64dab6656cc994bb70ebcdbfd6","abbreviatedHash":"c64b2b4","subject":"add mobile mapping page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-04-03T15:28:26+08:00","commitDate":"2020-04-03T15:28:26+08:00"},"Kind":"page","Lastmod":"2020-04-03T15:28:26+08:00","Len":205,"Name":"Deep Learning","Permalink":"https://nuhuo08.github.io/deep-learning/","Plain":"神经网络基本模块 交通标识符分类 行为克隆 语义分割 ","PublishDate":"2020-03-19T21:44:52+08:00","ReadingTime":1,"RelPermalink":"/deep-learning/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-19T21:47:41.028809906+08:00","Mode":436,"Name":"index.md","Size":179},"Tags":null,"Title":"Deep Learning","Type":"blog","Weight":0,"WordCount":4},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"opencv-image-processing","Dir":"blog/sdc-engineer/opencv-image-processing/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/sdc-engineer/opencv-image-processing/index.md","TranslationBaseName":"index","UniqueID":"c1b97561a8b8915fd59f1229aa228112"},"FuzzyWordCount":1500,"GitInfo":{"hash":"06cd9ed0f7b18a7d9308699ac04022bffc57a3ba","abbreviatedHash":"06cd9ed","subject":"add opencv image processing page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-17T21:21:19+08:00","commitDate":"2020-03-17T21:21:19+08:00"},"Kind":"page","Lastmod":"2020-03-17T21:21:19+08:00","Len":21013,"Name":"Opencv 图像处理","Permalink":"https://nuhuo08.github.io/opencv-image-processing/","Plain":"Finding Lane Lines #importing some useful packages import matplotlib.pyplot as plt import matplotlib.image as mpimg import numpy as np import cv2 %matplotlib inline 在原图像中找到车道线，需要进行5步操作：\n#reading in an image image = mpimg.imread(\u0026#39;test_images/solidWhiteRight.jpg\u0026#39;) # if you wanted to show a single color channel image called \u0026#39;gray\u0026#39;, # for example, call as plt.imshow(gray, cmap=\u0026#39;gray\u0026#39;) plt.imshow(image)     converted the images to grayscale.  cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # Or use BGR2GRAY if you read an image with cv2.imread()    In order to eliminate the efffect of random noise, Gaussian blur method is applied to the image. The image is a little blurry after the operation, but it's benificial for the next step.  cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)    Then, the canny algorithm is used for edge detection. Pixels with large gradients are likely to be lane lines as the color changes rapidly.  cv2.Canny(img, low_threshold, high_threshold)    Crop the Image. Lane lines are always right in front of the car, so only a small portion of the image needs to be processed.  #filling pixels inside the polygon defined by \u0026#34;vertices\u0026#34; with the fill color  cv2.fillPoly(mask, vertices, ignore_mask_color) #returning the image only where mask pixels are nonzero masked_image = cv2.bitwise_and(img, mask)    Hough transformation is really useful for line detection.  lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)    when the detected lines are overlayed on the original image, we can see that the lane lines are detected sucessfully.\ncv2.addWeighted(initial_img, α, img, β, γ)    Advanced Lane Finding 高级车道线检测需要在俯视图上进行，分为如下步骤：\n 图像校正\n Use color transforms and gradients to create a thresholded binary image.\n  I used a combination of color and gradient thresholds to generate a binary image.\nR and G channels are used as they are helpful to find yellow lane lines, which is quite common in the real world. When image is converted to HLS channel, white and yellow lane lines are quite distinctie, and the influence of shadows can be significantly reduced.\nSobel gradient and gradient direction thresholds are also used, since the gradients varies most along x axis, and the lane lines are often vertical to the car.\nHere are some examples of test images when converted to binary image. The lane lines are preserved while most useless information is filtered out.\n   Performed a perspective transform.  cv2.getPerspectiveTransform() function takes as inputs source (src) and destination (dst) points and is used to calculate perspective transform matrix. Note that source points are chosen along the straight lane line to form a rectangle.\ncv2.warpPerspective() function is used to rectify binary image.\nI chose the hardcode the source and destination points as follows:\n   Source Destination     570, 470 420, 1   722, 470 920, 1   1110, 720 920, 720   220, 720 420, 720    I verified that my perspective transform was working as expected by drawing the src and dst points onto a test image and its warped counterpart to verify that the lines appear parallel in the warped image.\n   Identified lane-line pixels and fit their positions with a polynomial.  I first take a histogram along all the columns of the images, and the two highest peaks in the histogram are treated as starting point of the lane lines.\n   Then I used sliding windows to find all the possbile pixels in lane lines, and fit my lane lines with a 2nd order polynomial kinda like this:\n   The position of lane lines shall not change much within seconds, so the polynomial derived from the previous image can be used as a starting point for the following image. Searching the lane lines along the previous polynomial can be much more efficient.\nCalculat the radius of curvature of the lane and the position of the vehicle with respect to center.  Firstly, we need to convert our calculation result from pixel world to real world.\nThen, we can derive the real distance and curvature of the lane lines with a pre-defined formular.\nI did this in the function curve_offset().\nPlotted back down onto the road such that the lane area is identified clearly.  draw_lane() function is used to plot lane area back down onto the road, while draw_text() function is used to visualize numerical estimation of lane curvature and vehicle position.\nHere is an example of my result on a test image:\n   Vehicle Detection and Tracking  Extract binned color, histograms of color, and Histogram of Oriented Gradients (HOG) features on a labeled training set of images. Normalize features and randomize a selection for training and testing. Train a Linear SVM classifier Implement a sliding-window technique and a HOG Sub-sampling technique. Then use the trained classifier to search for vehicles in images. Run the pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles. Estimate a bounding box for vehicles detected.  Data Visualization In order to distinguish vehicles from non-vehicles, we need to collect as many data sets as possible. Udacity has provided us 8792 images of vehicles and 8968 images of non-vehicles. Here are some examples:\n   Feature Extraction Since vehicles are significantly different with non-vehicles both in their shapes and colors, several kinds of features including binned color, histograms of color, and HOG are extracted from the datasets.\nBinned Color Features I used cv2.resize() function to resize the image from 6464 to 3232 to reduce the number of features. While others may resize the image to 16*16, I think it looks so blurry that even human can hardly recognize the vehicle. Here is an example of binned color features:\n   Histogram of Color Features Histogram of color is also a good way to represent the property of an image and can be easily implemented with the function np.histogram. Here is an example:\n   Histogram of Oriented Gradients (HOG) Features I grabbed the first images from each of the two classes and displayed them to get a feel for what the skimage.hog() output looks like. Here is an example using the YCrCb color space and HOG parameters of orientations=9, pixels_per_cell=(8, 8) and cells_per_block=(2, 2):\n   Train SVM Classifier Combine and Normalize Features I decided to extract all the features mentioned above and used np.concatenate() to combine them to a feature vector. As the magnitude of these features vary from each other, we should normalize the features and randomize a selection for training and testing.\nTrain and Test the Classifier I trained a linear SVM using the training dataset and achieve an accuracy of 99.94% with the testing dataset. Although other kernals like rbf may achieve even higher accuracy, it will cost much more time to train and to make prediction.\nThe classifier trained using rgb color space behaves very bad when there are shadows on the road, while YCrCb works much better under such challenging situations. Note that when an image is coverted to other color space, the range of values may change. So bins_range parameter should be taken care of when extracting histogram of color features.\nVehicle Detection in Image Sliding Window Search I decided to search the lower half of the image since vehicles shall never appear in the sky. And the further the vehicle, the smaller it looks like. So I also used 3 different scales of sliding window to search vehicles in the image.\nUltimately I searched on three scales using YCrCb 3-channel HOG features plus spatially binned color and histograms of color in the feature vector, which provided a nice result. Here are some example images:\n   HOG Sub-sampling Window Search Too much sliding windows can slow down the performance of the algorithm significantly. To improve the efficiency of the overall system, I decided to use the HOG sub-sampling window search method, which can speed up the image processing procedure and obtain as good result as the original sliding window. Here is the result:\n   Video Implementation Final video output My pipeline can perform reasonably well on the entire project video (somewhat wobbly or unstable bounding boxes are ok as long as you are identifying the vehicles most of the time with minimal false positives.)\nFilter for false positives and combining overlapping bounding boxes I recorded the positions of positive detections in each frame of the video. From the positive detections I created a heatmap and then thresholded that map to identify vehicle positions. I then used scipy.ndimage.measurements.label() to identify individual blobs in the heatmap. I then assumed each blob corresponded to a vehicle. I constructed bounding boxes to cover the area of each blob detected.\nHere's an example result showing the heatmap from one frame of video, the result of scipy.ndimage.measurements.label() and the bounding boxes then overlaid on the last frame of video:\n   ","PublishDate":"2020-03-17T10:47:50+08:00","ReadingTime":7,"RelPermalink":"/opencv-image-processing/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-17T21:19:27.73152814+08:00","Mode":436,"Name":"index.md","Size":11648},"Tags":null,"Title":"Opencv 图像处理","Type":"blog","Weight":0,"WordCount":1420},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"camera","Dir":"blog/sensors/self-calib/camera/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/sensors/self-calib/camera/index.md","TranslationBaseName":"index","UniqueID":"91c568391f6c056a02052f9539f0dcb7"},"FuzzyWordCount":200,"GitInfo":{"hash":"06cd9ed0f7b18a7d9308699ac04022bffc57a3ba","abbreviatedHash":"06cd9ed","subject":"add opencv image processing page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-17T21:21:19+08:00","commitDate":"2020-03-17T21:21:19+08:00"},"Kind":"page","Lastmod":"2020-03-17T21:21:19+08:00","Len":3084,"Name":"相机校正","Permalink":"https://nuhuo08.github.io/camera/","Plain":"针孔相机畸变校正 畸变模型 世界坐标到相机坐标：\n\\[ \\begin{bmatrix} x\\\\ y\\\\ z\\end{bmatrix} =R\\begin{bmatrix} X\\\\ Y\\\\ Z\\end{bmatrix}+t \\]\n相机坐标到归一化平面坐标：\n\\[ x'=x/z \\\\[2mm] y'=y/z \\\\[2mm] r^2 = x'^2 + y'^2 \\]\n畸变校正：\n\\[ x''=x'\\frac{1+k_1r^2+k_2r^4+k_3r^6}{1+k_4r^2+k_5r^4+k_6r^6}+2p_1x'y'+p_2(r^2+2x'^2) \\\\[2mm] y''=y'\\frac{1+k_1r^2+k_2r^4+k_3r^6}{1+k_4r^2+k_5r^4+k_6r^6}+p_1(r^2+2y'^2)+2p_2x'y' \\\\[2mm] \\]\n转化到像素坐标：\n\\[ u=f_x*x''+c_x \\\\[2mm] v=f_y*y''+c_y \\]\n校正方法 使用棋盘格进行图像校正：\n Find corners in chessboard  I used cv2.findChessboardCorners() to find all the corners, which are the feature points of these images for camera calibration. The pixel position of each of these corners is stored in imgpoints variable. Here is some examples:\n   Calculate distortion coefficients  The function cv2.calibrateCamera() is quite useful to calculate the camera distortion coefficients. All I need to do is to prepare objpoints variable to store object points, which are the same for all these images. After this operation, the curved lines are converted back to straight lines. Here is an exmaple to undistort a chessboard image:\n   Provide an example of a distortion-corrected image.  One of the test images is corrected using the distortion coefficients derived from the above chessboard calibration procedure. The difference between original image and corrected one is subtle, however, this is a very important step.\n   鱼眼相机畸变校正 畸变表 畸变模型 参考资料  Camera Calibration and 3D Reconstruction  ","PublishDate":"2020-03-16T21:24:47+08:00","ReadingTime":1,"RelPermalink":"/camera/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-17T18:08:06.486404485+08:00","Mode":436,"Name":"index.md","Size":2107},"Tags":null,"Title":"相机校正","Type":"blog","Weight":0,"WordCount":189},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"odometry","Dir":"blog/sensors/self-calib/odometry/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/sensors/self-calib/odometry/index.md","TranslationBaseName":"index","UniqueID":"9ac50fac0c7f86f3357a718ee7b4b690"},"FuzzyWordCount":100,"GitInfo":{"hash":"e2f8b338a4e79beba2034f4c65f8e02c98388c1b","abbreviatedHash":"e2f8b33","subject":"add odometry page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-16T16:27:06+08:00","commitDate":"2020-03-16T16:27:06+08:00"},"Kind":"page","Lastmod":"2020-03-16T16:27:06+08:00","Len":2641,"Name":"Odometry","Permalink":"https://nuhuo08.github.io/odometry/","Plain":"里程计定位方法 差速模型 \\[ ds=\\frac{s_L + s_R}{2} \\\\[2mm] d\\theta=\\frac{s_L - s_R}{L} \\]\n转弯半径模型 \\[ ds=\\frac{s_L + s_R}{2} \\\\[2mm] d\\theta=\\frac{ds}{R} \\]\n两种方法比较     差速模型 转弯半径模型     标定过程 简单 复杂   计算精度 角度分辨率低，容易跳变抖动 分辨率高   稳定性 打滑或撞到限位器时，效果很差 受影响相对较小    验证方法  运动已知距离，比较算法输出的距离与实际距离的差异 运动已知角度，如90°，360°等，比较算法输出的角度与实际角度的差异  标定方法 采集的数据：\n 逆时针三圈，保证开始与结束时候车辆的方向大致相同。 顺时针三圈，保证开始与结束时候车辆的方向大致相同。 沿直线运动一段距离，用皮尺测量长度。重复3次  物理距离标定  结合顺时针、逆时针的数据，可以得到左后轮、右后轮之间的物理距离比例 结合直线的数据，得到左后轮、右后轮对应的真实的物理距离  差速模型标定 以角度作为代价函数，保证顺时针、逆时针的数据得到的角度值约为\\(6\\pi\\)，从而估算高精度的左后轮、右后轮之间的距离\\(L\\)。\n转弯半径模型标定 当车辆沿直线行驶时，转弯半径为无穷大，此时的方向盘角度不一定为0°，需要记录此时的方向盘角度。\n标定场手工标定 每隔30°，标定转弯半径\n自相关方法自动标定  参数的形式\n 代价函数的构建\n 参数的估计方法\n  结合差速模型的自动标定  代价函数的构建  ","PublishDate":"2020-03-16T12:14:29+08:00","ReadingTime":1,"RelPermalink":"/odometry/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-16T16:26:16.893515575+08:00","Mode":436,"Name":"index.md","Size":2253},"Tags":null,"Title":"Odometry","Type":"blog","Weight":0,"WordCount":54},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"imu","Dir":"blog/sensors/self-calib/imu/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/sensors/self-calib/imu/index.md","TranslationBaseName":"index","UniqueID":"60a71c3122779edfdc9585a3d9136231"},"FuzzyWordCount":200,"GitInfo":{"hash":"c1c9087050d011e7653482fcc9f844e6b61d4fc3","abbreviatedHash":"c1c9087","subject":"add imu page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-15T22:29:04+08:00","commitDate":"2020-03-15T22:29:04+08:00"},"Kind":"page","Lastmod":"2020-03-15T22:29:04+08:00","Len":3546,"Name":"IMU标定与解算","Permalink":"https://nuhuo08.github.io/imu/","Plain":"误差种类 \\[ a^{B}=T^{a}K^{a}(a^{S}+b^{a}) \\\\[2mm] w^{B}=T^{g}K^{g}(w^{S}+b^{g}) \\]\n加速度和陀螺仪包含如下3种误差：\n 偏置\n 比例误差\n  \\[ K^{a}= \\begin{bmatrix} s^{a}_{x} \u0026 0\u00260 \\\\ 0 \u0026s^{a}_{x} \u00260 \\\\ 0\u0026 0\u0026s^{a}_{x} \\end{bmatrix} K^{g}= \\begin{bmatrix} s^{g}_{x} \u0026 0\u00260 \\\\ 0 \u0026s^{g}_{x} \u00260 \\\\ 0\u0026 0\u0026s^{g}_{x} \\end{bmatrix} \\]\n轴向误差  建立一个正交坐标轴，x轴与加速度计的x轴重合，y轴在加速度计的xy平面上。\n\\[ T^{a}=\\begin{bmatrix} 1 \u0026 -\\alpha_{yz} \u0026 \\alpha_{zy} \\\\ 0 \u0026 1 \u0026 -\\alpha_{zx} \\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n陀螺仪坐标轴与正交坐标轴之间的转换关系为：\n\\[ T^g=\\begin{bmatrix} 1 \u0026 -\\gamma_{yz} \u0026 \\gamma_{zy} \\\\ \\gamma_{xz} \u0026 1 \u0026 -\\gamma{zx} \\\\ \\gamma_{xy} \u0026 \\gamma_{yx} \u0026 1 \\end{bmatrix} \\]\n加速度校准 静态数据标记 计算方差大小，当方差小于某一阈值时，认为是静止状态。\n参数估计 当加速度计静止时，输出的观测值大小为9.81，由此可以构建：\n待估参数：\n\\[ \\theta^{acc}=[\\alpha_{yz},\\alpha_{zy},\\alpha_{zx},s^{a}_{x},s^{a}_{y},s^{a}_{z},b^{a}_{x},b^{a}_{y},b^{a}_{z}] \\]\n代价函数：\n\\[ L(\\theta^{acc})=\\sum_{k=1}^M(\\|g\\|^2-\\|T^aK^a(a^S+b^a)\\|^2)^2 \\]\n六面法 陀螺仪校准 偏置 Allen方差包括：\n 量化噪声 角度随机游走 零偏不稳定性 速度随机游走 速度爬升  通过Allan方差分析得到陀螺仪Bias的过程，一般要采集好几个小时的数据。如果仅需要零偏参数，则在初始放置的50s左右的时间就足够了。\n参数估计 IMU从静止状态，经过一定的平移旋转，到达一个新的静止状态。由此可以构建：\n待估参数：\n\\[ \\theta ^{gyro}=[\\gamma_{yz},\\gamma_{zy},\\gamma_{xz},\\gamma_{zx},\\gamma_{xy},\\gamma_{yx},s^{g}_{x},s^{g}_{y},s^{g}_{z}] \\]\n初始的加速度向量\\(u_{a,k-1}\\)，经过多个陀螺仪测量值\\(\\omega_i\\)旋转之后，采用龙格库塔积分， 计算得到旋转之后的加速度向量\\(u_{g,k}\\)。而真实的加速度向量为\\(u_{a,k}\\)。可知代价函数：\n\\[ L(\\theta ^{gyro})=\\sum^{M}_{k=2}\\|u_{a,k}-\\Psi[w^{S}_{i},u_{a,k-1}]\\|^{2} \\]\n龙格库塔积分 姿态解算方法 mahony互补滤波 EKF madgwick梯度下降法 参考资料  IMUCalibration-Gesture IMU误差模型与校准 Pixhawk之姿态解算篇  ","PublishDate":"2020-03-15T19:48:40+08:00","ReadingTime":1,"RelPermalink":"/imu/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-15T22:27:42.419457148+08:00","Mode":436,"Name":"index.md","Size":2660},"Tags":null,"Title":"IMU标定与解算","Type":"blog","Weight":0,"WordCount":127},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"move_base","Dir":"blog/ros/move_base/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/ros/move_base/index.md","TranslationBaseName":"index","UniqueID":"c60418cab437d3955a46fe1f169f9ff2"},"FuzzyWordCount":200,"GitInfo":{"hash":"bf7621240467f86da60feffc5bd1fe617e26440c","abbreviatedHash":"bf76212","subject":"add move_base page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-15T14:08:34+08:00","commitDate":"2020-03-15T14:08:34+08:00"},"Kind":"page","Lastmod":"2020-03-15T14:08:34+08:00","Len":2792,"Name":"move_base 模块","Permalink":"https://nuhuo08.github.io/move_base/","Plain":"整体模块     odometry source: 里程计用来提供高频率的概略初始位姿； sensor sources: 机器人或无人车中，包含大量可用于定位的传感器：相机、激光、毫米波雷达等； map_server: 用激光SLAM手段，如 LOAM、GMapping 建立高精度地图； amcl: 结合传感器与高精度地图，实现 蒙特卡洛定位。  规划和控制     Global Planner\n global_planner: 可用来取代过时的navfn。 使用A*或Dijkstra算法进行全局路径规划。 carrot_planner: 简单的测试算法。  Local Planner\n base_local_planner: 实现Dynamic Window Approach(DWA) and Trajectory Rollout两种算法。其中DWA算法被dwa_local_planner取代。 eband_local_planner: Implements the Elastic Band method on the SE2 manifold teb_local_planner: Implements the Timed-Elastic-Band method for online trajectory optimization mpc_local_planner: Provides several model predictive control approaches embedded in the SE2 manifold  Recovery Behavior\n clear_costmap_recovery: A recovery behavior that reverts the costmaps used by move_base to the static map outside of a user-specified range rotate_recovery: A recovery behavior that perfroms a 360 degree rotation of the robot to attempt to clear out space.   其他  Cost Map\n Robot Pose EKF\n  ","PublishDate":"2020-03-15T13:33:44+08:00","ReadingTime":1,"RelPermalink":"/move_base/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-15T14:06:56.167565655+08:00","Mode":436,"Name":"index.md","Size":2082},"Tags":null,"Title":"move_base 模块","Type":"blog","Weight":0,"WordCount":109},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"kd-tree","Dir":"blog/math/kd-tree/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/math/kd-tree/index.md","TranslationBaseName":"index","UniqueID":"a504c6c4a19b6bfec97decdffb389942"},"FuzzyWordCount":100,"GitInfo":{"hash":"d65a8b9ecf42a50ac7bc71ca4b7e437fd16f78ba","abbreviatedHash":"d65a8b9","subject":"add kd-tree page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-13T12:16:32+08:00","commitDate":"2020-03-13T12:16:32+08:00"},"Kind":"page","Lastmod":"2020-03-13T12:16:32+08:00","Len":2001,"Name":"Kd Tree","Permalink":"https://nuhuo08.github.io/kd-tree/","Plain":"建立KD-Tree  选取方差最大的特征作为分割特征； 选择该特征的中位数作为分割点； 将数据集中该特征小于中位数的传递给根节点的左节点，大于中位数的传递给根节点的右节点； 递归执行步骤1-3，直到所有数据都被建立到KD Tree的节点上为止。     查找元素  从根节点开始，根据目标在分割特征中是否小于或大于当前节点，向左或向右移动； 一旦算法到达叶节点，它就将节点点保存为“当前最佳”； 回溯，即从叶节点再返回到根节点； 如果当前节点比当前最佳节点更接近，那么它就成为当前最好的； 如果目标距离当前节点的父节点所在的将数据集分割为两份的超平面的距离更接近，说明当前节点的兄弟节点所在的子树有可能包含更近的点。 因此需要对这个兄弟节点递归执行1-4步。  使用范例 AMCL 定位中，会使用大量的粒子描述状态的统计信息。为了防止最优粒子频繁切换带来的定位结果抖动，需要对粒子进行分组。 将临近的粒子分为一组，就需要使用KD-Tree进行查找。请参考 粒子聚类。\n建立KD-Tree时，不一定要选择方差最大的特征作为分割特征，也不一定要选择该特征的中位数作为分割点。 进行这两个步骤的统计可能会消耗大量的计算，因此实际实现中，也可以随机选择某个数作为分割点。\n","PublishDate":"2020-03-13T11:53:57+08:00","ReadingTime":1,"RelPermalink":"/kd-tree/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-13T12:09:26.799011346+08:00","Mode":436,"Name":"index.md","Size":1694},"Tags":null,"Title":"Kd Tree","Type":"blog","Weight":0,"WordCount":20},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"ransac","Dir":"blog/math/ransac/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/math/ransac/index.md","TranslationBaseName":"index","UniqueID":"78556dff12e5ccb029780d362fa93874"},"FuzzyWordCount":100,"GitInfo":{"hash":"e6e757eaf6d88080e5fb7ba45443211d89bfa621","abbreviatedHash":"e6e757e","subject":"add 2-points ransac content for msckf","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-15T11:55:22+08:00","commitDate":"2020-03-15T11:55:22+08:00"},"Kind":"page","Lastmod":"2020-03-15T11:55:22+08:00","Len":2482,"Name":"RANSAC","Permalink":"https://nuhuo08.github.io/ransac/","Plain":"在MSCKF的前端跟踪中，会使用RANSAC方法估计最优的平移量，可参考 MSCKF前端跟踪。\n算法基本思想和流程 RANSAC是通过反复选择数据集去估计出模型，一直迭代到估计出认为比较好的模型。\n具体的实现步骤可以分为以下几步：\n 选择出可以估计出模型的最小数据集；(对于直线拟合来说就是两个点，对于计算Homography矩阵就是4个点) 使用这个数据集来计算出数据模型； 将所有数据带入这个模型，计算出“内点”的数目；(累加在一定误差范围内的适合当前迭代推出模型的数据) 比较当前模型和之前推出的最好的模型的“内点“的数量，记录最大“内点”数的模型参数和“内点”数； 重复1-4步，直到迭代结束或者当前模型已经足够好了(“内点数目大于一定数量”)。  算法输入  判断样本是否满足模型的误差容忍度t。t可以看作为对内点噪声均方差的假设，对于不同的输入数据需采用人工干预的方式预设合适的门限，且该参数对RANSAC性能有很大的影响； 随机抽取样本集S的次数。该参数直接影响余集SC中样本参与模型参数的检验次数，从而影响算法的效率，因为大部分随机抽样都受到外点的影响； 表征得到正确模型时，一致集S*的大小N。为了确保得到表征数据集P的正确模型，一般要求一致集足够大；另外，足够多的一致样本使得重新估计的模型参数更精确。 算法的迭代次数k。 适应于数据的模型model。 随机在样本抽样的数目n。  迭代次数推导    例子    ","PublishDate":"2020-03-10T22:37:33+08:00","ReadingTime":1,"RelPermalink":"/ransac/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-15T11:46:29.43889816+08:00","Mode":436,"Name":"index.md","Size":1983},"Tags":null,"Title":"RANSAC","Type":"blog","Weight":0,"WordCount":19},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"large_scale_mapping","Dir":"blog/mapping/large_scale_mapping/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/mapping/large_scale_mapping/index.md","TranslationBaseName":"index","UniqueID":"c6711105974eb1f587a6ad7dde8289ad"},"FuzzyWordCount":100,"GitInfo":{"hash":"423ec00a24a33f4122dfe0a62f9b8743dbfd6c8d","abbreviatedHash":"423ec00","subject":"add large-scale-mapping page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-07T15:50:20+08:00","commitDate":"2020-03-07T15:50:20+08:00"},"Kind":"page","Lastmod":"2020-03-07T15:50:20+08:00","Len":10380,"Name":"大比例尺地形图测绘","Permalink":"https://nuhuo08.github.io/large_scale_mapping/","Plain":"平面控制测量 首级平面控制（静态）： 采用GPS静态测量技术，通过联测武汉IGS站，并已知武汉站的CGCS2000的空间三维坐标，就可以得到5个框架点在CGCS2000椭球下的三维坐标。 之所以一个已知点就可以完成转换，是因为CGCS2000和WGS-84椭球差异很小，可以认为只有一个微小量的平移。\n将框架网和全面网联合平差，将上一步得到的5个框架网坐标作为已知点，平差便可以得到15个全面网点在CGCS2000椭球下的三维坐标。 当然，三维坐标通过高斯投影，很方便的就得到了所有点的CGCS2000系统下的平面坐标。\n图根平面控制（GPS RTK）： 采用GPS RTK测量技术，基准站架好了以后，首先要进行点校正。 在三个已知上进行约一分钟的观测，就可以通过相对定位得到3个已知点的WGS-84坐标。 而3个已知点在CGCS2000系统下的平面坐标和大地高已知，于是通过点校正就可以将坐标系统转换到CGCS2000系统下。 这样，接下来进行的图根点坐标便是CGCS2000坐标系统下的了。\n需要注意的事项和遇到的问题：\n 选控制点。点位的选择要能够均匀的分布于整个测区，略有偏重的在自己测区中稍微多布设些控制点，并且需要便于调度方案的设计。 选点的时候，应该分成5个小组，并且人员相互混合后去选点。这样又能够提高效率，又能够保证每个组都有成员知道控制点在哪个地方。\n 网形的设计。GPS网形设计中，最重要的便是“短边必测”。 设计不当，导致网的强度不够好，就可能导致最终的数据处理难以进行，容易超限。 并且可能需要进行跟多的时段观测，浪费人力物力。采用“翻滚式”调度方案，比较适合本队的点位分布，也能够保证网形的强度。\n 各组间的约定。如果某一控制点第一次被观测，可以根据实际情况选择更好的点位。 若更换了控制点点位，一定要在新的点位边进行注明。而其它组找点的时候，若该点不是第一次观测，一定要找到有其它组进行标注过的点位。 否则一旦点位错位，就需要重新进行观测。\n 配置集的设定。由于错误的将配置集设置为了“最大精度”，导致最终的数据无法用TGO导出来。 结果只好采用TEQC对数据进行提取，再通过LGO对数据文件进行分割。花费了大量的人力物力，不过好在成功的解决了问题。这也是这次实习过程中的一大收获吧。\n GPS控制网的平差。主要包括基线处理、网平差、与武汉IGS站联合平差。 这些过程在以前实习中都有接触，但是武汉IGS站的文件的预处理是一个新的知识点。 并且在这次实习中，遇到了TGO无法使用的情况，所以只好使用南方的GPS网平差软件进行结算。不过南方软件可更改的参数并不多，使用起来比较简单。\n 点校正。通过GPS网平差，可以得到GPS网点的CGCS2000下的平面坐标。 通过重新对其中任意三个点进行观测，得到其WGS-84下的坐标，就可以通过点校正，建立图根点的WGS-84坐标和CGCS2000坐标之间的转换关系， 由此可以方便的进行图根点测量，得到的图根点坐标为CGCS2000下的坐标。\n 做事要有始有终，谨慎再谨慎。在点校正完成以后，需要在一个一直点上进行检核，在测量完成之后，一定要进行复查。\n 选图根点。图根点的选择以保证能够完成测区数字测图任务为前提进行。 图根点可适量多选，因为GPS测量图根点十分方便，一个点只需要几分钟。 倘若到真正测量数字地形图时，发现图根点不够，需要进行支导线时，就会麻烦很多。\n  高程控制测量 首级高程控制（二等水准测量）： 水准测量的两个重要指标——测段往返较差、环闭合差不能超限。水准点至少要选择6个与GPS控制点重合。 进行精密水准的目的，就是测量出GPS平面控制点的正常高。\n图根高程控制： 平面控制点的大地高已知后，通过高程拟合（一般为多项式拟合）便可以得到整片区域的高程异常。 这样就可以得到所有图根点的正常高。为数字地形测量提供了稳固的基础。\n需要注意的事项和遇到的问题：\n i角检验。根据实习任务数要求，每个组员都要进行一次i角检验。 如果只是每天进行一次，就没法满足这个要求。所以做事不单要有始有终，还要细心仔细，看清要求。 I角检验由于形势固定不变，为了提高效率，可以在地面上做好记号，以后的每一次检验都可以不用重新拉线。\n 水准点的选择。水准点至少要选择6个与GPS控制点重合。这样才能够比较好的进行高程拟合，求得图根点的正常高。为数字地形图测绘做准备。\n 过渡点的选择。过渡点的是必须要有的，否则一旦出错，就要重新测量整个闭合环。 但是过渡点也不是越多越好，因为需要偶数站上过渡点，多了以后需要刻意的调节测站长度，丧失了灵活性。 一般在地面状况较好时，可以少用过渡点，而有较大高差或者地面状况较差时，则应增加过渡点。这样出错以后，返测可以减少工作量。\n 过渡点的输入。第一次进行精密水准测量，总是忘记在过渡点上先“在过渡点结束”观测，然后重新进行测量。 所以在最后的数据处理时候，一旦出错，就需要通过复杂的查找，才能够确定过渡点所在的地方，才能够找到错误出现的测段。\n 水准测量中的技巧。往测时需要记录手簿。只要保证记录数据时进行了回报确认以后，仪器不提示超限，那么就不需要一直等记录人员计算结束，这样可以提高效率。 并且，由于往测返测需要在同一路线上进行。所以往测时可以用粉笔或者砖头等在地面上做记号，避免返测时重新拉尺，减轻工作量。\n 水准数据的编辑。由于大多数组都忘记在过渡点上停止观测，导致需要人工进行数据的编辑。 通过阅读COSALEVEL的水准文件格式说明，就可以按照“起点、终点、距离、高差、测段数”这个格式对文件进行人工提取、编辑。\n 水准网平差。水准网平差采用COSALEVEL进行，操作过程十分简单， 但是需要注意的是剔除往返测较差超限的测段、并且对环闭合差超限的闭合环进行仔细地分析，剔除有问题的测段并重新进行平差，直到结果符合规范要求。\n  数字地形图测绘 碎部测量（全站仪）： 数字地形测量使用全站仪进行，只要在测站上输入正确的坐标，后定向成功，便可以进行测量了。\n数字成图（南方CASS9.0）：绘制出地物图和地貌图。\n需要注意的事项和遇到的问题：\n 数字地形测量。地物测量时，只需要抓住特征点，比如房屋3个角点、道路两端和弯曲变化处等。 而进行地貌测量时，很重要的一点就是跑尺人的灵动性。 在什么地方仪器视线不会被遮挡；怎样跑能够以最少的时间、最高的效率完成可视区域的测量；什么时候搬站、搬到哪里去等等问题，都需要跑尺人的经验。\n 后视和检核。通过两个已知点，可以得到其方位角，然后通过后视角度测量，就得到全站仪零方向和真北之间的关系。 这样，通过三角高程测量出来的点的平面坐标和高程就是在同一个平面坐标系统下的。为了保证没有定向错误，一定要对另一个已知点进行测量以检查是否出现错误。\n 支导线点的坐标，就是通过三角高程得到的，跟碎部点是一样的。 只是为了提高精度，多进行几次观测而已。然后在支导线点上，就可以像图根点一样进行测量。但是支导线不能够支出去太多，否则精度会严重下降。\n 测图人必须注意的是，自己提交的成果肯定要是一张完整的250250的地形图，所以不能够以只完成自己测区任务为目的，必要时候还是要像四周扩充以到达250250.\n CASS画地物图地貌图并没有太大难度，虽然已经不太熟悉，耐心、仔细的工作还是能够完成一幅较好的图。\n  空间数据建库与三维建模 空间数据建库（ArcGIS）：建立空间数据建库，由高程点、等高线矢量数据建立DEM。\n三维建模(3DMAX或sketchup)：利用三维建模工具（3DMAX、sketchup等）进行三维建模，并结合ArcGIS来制作三维景观图。\n需要注意的事项和遇到的问题：\n 使用Photoshop将倾斜的照片拉正是一个繁琐的过程，尤其是对圆形建筑，更是复杂非常。 这个过程没有太大技巧，就是需要时间、精力慢慢的将图像拉正、美化。\n 将CASS地物图导入ARCGIS时，特别需要注意的一点——不能够有汉字。有汉字就无法成功导入。 导入后对有用字段进行编辑，无用字段则删除，然后为建筑物添加一个“HEIGHT”字段，为其附上高程。\n 在SKETCHUP中对三维实体进行编辑。为了使三维模型更加真实，需要对三维模型进行进一步的修缮。比如增加房檐、梁柱等工作。 完成以后就可以将拉正的照片作为纹理，贴到三维模型上面去。\n  ","PublishDate":"2020-03-07T10:36:27+08:00","ReadingTime":1,"RelPermalink":"/large_scale_mapping/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-07T15:49:08.381545582+08:00","Mode":436,"Name":"index.md","Size":9748},"Tags":null,"Title":"大比例尺地形图测绘","Type":"blog","Weight":0,"WordCount":81},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"control","Dir":"blog/sdc-engineer/control/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/sdc-engineer/control/index.md","TranslationBaseName":"index","UniqueID":"0cdbbb28b5ebf3b8dc28c8049adb4f84"},"FuzzyWordCount":1600,"GitInfo":{"hash":"3f67c5273a4956e1eb1206d636fdb5c36591c2b1","abbreviatedHash":"3f67c52","subject":"add control page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-02-13T00:00:22+08:00","commitDate":"2020-02-13T00:00:22+08:00"},"Kind":"page","Lastmod":"2020-02-13T00:00:22+08:00","Len":31028,"Name":"Control","Permalink":"https://nuhuo08.github.io/control/","Plain":"PID PID原理 P Controller：将控制参数设置成误差的比例，快速接近目标，但是会造成震荡。\nsteering = -tau * crosstrack_error PD Controller：将误差的变化率也考虑进来。当误差变小的同时，误差的变化率也在不断变小。 两者之和将会更小，从而使控制器做出更微小的调节，防止出现控制过头，引发震荡。\nsteering = -tau_p * CTE - tau_d * diff_CTE where: differential crosstrack error (diff_CTE) is given by CTE(t) - CTE(t-1) PID Controller：当存在系统误差时，可以通过误差积分可以反映出来。\nsteering = -tau_p * CTE - tau_d * diff_CTE - tau_i * int_CTE where: the integrated crosstrack error (int_CTE) is the sum of all the previous crosstrack errors. This term works to cancel out steering drift. Twiddle Algorithm Twiddle算法提供了一套非常好的参数估计方法。当代价函数与待估参数之间没有严格的数学关系，通过twiddle算法可以高校估算出结果。\n其思想是：对每个参数，在其附近上下调节。 若调节的方向正确，使得代价函数减小，就加大调节步长；若上下调节都无法使代价函数减小，则缩小调节步长。 直至调节步长缩小到满足阈值，认为优化结束。\n# Choose an initialization parameter vector p = [0, 0, 0] # Define potential changes dp = [1, 1, 1] # Calculate the error best_err = A(p) threshold = 0.001 while sum(dp) \u0026gt; threshold: for i in range(len(p)): p[i] += dp[i] err = A(p) if err \u0026lt; best_err: # There was some improvement best_err = err dp[i] *= 1.1 else: # There was no improvement p[i] -= 2*dp[i] # Go into the other direction err = A(p) if err \u0026lt; best_err: # There was an improvement best_err = err dp[i] *= 1.05 else # There was no improvement p[i] += dp[i] # As there was no improvement, the step size in either # direction, the step size might simply be too big. dp[i] *= 0.95 MPC Kinematic Model 对自车进行位姿预测时，由于已知方向盘、油门刹车的输入\\(\\)，可以使用动态模型进行预测：\n\\[ \\begin{aligned} x_{t+1}\u0026=x_t+v_t\\cos(\\psi_t)*dt \\\\[2mm] y_{t+1}\u0026=y_t+v_t\\sin(\\psi_t)*dt \\\\[2mm] \\psi_{t+1}\u0026=\\psi_t+\\frac{v_t}{L_f}\\delta*dt \\\\[2mm] v_{t+1}\u0026=v_t+a_t*dt \\end{aligned} \\]\n\\(\\begin{bmatrix} x, y, \\psi, v \\end{bmatrix}\\) is the state of the vehicle, \\(L_f\\) is a physical characteristic of the vehicle, and \\(\\begin{bmatrix} \\delta, a \\end{bmatrix}\\) are the actuators, or control inputs, to our system.\nwe add a multiplicative factor of the steering angle, \\(\\delta\\) to \\(\\psi\\). \\(L_f\\) measures the distance between the center of mass of the vehicle and it's front axle. The larger the vehicle, the slower the turn rate.\nIf you've driven a vehicle you're well aware at higher speeds you turn quicker than at lower speeds. This is why \\(v\\) is the included in the update.\nErrors We can capture how the errors we are interested in change over time by deriving our kinematic model around these errors as our new state vector. The new state is \\( \\begin{pmatrix} x, y, \\psi, v, cte, e\\psi \\end{pmatrix}\\).\n\\[ \\begin{aligned} cte_{t+1}\u0026=f(x_t)-y_t+(v_t*\\sin(e\\psi_t)*dt) \\\\[2mm] e\\psi_{t+1}\u0026=\\psi_t-\\psi des_t + (\\frac{v_t}{L_f}*\\delta t*dt) \\end{aligned} \\]\n   double cost = 0; for (int t = 0; t \u0026lt; N; ++t) { cost += pow(cte[t], 2); cost += pow(epsi[t], 2); }  还可以添加很多其他误差项。例如方向盘、油门刹车的变化不能太剧烈：\nfor (int t = 0; t \u0026lt; N-1; ++t) { cost += pow(delta[t], 2); } for (int t = 0; t \u0026lt; N-1; ++t) { cost += pow(delta[t+1] - delta[t], 2); cost += pow(a[t+1] - a[t], 2); }  Dynamic Model Dynamic Model 精度更高，但是需要考虑各种力学模型，建模也比Kinematic Model 更为复杂。 A dynamic model considers: tire forces, longitudinal and lateral forces, gravity, air resistance, drag.\nWhat we have learned so far From the previous lessons we have learned to apply the bicycle model, polynomial fitting, low complexity heuristics (e.g. CTE), and short time steps, to enable vehicles to follow a complex (polynomial) trajectories. This is an effective, practical, and commonly used approach, which can be applied to many autonomous vehicle scenarios, in real time.\nComing Next For the next few lessons we will round out our discussion of vehicle models with an overview of the more comprehensive, but less practical, dynamic models. Dynamic models and the elements which comprise them are rigorous and could be modules or courses unto themselves. The content that follows is targeted developing awareness and intuition that can be applied to further study and consists of:\n Dynamic Model Forces Tire Slip Angle Tire Slip Ratio Tire Models  Additional resources are linked to each lesson to encourage and enable more in depth study. One of these resources makes a good case for the use of lower complexity kinematic models, as:\nCompared to higher fidelity vehicle models, the system identification on the kinematic bicycle model is easier because there are only two parameters to identify, lf and lr. This makes it simpler to port the same controller or path planner to other vehicles with differently sized wheelbases.\nTo further expand on this, lower complexity models have two strong advantages over higher complexity (dynamic included) models. They can run in real time (essential requirement of any model operating in a vehicle) and they are transferable to vehicles with differing attributes, such as mass. To use a dynamic model engineers would have to be able to control the vehicle attributes of the vehicles they are deploying models into (they probably won't have control over this). High complexity models would need major re-adjustment to account for even small differences. Lower complexity models do not suffer from this constraint and so can be placed in a wider range of vehicles, with far less additional effort, and unpredictability.\nAnother frequently asked question is where our model comes from and why it differs from other models seen in the program and from other sources.\nThe kinematic model we derive and use here is not quite the same as in the Berkeley paper (linked above), although they are similar. It is possible to use different models in different parts of your pipeline, depending on what levels of accuracy you need in different places. It is common to see this in industry. The principles of model we present can be applied to add parameters into the model to make models fit to purpose.\nAdditional Reading\n Pacejka Tire Model This paper presents a comparison between a kinematic and dynamic model. A brief overview of essential topics in vehicle dynamics Drew Gray's dissertation thesis This contains an excellent review, additional resources, and novel approaches/findings. An excellent book This is not a free resource but is highly recommended by domain experts.  MPC原理    约束条件 约束条件即为运动学方程，转换成等式，上下界都为0。对应的代码：\nsize_t n_constraints = 6 * N; Dvector constraints_lowerbound(n_constraints); Dvector constraints_upperbound(n_constraints); for (i = 0; i \u0026lt; n_constraints; i++) { constraints_lowerbound[i] = 0; constraints_upperbound[i] = 0; } constraints_lowerbound[x_start] = constraints_upperbound[x_start] = state[0]; constraints_lowerbound[y_start] = constraints_upperbound[y_start] = state[1]; constraints_lowerbound[psi_start] = constraints_upperbound[psi_start] = state[2]; constraints_lowerbound[v_start] = constraints_upperbound[v_start] = state[3]; constraints_lowerbound[cte_start] = constraints_upperbound[cte_start] = state[4]; constraints_lowerbound[epsi_start] = constraints_upperbound[epsi_start] = state[5];  待估变量 变量包括： \\([x,y,\\psi,v,cte,e\\psi]\\)，外加N个时刻的\\([\\delta, a]\\)。对应的代码：\nsize_t n_vars = 6 * N + 2 * (N - 1); Dvector vars(n_vars); for (i = 0; i \u0026lt; n_vars; i++) { vars[i] = 0; } for (i = delta_start; i \u0026lt; a_start; i++) { vars_lowerbound[i] = -0.436332; vars_upperbound[i] = 0.436332; } for (i = a_start; i \u0026lt; n_vars; i++) { vars_lowerbound[i] = -1.0; vars_upperbound[i] = 1.0; }  残差 残差为：\n// The part of the cost based on the reference state. for (size_t t = 0; t \u0026lt; N; t++) { fg[0] += 1000 * CppAD::pow(vars[cte_start + t], 2); fg[0] += 1000 * CppAD::pow(vars[epsi_start + t], 2); fg[0] += CppAD::pow(vars[v_start + t] - ref_v, 2); } // Minimize the use of actuators. for (size_t t = 0; t \u0026lt; N - 1; t++) { fg[0] += CppAD::pow(vars[delta_start + t], 2); fg[0] += CppAD::pow(vars[a_start + t], 2); } // Minimize the value gap between sequential actuations. for (size_t t = 0; t \u0026lt; N - 2; t++) { fg[0] += 500 * CppAD::pow(vars[delta_start + t + 1] - vars[delta_start + t], 2); fg[0] += 500 * CppAD::pow(vars[a_start + t + 1] - vars[a_start + t], 2); }  动力学方程 运动学方程，构建了各个变量之间的数学关系。\n// Initialize the model to the initial state fg[1 + x_start] = vars[x_start]; fg[1 + y_start] = vars[y_start]; fg[1 + psi_start] = vars[psi_start]; fg[1 + v_start] = vars[v_start]; fg[1 + cte_start] = vars[cte_start]; fg[1 + epsi_start] = vars[epsi_start]; for (size_t t = 1; t \u0026lt; N; t++) { // The state at time t+1 .  AD\u0026lt;double\u0026gt; x1 = vars[x_start + t]; AD\u0026lt;double\u0026gt; y1 = vars[y_start + t]; AD\u0026lt;double\u0026gt; psi1 = vars[psi_start + t]; AD\u0026lt;double\u0026gt; v1 = vars[v_start + t]; AD\u0026lt;double\u0026gt; cte1 = vars[cte_start + t]; AD\u0026lt;double\u0026gt; epsi1 = vars[epsi_start + t]; // The state at time t.  AD\u0026lt;double\u0026gt; x0 = vars[x_start + t - 1]; AD\u0026lt;double\u0026gt; y0 = vars[y_start + t - 1]; AD\u0026lt;double\u0026gt; psi0 = vars[psi_start + t - 1]; AD\u0026lt;double\u0026gt; v0 = vars[v_start + t - 1]; AD\u0026lt;double\u0026gt; cte0 = vars[cte_start + t - 1]; AD\u0026lt;double\u0026gt; epsi0 = vars[epsi_start + t - 1]; // Only consider the actuation at time t.  AD\u0026lt;double\u0026gt; delta0 = vars[delta_start + t - 1]; AD\u0026lt;double\u0026gt; a0 = vars[a_start + t - 1]; AD\u0026lt;double\u0026gt; f0 = coeffs[0] + coeffs[1]*x0 + coeffs[2]*x0*x0 + coeffs[3]*x0*x0*x0; AD\u0026lt;double\u0026gt; psides0 = CppAD::atan(3*coeffs[3]*x0*x0 + 2*coeffs[2]*x0 + coeffs[1]); /* AD\u0026lt;double\u0026gt; f0 = coeffs[0] + coeffs[1] * x0; */ /* AD\u0026lt;double\u0026gt; psides0 = CppAD::atan(coeffs[1]); */ // Here\u0026#39;s `x` to get you started.  // The idea here is to constraint this value to be 0.  fg[1 + x_start + t] = x1 - (x0 + v0 * CppAD::cos(psi0) * dt); fg[1 + y_start + t] = y1 - (y0 + v0 * CppAD::sin(psi0) * dt); fg[1 + psi_start + t] = psi1 - (psi0 - v0 * delta0 / Lf * dt); fg[1 + v_start + t] = v1 - (v0 + a0 * dt); fg[1 + cte_start + t] = cte1 - ((f0 - y0) + (v0 * CppAD::sin(epsi0) * dt)); fg[1 + epsi_start + t] = epsi1 - ((psi0 - psides0) - v0 * delta0 / Lf * dt); }  优化器 Ipopt (Interior Point OPTimizer, pronounced eye-pea-Opt) is a software package for large-scale nonlinear optimization. It is designed to find (local) solutions of mathematical optimization problems. Ipopt is the tool we'll be using to optimize the control inputs.\nCppAD (C++ Algorithmic Differentiation Package) is a library we'll use for automatic differentiation. By using CppAD we don't have to manually compute derivatives, which is tedious and prone to error.\n","PublishDate":"2020-02-12T20:11:58+08:00","ReadingTime":8,"RelPermalink":"/control/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-12T23:49:49.780373617+08:00","Mode":436,"Name":"index.md","Size":11981},"Tags":null,"Title":"Control","Type":"blog","Weight":0,"WordCount":1575},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"rotation","Dir":"blog/math/rotation/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/math/rotation/index.md","TranslationBaseName":"index","UniqueID":"43909b900be4530fcb6e8853b56e9467"},"FuzzyWordCount":500,"GitInfo":{"hash":"a44513a073c4ee2eab1c5884736df50f43403d3b","abbreviatedHash":"a44513a","subject":"add online calibration chapter for vins-mono","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-03T21:03:29+08:00","commitDate":"2020-03-03T21:03:29+08:00"},"Kind":"page","Lastmod":"2020-03-03T21:03:29+08:00","Len":7948,"Name":"Rotation","Permalink":"https://nuhuo08.github.io/rotation/","Plain":"旋转有很多种表达形式，Active/Passive，坐标/坐标系等等。 不同的表达形式得到的矩阵表达形式有较大差异，为了避免混淆，最重要的是，给自己构建一套统一的旋转表示系统。\n简单旋转 假设有一世界坐标系\\(w\\)，将\\(w\\)坐标系逆时针旋转45°，得到一个局部坐标系\\(b\\)。那么，在\\(w\\)坐标系下，坐标为\\(\\begin{pmatrix}1 \\\\ 0\\end{pmatrix}\\)的点，在\\(b\\)坐标系下的坐标是多少呢？\n采用如下公式求得：\n\\[ r_b = R_{bw}r_w \\]\n其中，\\(r_w\\)表示点在\\(w\\)坐标系下的坐标，即\\(\\begin{pmatrix}1 \\\\ 0\\end{pmatrix}\\)。\n而\\(R_{bw}\\)表示\\(w\\)相对于\\(b\\)的旋转。由于\\(b\\)是将\\(w\\)逆时针旋转45°得到的，也就是说，从\\(b\\)出发，转到\\(w\\)的角度为-45°，从而得到：\n\\[ R_{bw}=\\begin{pmatrix}\\cos\\theta \u0026 -\\sin\\theta \\\\ \\sin\\theta \u0026 \\cos\\theta\\end{pmatrix} =\\begin{pmatrix}\\cos(-45\\degree) \u0026 -\\sin(-45\\degree) \\\\ \\sin(-45\\degree) \u0026 \\cos(-45\\degree)\\end{pmatrix} =\\begin{pmatrix}\\frac{\\sqrt{2}}{2} \u0026 \\frac{\\sqrt{2}}{2} \\\\ -\\frac{\\sqrt{2}}{2} \u0026 \\frac{\\sqrt{2}}{2}\\end{pmatrix} \\]\n由此可知：\n\\[ r_b = R_{bw}r_w=\\begin{pmatrix}\\frac{\\sqrt{2}}{2} \\\\ -\\frac{\\sqrt{2}}{2}\\end{pmatrix} \\]\n这正是我们所期待的结果。\n三维旋转 旋转都是按照roll，pitch，yaw的顺序进行的。这里假设分别对应的是X，Y，Z坐标轴。 若从\\(w\\)坐标系出发，通过旋转roll，pitch，yaw的角度后，得到\\(b\\)坐标系，则\\(b\\)坐标系下的点\\(P_b\\)，在\\(w\\)坐标系下的坐标为：\n\\[ \\begin{aligned} P_w \u0026= R_{wb} * P_b \\\\[2mm] \u0026= R_z(yaw) * R_y(pitch) * R_x(roll) * P_b \\\\[2mm] \u0026= \\begin{pmatrix} \\cos \u0026-\\sin \u00260 \\\\ \\sin \u0026\\cos \u00260 \\\\ 0 \u00260 \u00261 \\end{pmatrix} \\begin{pmatrix} \\cos \u00260 \u0026\\sin \\\\ 0 \u00261 \u00260 \\\\ -\\sin \u00260 \u0026\\cos \\end{pmatrix} \\begin{pmatrix} 1 \u00260 \u00260 \\\\ 0 \u0026\\cos \u0026-\\sin \\\\ 0 \u0026\\sin \u0026\\cos \\end{pmatrix} * P_b \\end{aligned} \\]\n请注意Y轴对应的旋转矩阵的符号，跟X，Z轴是不同的。\n右手系四元数 \\[ q=\\cos\\frac{\\theta}{2}+u^w\\cdot\\sin\\frac{\\theta}{2} \\]\n其中：\\(u^w\\)表示在参考系\\(w\\)下的某个单位矢量。\\(q\\)描述的是将坐标系\\(w\\)旋转成新的坐标系\\(b\\)。\n注意！！！\n在原始Hamilton Notation的情况下，会采用\\(_w^bq\\)表示将坐标系\\(w\\)旋转成新的坐标系\\(b\\)，或者采用\\(q_{bw}\\)。这与上一节，我们所习惯的旋转矩阵出现了不统一。按照旋转矩阵的写法，应该是\\(R_{wb}\\)\n这在实际运算过程中会带来很多麻烦，因此，我们直接采用如下规定：\n采用\\(_b^wq\\)表示将坐标系\\(w\\)旋转成新的坐标系\\(b\\)，或者采用\\(q_{wb}\\)\n\\[ \\begin{aligned} r_w\u0026={_b^w}q\\otimes r_b \\otimes {_b^w}q^{-1}\\\\ \u0026=q_{wb}\\otimes r_b \\otimes q_{wb}^{-1}\\\\ \u0026=R_{wb}r_b \\end{aligned} \\]\n我们可以注意到，VINS，组合导航，都是采用了这套符号规定！\n在《捷联惯导算法与组合导航原理讲义》一书中，\\(C_b^i\\)表示从坐标系\\(i\\)转到坐标系\\(b\\)，对应于我们规定的旋转矩阵应该是\\(R_{ib}\\)。 参考 GPS/INS组合导航。\n四元数与旋转矩阵的关系 下面这套转换关系通过Matlab代码验证过，请参考 代码文件。\n\\[ \\mathbf{q} = q_0 + q_1 i + q_2 j + q_3 k = [s, \\mathbf{v}] \\]\n四元数转旋转矩阵：\n\\[ R = \\begin{bmatrix} 1 - 2 q_2^2 - 2 q_3^2 \u0026 2q_1 q_2 - 2q_0 q_3 \u0026 2 q_1 q_3 + 2 q_0 q_2 \\\\ 2q_1 q_2 + 2q_0 q_3 \u0026 1 - 2 q_1^2 - 2 q_3^2 \u0026 2 q_2 q_3 - 2 q_0 q_1 \\\\ 2 q_1 q_3 - 2 q_0 q_2 \u0026 2 q_2 q_3 + 2 q_0 q_1 \u0026 1 - 2 q_1^2 - 2 q_2^2 \\end{bmatrix} \\]\n旋转矩阵转四元数：\n\\[ \\begin{aligned} q_0 \u0026= \\frac{\\sqrt{1+r_{11}+r_{22}+r_{33}}}{2} \\\\[2mm] q_1 \u0026= \\frac{r_{32}-r_{23}}{4q_0} \\\\[2mm] q_2 \u0026= \\frac{r_{13}-r_{31}}{4q_0} \\\\[2mm] q_3 \u0026= \\frac{r_{21}-r_{12}}{4q_0} \\end{aligned} \\]\n四元数乘法：\n\\[ \\begin{aligned} \\mathbf{q}_1 \u0026= [s_1, \\mathbf{v}_1]=\\begin{pmatrix} a_1 \u0026 b_1 \u0026 c_1 \u0026 d_1 \\end{pmatrix}^T \\\\[2mm] \\mathbf{q}_2 \u0026= [s_2, \\mathbf{v}_2]=\\begin{pmatrix} a_2 \u0026 b_2 \u0026 c_2 \u0026 d_2 \\end{pmatrix}^T \\\\[2mm] \\mathbf{q}_1 \\mathbf{q}_2 \u0026= \\begin{pmatrix} a_1 a_2 - b_1 b_2 - c_1 c_2 - d_1 d_2 \\\\ a_1 b_2 + b_1 a_2 + c_1 d_2 - d_1 c_2 \\\\ a_1 c_2 - b_1 d_2 + c_1 a_2 + d_1 b_2 \\\\ a_1 d_2 + b_1 c_2 - c_1 b_2 + d_1 a_2 \\end{pmatrix} \\end{aligned} \\]\n四元数的逆：\n\\[ \\mathbf{q}^* = s - \\mathbf{v} = [s, -\\mathbf{v}] \\\\[2mm] \\mathbf{q}^{-1} = \\frac{\\mathbf{q}^*}{||\\mathbf{q}||^2} \\]\n反对称阵：\n\\[ [\\omega]_{\\times} = \\begin{pmatrix} 0 \u0026-\\omega_z \u0026\\omega_y \\\\ \\omega_z \u00260 \u0026-\\omega_x \\\\ -\\omega_y \u0026\\omega_x \u00260 \\end{pmatrix} \\]\n其它常用公式：\n\\[ a_{\\times}b=-b_{\\times}a \\\\[2mm] (Rb)_\\times=Rb_{\\times}R^T \\]\n按照上面的这一套符号系统，可以看到旋转矩阵与四元数在进行旋转计算时，完全统一：\n\\[ \\begin{aligned} P_c \u0026= R_{cb}R_{ba}P_a \\\\[2mm] \u0026= (\\mathbf{q}_{cb} \\mathbf{q}_{ba})\\begin{pmatrix} 0 \\\\ P_a\\end{pmatrix} (\\mathbf{q}_{cb} \\mathbf{q}_{ba})^{-1} \\end{aligned} \\]\n四元数的导数：\n\\[ \\begin{aligned} \\dot{\\mathbf{q}}\u0026=\\frac{1}{2}\\mathbf{\\Omega}(\\mathbf{\\omega}_{\\mathcal{L}})\\mathbf{q}=\\frac{1}{2}\\mathbf{q}\\otimes\\mathbf{\\omega}_{\\mathcal{L}} \\\\[2mm] \u0026=\\frac{1}{2} \\begin{pmatrix} 0 \u0026-\\omega_x \u0026-\\omega_y \u0026 -\\omega_z \\\\ \\omega_x \u00260 \u0026\\omega_z \u0026-\\omega_y \\\\ \\omega_y \u0026-\\omega_z \u00260 \u0026\\omega_x \\\\ \\omega_z \u0026 \\omega_y \u0026-\\omega_x \u00260 \\end{pmatrix}\\mathbf{q} \\end{aligned} \\]\n对应的旋转矩阵导数：\n\\[ \\dot{R}=R[\\omega_{\\mathcal{L}}]_{\\times} \\]\n左手系四元数 通过上面的定义，右手系四元数与旋转矩阵得到了统一，而左手系四元数将会反而显得比较奇怪了。\n\\({_G^I}q\\) is the unit quaternion describing the rotation from frame {\\(G\\)} to frame {\\(I\\)}\n\\[ r_I={_G^I}q \\cdot r_G=R_{IG} \\cdot r_G \\]\nMSCKF采用的是这套符号规定，看论文时需要特别注意！\n","PublishDate":"2020-02-11T20:28:42+08:00","ReadingTime":3,"RelPermalink":"/rotation/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-14T22:21:57.344151935+08:00","Mode":436,"Name":"index.md","Size":5961},"Tags":null,"Title":"Rotation","Type":"blog","Weight":0,"WordCount":452},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"bayesian-filter","Dir":"blog/sdc-engineer/bayesian-filter/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/sdc-engineer/bayesian-filter/index.md","TranslationBaseName":"index","UniqueID":"14152ecdc6e90c8df5c1296d96fe1fa7"},"FuzzyWordCount":1100,"GitInfo":{"hash":"c64b2b4c9eb7dd64dab6656cc994bb70ebcdbfd6","abbreviatedHash":"c64b2b4","subject":"add mobile mapping page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-04-03T15:28:26+08:00","commitDate":"2020-04-03T15:28:26+08:00"},"Kind":"page","Lastmod":"2020-04-03T15:28:26+08:00","Len":23393,"Name":"Bayesian Filter","Permalink":"https://nuhuo08.github.io/bayesian-filter/","Plain":"Kalman Filter Imagine you are in a car equipped with sensors on the outside. The car sensors can detect objects moving around: for example, the sensors might detect a pedestrian, as described in the video, or even a bicycle. For variety, let's step through the Kalman Filter algorithm using the bicycle example.\nThe Kalman Filter algorithm will go through the following steps:\n first measurement - the filter will receive initial measurements of the bicycle's position relative to the car. These measurements will come from a radar or lidar sensor. initialize state and covariance matrices - the filter will initialize the bicycle's position based on the first measurement. then the car will receive another sensor measurement after a time period \\(\\Delta t\\). predict - the algorithm will predict where the bicycle will be after time \\(\\Delta t\\). One basic way to predict the bicycle location after \\(\\Delta t\\) is to assume the bicycle's velocity is constant; thus the bicycle will have moved velocity * \\(\\Delta t\\). In the extended Kalman filter lesson, we will assume the velocity is constant. update - the filter compares the \u0026quot;predicted\u0026quot; location with what the sensor measurement says. The predicted location and the measured location are combined to give an updated location. The Kalman filter will put more weight on either the predicted location or the measured location depending on the uncertainty of each value. then the car will receive another sensor measurement after a time period \\(\\Delta t\\). The algorithm then does another predict and update step.  Extended Kalman Filter (EKF) 动态方程 常速度模型下，加速度为白噪声。\n\\[ \\begin{pmatrix} p'_x \\\\ p'_y \\\\ v'_x \\\\ v'_y \\end{pmatrix} = \\underbrace{\\begin{pmatrix} 1 \u00260 \u0026\\Delta t \u00260 \\\\ 0 \u00261 \u00260 \u0026\\Delta t \\\\ 0 \u00260 \u00261 \u00260 \\\\ 0 \u00260 \u00260 \u00261 \\end{pmatrix}}_F \\begin{pmatrix} p_x \\\\ p_y \\\\ v_x \\\\ v_y \\end{pmatrix} + \\begin{pmatrix} \\frac{a_x \\Delta t^2}{2} \\\\ \\frac{a_y \\Delta t^2}{2} \\\\ a_x \\Delta t \\\\ a_y \\Delta t \\end{pmatrix} \\]\n其中动态噪声的协方差矩阵，应该根据与加速度白噪声的关系确定。而加速度的白噪声大小属于先验值。\n\\[ \\begin{pmatrix} \\frac{a_x \\Delta t^2}{2} \\\\ \\frac{a_y \\Delta t^2}{2} \\\\ a_x \\Delta t \\\\ a_y \\Delta t \\end{pmatrix} = \\underbrace{\\begin{pmatrix} \\frac{\\Delta t^2}{2} \u00260 \\\\ 0 \u0026\\frac{\\Delta t^2}{2} \\\\ \\Delta t \u00260 \\\\ 0 \u0026\\Delta t \\end{pmatrix}}_G \\begin{pmatrix} a_x \\\\ a_y \\end{pmatrix} \\]\n根据协方差传播定律，在已知\\(a_x\\)、\\(a_y\\)的标准差为\\(\\sigma_{ax}\\)、\\(\\sigma_{ay}\\)的情况下，动态噪声的协方差矩阵为：\n\\[ Q = GQ_vG^T= \\begin{pmatrix} \\frac{\\Delta t^2}{2} \u00260 \\\\ 0 \u0026\\frac{\\Delta t^2}{2} \\\\ \\Delta t \u00260 \\\\ 0 \u0026\\Delta t \\end{pmatrix} \\begin{pmatrix} \\sigma_{ax}^2 \u00260 \\\\ 0 \u0026\\sigma_{ay}^2 \\end{pmatrix} \\begin{pmatrix} \\frac{\\Delta t^2}{2} \u00260 \u0026\\Delta t \u00260 \\\\ 0 \u0026\\frac{\\Delta t^2}{2} \u00260 \u0026\\Delta t \\end{pmatrix} \\]\nLidar \\[ \\begin{pmatrix} p_x \\\\ p_y \\end{pmatrix} = \\underbrace{\\begin{pmatrix} 1 \u00260 \u00260 \u00260 \\\\ 0 \u00261 \u00260 \u00260 \\end{pmatrix}}_H \\begin{pmatrix} p'_x \\\\ p'_y \\\\ v'_x \\\\ v'_y \\end{pmatrix} \\]\n观测值的噪声为先验值：\n\\[ R=\\begin{pmatrix} \\sigma_{px}^2 \u00260 \\\\ 0 \u0026\\sigma_{py}^2 \\end{pmatrix} \\]\nRadar \\[ \\begin{aligned} \\begin{pmatrix} \\rho \\\\ \\phi \\\\ \\dot{\\rho} \\end{pmatrix} \u0026= \\begin{pmatrix} \\sqrt{{p'_x}^2+{p'_y}^2} \\\\ \\arctan(p'_y / p'_x) \\\\ \\frac{p'_x v'_x + p'_y v'_y}{\\sqrt{{p'_x}^2+{p'_y}^2}} \\end{pmatrix} \\\\[2mm] \u0026\\approx \\begin{pmatrix} \\sqrt{p_x^2+p_y^2} \\\\ \\arctan(p_y / p_x) \\\\ \\frac{p_x v_x + p_y v_y}{\\sqrt{p_x^2+p_y^2}} \\end{pmatrix} + \\underbrace{\\begin{pmatrix} \\frac{p_x}{\\sqrt{p_x^2+p_y^2}} \u0026\\frac{p_y}{\\sqrt{p_x^2+p_y^2}} \u00260 \u00260 \\\\ -\\frac{p_y}{p_x^2+p_y^2} \u0026\\frac{p_x}{p_x^2+p_y^2} \u00260 \u00260 \\\\ \\frac{p_y(v_xp_y-v_yp_x)}{(p_x^2+p_y^2)^{3/2}} \u0026\\frac{p_x(v_yp_x-v_xp_y)}{(p_x^2+p_y^2)^{3/2}} \u0026\\frac{p_x}{\\sqrt{p_x^2+p_y^2}} \u0026\\frac{p_y}{\\sqrt{p_x^2+p_y^2}} \\end{pmatrix}}_{H_j} \\begin{pmatrix} p'_x - p_x \\\\ p'_y - p_y \\\\ v'_x - v_x \\\\ v'_y - v_y \\end{pmatrix} \\end{aligned} \\]\n观测值的噪声为先验值：\n\\[ R=\\begin{pmatrix} \\sigma_{\\rho}^2 \u00260 \u00260 \\\\ 0 \u0026\\sigma_{\\phi}^2 \u00260 \\\\ 0 \u00260 \u0026\\sigma_{\\dot{\\rho}}^2 \\end{pmatrix} \\]\n已知状态转移矩阵\\(F\\)、动态噪声\\(Q\\)，便可以预测下一时刻的状态和协方差；\n已知观测矩阵\\(H\\)、观测噪声\\(R\\)，当更新一个观测量\\(z\\)时，便可以得到最优估计状态和协方差。\n      Error State Extended Kalman Filter (ES-EKF) 参考 An Improved EKF - The Error State Extended Kalman Filter\n         More 迭代卡尔曼：当非线性化程度高的时候，可能需要迭代多次。每次迭代时候，协方差\\(P\\)要保持相同不变，只更新先验的状态量\\(x\\)。\n最小二乘：当迭代多次，且动态噪声设置为无穷大时，观测噪声起主导作用，其效果等同于最小二乘。\n序列化卡尔曼滤波：将观测量依次输入，矩阵运算变为标量运算，减小计算量，同时可以剔除粗差。\nUnscented Kalman Filter CVTR CVTR表示运动模型为常速度、常转向角速度，其微分方程可以写做：\n\\[ \\begin{pmatrix} \\dot{p_x} \\\\ \\dot{p_y} \\\\ \\dot{v} \\\\ \\dot{\\psi} \\\\ \\ddot{\\psi} \\end{pmatrix} = \\begin{pmatrix} v\\cdot\\cos(\\psi) \\\\ v\\cdot\\sin(\\psi) \\\\ 0 \\\\ \\dot{\\psi} \\\\ 0 \\end{pmatrix} \\]\n对上式进行积分，可得：\n\\[ \\begin{aligned} x_{k+1} \u0026= x_k + \\int_{t_k}^{t_{k+1}} \\begin{pmatrix} \\dot{p_x}(t) \\\\ \\dot{p_x}(t) \\\\ \\dot{v}(t) \\\\ \\dot{\\psi}(t) \\\\ \\ddot{\\psi}(t) \\end{pmatrix} dt + \\nu \\\\[2mm] \u0026=x_k+ \\begin{pmatrix} v_k\\int_{t_k}^{t_{k+1}}\\cos(\\psi_k+\\dot{\\psi}_k\\cdot(t-t_k))dt \\\\ v_k\\int_{t_k}^{t_{k+1}}\\cos(\\psi_k+\\dot{\\psi}_k\\cdot(t-t_k))dt \\\\ 0 \\\\ \\dot{\\psi}_k\\Delta t \\\\ 0 \\end{pmatrix} + \\nu \\\\[2mm] \u0026=x_k+ \\begin{pmatrix} \\frac{v_k}{\\dot{\\psi}_k}\\left(\\sin(\\psi_k+\\dot{\\psi}_k\\Delta t)-\\sin(\\psi_k)\\right) \\\\ \\frac{v_k}{\\dot{\\psi}_k}\\left(-\\cos(\\psi_k+\\dot{\\psi}_k\\Delta t)+\\cos(\\psi_k)\\right) \\\\ 0 \\\\ \\dot{\\psi}_k\\Delta t \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} \\frac{1}{2}(\\Delta t)^2\\cos(\\psi_k)\\cdot\\nu_{a,k} \\\\ \\frac{1}{2}(\\Delta t)^2\\sin(\\psi_k)\\cdot\\nu_{a,k} \\\\ \\Delta t\\cdot\\nu_{a,k} \\\\ \\frac{1}{2}(\\Delta t)^2\\cdot\\nu_{\\ddot{\\psi},k} \\\\ \\Delta t\\cdot\\nu_{\\ddot{\\psi},k} \\end{pmatrix} \\text{ if } \\dot{\\psi}\\neq0 \\\\[2mm] \u0026=x_k+ \\begin{pmatrix} v_k\\cos\\psi_k\\Delta t \\\\ v_k\\sin\\psi_k\\Delta \\\\ 0 \\\\ 0 \\\\0 \\end{pmatrix} + \\begin{pmatrix} \\frac{1}{2}(\\Delta t)^2\\cos(\\psi_k)\\cdot\\nu_{a,k} \\\\ \\frac{1}{2}(\\Delta t)^2\\sin(\\psi_k)\\cdot\\nu_{a,k} \\\\ \\Delta t\\cdot\\nu_{a,k} \\\\ \\frac{1}{2}(\\Delta t)^2\\cdot\\nu_{\\ddot{\\psi},k} \\\\ \\Delta t\\cdot\\nu_{\\ddot{\\psi},k} \\end{pmatrix} \\text{ if } \\dot{\\psi}=0 \\end{aligned} \\]\nUKF 对于动态方程高度非线性化，可以使用UKF进行参数估计。其核心思想为，按照高斯分布采样点，通过非线性函数后，对变化后的点进行高斯分布拟合。\n   Generate Sigma Points \\[ X_{k|k} = \\begin{pmatrix} x_{k|k} \u0026 x_{k|k}+\\sqrt{(\\lambda+n_x)P_{k|k}} \u0026 x_{k|k}-\\sqrt{(\\lambda+n_x)P_{k|k}} \\end{pmatrix} \\]\nwith scaling factor \\(\\lambda=3-n_x\\)\n为了将动态噪声的影响纳入，需要采用状态增广的方法：\n   Predict Sigma Points 使用上面推导的CVTR模型，预测Sigma Points。\n   Predict Mean and Covariance    Measurement Prediction 由于观测噪声是可直接相加，因此不再需要状态增广。\n      UKF Update Here you need the cross-correlation matrix between the predicted sigma points in the state space and the predicted sigma points in the measurement space.\n   Parameters And Consistency 服从\\(\\chi^2\\)分布，对于Radar传感器，有3个观测量，自由度为3。查表可知，统计上来说，5%的NIS值会超过7.8。\n   Partical Filter Init 在初始点附近生成N个粒子。\nfor (int i = 0; i \u0026lt; num_particles; ++i) { Particle p; p.id = i; p.weight = 1.0; p.x\t= dist_x(gen); p.y\t= dist_y(gen); p.theta\t= dist_theta(gen); particles.push_back(p); }  Prediction 根据Motion Model，预测下一时刻位置，并添加动态噪声。\nif (fabs(yaw_rate) \u0026gt; 1e-5) { theta_new = theta_old + yaw_rate * delta_t; x_new = x_old + velocity / yaw_rate * (sin(theta_new) - sin(theta_old)); y_new = y_old + velocity / yaw_rate * (cos(theta_old) - cos(theta_new)); } else { theta_new = theta_old; x_new = x_old + velocity * delta_t * cos(theta_old); y_new = y_old + velocity * delta_t * sin(theta_old); } normal_distribution\u0026lt;double\u0026gt; dist_x(x_new, std_pos[0]); normal_distribution\u0026lt;double\u0026gt; dist_y(y_new, std_pos[1]); normal_distribution\u0026lt;double\u0026gt; dist_theta(theta_new, std_pos[2]); particle.x = dist_x(gen); particle.y = dist_y(gen); particle.theta = dist_theta(gen);  DataAssociation 根据观测值，找到地图上对应的点。\nfor (auto\u0026amp; observation : observations) { double min_dist = 9999.0; for (auto\u0026amp; predict : predicted) { double d = dist(observation.x, observation.y, predict.x, predict.y); if (d \u0026lt; min_dist) { observation.id = predict.id; min_dist = d; } } }  Update Weight 把观测的点，与找到的地图上的点，求正态分布概率。\nfor (auto\u0026amp; obs : observations_map) { for (auto\u0026amp; land: visibleLandmarks_map) if (obs.id == land.id) { mu_x = land.x; mu_y = land.y; break; } double tmp = exp( -( pow(obs.x - mu_x, 2) / (2 * std_landmark[0] * std_landmark[0]) + pow(obs.y - mu_y, 2) / (2 * std_landmark[1]* std_landmark[1]) ) ) / (2 * M_PI * std_landmark[0]* std_landmark[1]); if(fabs(tmp) \u0026lt; 1e-15) continue; particle_likelihood *= tmp; } particle.weight = particle_likelihood;  之后对粒子的概率进行归一化。\nfor (auto\u0026amp; particle : particles) particle.weight /= weights_sum;  Resample 根据权值重采样，权值大的容易被多次采到，表示该粒子所在的位置更接近真实值，粒子在此处渐渐聚集。 重采样之后，每个粒子的权值重新赋值为1。\nvector\u0026lt;double\u0026gt; particle_weights; for (auto\u0026amp; particle : particles) particle_weights.push_back(particle.weight); discrete_distribution\u0026lt;int\u0026gt; weighted_distribution(particle_weights.begin(), particle_weights.end()); vector\u0026lt;Particle\u0026gt; resampled_particles; default_random_engine gen; for (int i = 0; i \u0026lt; num_particles; ++i) { int k = weighted_distribution(gen); particles[k].weight = 1.0; resampled_particles.push_back(particles[k]); } particles = resampled_particles;  多余的话 动态方程的确定：\n 直接写出下一时刻状态量\\(x_{k+1}\\)与当前时刻状态量\\(x_k\\)的数学方程；（本文中的EKF） 直接写出状态量导数\\(\\dot{x}\\)与状态量\\(x\\)的数学方程；  积分得到下一时刻状态量\\(x_{k+1}\\)与当前时刻状态量\\(x_k\\)的数学方程；（本文中的UKF / VINS-MONO的代码实现） 求得error-state状态方程，即\\(\\dot{\\delta x}\\)与\\(\\delta x\\)的数学方程；（MSCKF / GPS\u0026amp;INS组合导航 / VINS-MONO论文）   ","PublishDate":"2020-02-10T09:31:36+08:00","ReadingTime":5,"RelPermalink":"/bayesian-filter/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-04-02T10:48:57.203930584+08:00","Mode":436,"Name":"index.md","Size":12779},"Tags":null,"Title":"Bayesian Filter","Type":"blog","Weight":0,"WordCount":1051},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"path-planning","Dir":"blog/sdc-engineer/path-planning/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/sdc-engineer/path-planning/index.md","TranslationBaseName":"index","UniqueID":"d934e85c7be151ca8eedada19d181bbe"},"FuzzyWordCount":1500,"GitInfo":{"hash":"4bf80934147ad53644288edd23e97039c4852613","abbreviatedHash":"4bf8093","subject":"add path-planning page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-02-09T23:36:53+08:00","commitDate":"2020-02-09T23:36:53+08:00"},"Kind":"page","Lastmod":"2020-02-09T23:36:53+08:00","Len":21009,"Name":"Path Planning","Permalink":"https://nuhuo08.github.io/path-planning/","Plain":" search algorithms used in discrete path planning prediction which is where we use the data from sensor fusion to generate predictions about what all the other objects around us are likely to do. behavior planning: what the car shall do in the next 10 seconds or so. trajectory generation, which is where we create smooth, drivable, and collision-free trajectories.  Search    A star with heuristic function:\n   Dynamic Programming:\nGiven: Map \u0026amp; Goal\nOutputs: Best path from ANYWHERE\n   Prediction A prediction module uses a map and data from sensor fusion to generate predictions for what all other dynamic objects in view are likely to do. Neither approach (model based or data driven) is strictly better than the other but there are certain situations in which one is more useful than the other.\nThere are two different approaches to handle the prediction problem: Model-based approach vs Data-driven approach.\n   Data-driven Data-driven approaches would be more useful in the following situations:\n Predicting the behavior of an unidentified object sitting on the road.  Data-driven approaches solve the prediction problem in two phases:\n Offline training Online Prediction  Offline Training In this phase the goal is to feed some machine learning algorithm a lot of data to train it. For the trajectory clustering example this involved:\n Define similarity - we first need a definition of similarity that agrees with human common-sense definition. Unsupervised clustering - at this step some machine learning algorithm clusters the trajectories we've observed. Define Prototype Trajectories - for each cluster identify some small number of typical \u0026quot;prototype\u0026quot; trajectories.     Online Prediction Once the algorithm is trained we bring it onto the road. When we encounter a situation for which the trained algorithm is appropriate (returning to an intersection for example) we can use that algorithm to actually predict the trajectory of the vehicle. For the intersection example this meant:\n Observe Partial Trajectory - As the target vehicle drives we can think of it leaving a \u0026quot;partial trajectory\u0026quot; behind it. Compare to Prototype Trajectories - We can compare this partial trajectory to the corresponding parts of the prototype trajectories. When these partial trajectories are more similar (using the same notion of similarity defined earlier) their likelihoods should increase relative to the other trajectories. Generate Predictions - For each cluster we identify the most likely prototype trajectory. We broadcast each of these trajectories along with the associated probability (see the image below).     Model-based Model-based approaches would be more useful in the following situations:\n Determining maximum safe turning speed on a wet road. Predicting the behavior of a vehicle on a two lane highway in light traffic.  You can think of model based solutions to the prediction problem as also having an \u0026quot;offline\u0026quot; and online component. In that view, this approach requires:\n Defining process models (offline). Using process models to compare driver behavior to what would be expected for each model. Probabilistically classifying driver intent by comparing the likelihoods of various behaviors with a multiple-model algorithm. Extrapolating process models to generate trajectories.     Defining Process Models You saw how process models can vary in complexity from very simple...\n   Using Process Models Process Models are first used to compare a target vehicle's observed behavior to the behavior we would expect for each of the maneuvers we've created models for. The pictures below help explain how process models are used to calculate these likelihoods.\n   On the left we see two images of a car. At time \\(k-1\\) we predicted where the car would be if it were to go straight vs go right. Then at time \\(k\\) we look at where the car actually is. The graph on the right shows the car's observed ss coordinate along with the probability distributions for where we expected the car to be at that time. In this case, the ss that we observe is substantially more consistent with turning right than going straight.\nClassifying Intent with Multiple Model Algorithm In the image at the top of the page you can see a bar chart representing probabilities of various clusters over time. Multiple model algorithms serve a similar purpose for model based approaches: they are responsible for maintaining beliefs for the probability of each maneuver. The algorithm we discussed is called the Autonomous Multiple Model algorithm (AMM). AMM can be summarized with this equation:\n\\[ \\mu_k^{(i)}=\\frac{\\mu_{k-1}^{(i)}L_k^{(i)}}{\\sum_{j=1}^M\\mu_{k-1}^{(j)}L_k^{(j)}} \\]\nor, if we ignore the denominator (since it just serves to normalize the probabilities), we can capture the essence of this algorithm with\n\\[ \\mu_k^{(i)} \\propto \\mu_{k-1}^{(i)}L_k^{(i)} \\]\nwhere the \\(\\mu_k^{(i)}\\) is the probability that model number \\(i\\) is the correct model at time \\(k\\) and \\(L_k^{(i)}\\) is the likelihood for that model (as computed by comparison to process model).\nThe paper, \u0026quot;A comparative study of multiple model algorithms for maneuvering target tracking\u0026quot; is a good reference to learn more.\n   Trajectory Generation Trajectory generation is straightforward once we have a process model. We simply iterate our model over and over until we've generated a prediction that spans whatever time horizon we are supposed to cover. Note that each iteration of the process model will necessarily add uncertainty to our prediction.\nHybrid Approach Replace Multimodel Estimator with Machine Learning Method. For more info, please refer to machine learning.\n   Behavior Planning It's possible to suggest a wide variety of behaviors by specifying only a few quantities. For example by specifying only a target lane, a target vehicle (to follow), a target speed, and a time to reach these targets, we can make suggestions as nuanced as \u0026quot;stay in your lane but get behind that vehicle in the right lane so that you can pass it when the gap gets big enough.\u0026quot;\nThe behavior planning team is responsible for providing guidance to the trajectory planner about what sorts of maneuvers they should plan trajectories for.\n      Finite State Machine:\n   One way to implement a transition function is by generating rough trajectories for each accessible \u0026quot;next state\u0026quot; and then finding the best. To \u0026quot;find the best\u0026quot; we generally use cost functions. We can then figure out how costly each rough trajectory is and then select the state with the lowest cost trajectory.\nFrom what I understood it goes as follows (note that I had to read all the subsequent lessons to get to this understanding): The goal lane is the lane that we should aim to in the long run (e.g. the right most lane for normal driving) and it is used to compute the distance (and cost). Then we need to choose the behaviour according to traffic, here we have different choices when it comes to passing cars and there is the catch that we have two different states to change lane: prepare for change lane and change lane with the former aimed to mach the speed to perform a lane change and the latter to actually move to the adjacent lane. The \u0026quot;final lane\u0026quot; is the lane that the state will be at, while the \u0026quot;intended lane\u0026quot; is the lane that the state is aiming for. So, when we prepare for a lane change the final lane will be the same lane we are at, as we do not change lane at this stage, while the \u0026quot;intended lane\u0026quot; is the lane we are preparing for. When we change lane the \u0026quot;final lane\u0026quot; is the lane we are going to, which corresponds to the \u0026quot;intended lane\u0026quot; as at this stage we are actually changing the lane.\n      An Programming Examples:\npractice\nsolution\nTrajectory Generation Types of Motion Planning Algorithms       Hybrid A*  It uses a continuous search space. It uses an optimistic heuristic function to guide grid cell expansion. Solutions it finds are drivable        Exercise:\nhybrid-a-star\nHybrid A* doesn't take advantage of the pre-defined environment information.\nStructured Trajectory Generation       Jerk Minimizing Trajectories             Implementing Feasibility:\n   When evaluating the feasibility of a potential trajectory, the following quantities should be checked\n Maximum velocity (with respect to car's capabilities and speed limit) Minimum velocity Maximum acceleration Minimum acceleration Steering angle  Cost Functions:\n   If you are interested in learning more about PTG, I've included a link to a paper (below) titled \u0026quot;Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame\u0026quot;. It is short and discusses some interesting (and potentially useful) topics like:\n Cost Functions. Differences between high speed and low speed trajectory generation. Implementation of specific maneuvers relevant to highway driving like following, merging, and velocity keeping. How to combining lateral and longitudinal trajectories. A derivation of the transformation from Frenet coordinates to global coordinates (in the appendix).  Exercises:\nPolynomial Playground (making PTG work)\ntrajectoryexercise2-python3\nPaper Reading Indoors\nIntention-Net: Integrating Planning and Deep Learning for Goal-Directed Autonomous Navigation by S. W. Gao, et. al.\nCity Navigation\nLearning to Navigate in Cities Without a Map by P. Mirowski, et. al.\nIntersections\nA Look at Motion Planning for Autonomous Vehicles at an Intersection by S. Krishnan, et. al.\nPlanning in Traffic with Deep Reinforcement Learning\nDeepTraffic: Crowdsourced Hyperparameter Tuning of Deep Reinforcement Learning Systems for Multi-Agent Dense Traffic Navigation by L. Fridman, J. Terwilliger and B. Jenik\n","PublishDate":"2020-02-09T18:22:30+08:00","ReadingTime":7,"RelPermalink":"/path-planning/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-09T23:31:07.067692904+08:00","Mode":436,"Name":"index.md","Size":13374},"Tags":null,"Title":"Path Planning","Type":"blog","Weight":0,"WordCount":1488},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"vim","Dir":"blog/tools/vim/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/tools/vim/index.md","TranslationBaseName":"index","UniqueID":"1c3d4a5fa2d397247865ee360994942d"},"FuzzyWordCount":300,"GitInfo":{"hash":"63f922e914d13d85fe2bf6ee0db7fbf9547310b3","abbreviatedHash":"63f922e","subject":"add vim page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-02-08T19:21:48+08:00","commitDate":"2020-02-08T19:21:48+08:00"},"Kind":"page","Lastmod":"2020-02-08T19:21:48+08:00","Len":6659,"Name":"Vim","Permalink":"https://nuhuo08.github.io/vim/","Plain":"安装 cd ~ git clone git@github.com:nuhuo08/MyVimrc.git mv MyVimrc .vim_mengqi ln -s .vim_mengqi/.vimrc .vimrc ln -s .vim_mengqi/.ackrc .ackrc # ln -s .vim_mengqi/.bash_aliases .bash_aliases cd .vim_mengqi mkdir -p cache plugged temp_dirs/undodir vi :PlugInstall #NOTE: You may need to run the command below for several times. Since downloading submodules may fail. cd ~/.vim_mengqi/plugged/YouCompleteMe git submodule update --init --recursive #NOTE: YCM donot support python2.7 any more. For Ubuntu 16.04, checkout 9309f77 git checkout 9309f77 python3 install.py --clang-completer 常用快捷命令 ,w 保存 ,nn 打开文件浏览树 ,nf 将文件浏览树定位到当前文件 ,tb 打开函数列表 ,f 查找工程文件 ,j 最近编辑文件列表 ,g 开始查找某字符串 ,r 替换visual选中的字符串 gv 查找visual选中模式下的字符串 gcc 注释 ga*| 以|符号对选中的多行进行对齐 ctrl+n 开始多光标模式 ctrl+x 多光标模式，跳过当前词 ctrl+p 多光标模式，回到上一次选中词 ,q 打开quickfix窗口 ,n 下一个quickfix记录 ,p 上一个quickfix记录 alt+p 粘贴上一个剪切板内容 alt+m 粘贴下一个剪切板内容 g] 跳转到tag ,,w 高级的移动模式 ctrl+d 窗口翻页 ctrl+u ctrl+f ctrl+b zt 当前行在窗口的位置 zz zb * 查找并高亮字符串 # ,m 删除^M符号 gt 下一个tab gT 上一个tab 2gt 第二个tab ]c 跳到下一处Git修改处 [c ,hs git stash ,hu git undo ,hp git preview ,d\ttoggle gitgutter ma 设置书签a `a \u0026#39;a Vim的配置 vim有强大的可扩展性，请参考Learn Vimscript the Hard Way。\n~/.vim_mengqi/vimrc/文件夹下面时候个人定制的很多配置项，熟悉以后可以自定义很多快捷的操作。\nBasic Settings set用于配置基本的vim属性。例如，设置下面命令，可以在vim中使用鼠标。\nset mouse=a map用于映射快捷键。例如，下面的命令，可以使用\u0026lt;C-j\u0026gt;映射\u0026lt;C-W\u0026gt;j，实现在窗口中跳转。\nmap \u0026lt;C-j\u0026gt; \u0026lt;C-W\u0026gt;j map的变体有多种，例如vnoremap可以在visual模式下映射一些命令。\nExtended Settings fun! CleanExtraSpaces() let save_cursor = getpos(\".\") let old_query = getreg('/') silent! %s/\\s\\+$//e call setpos('.', save_cursor) call setreg('/', old_query) endfun if has(\"autocmd\") autocmd BufWritePre *.txt,*.js,*.py,*.wiki,*.sh,*.h,*.c,*.cpp,*.m :call CleanExtraSpaces() endif 可以自定义函数CleanExtraSpaces，可以使用autocmd自动运行，BufWritePre则表示在写入buffer之前做一些操作。 上面这段脚本，可以自动清除txt等文件末尾多余的空白符。\nPlugin Settings 使用了Plug作为插件管理器，插件可以扩展vim的功能，使编辑更为高效。\ncall plug#begin(\u0026#39;~/.vim_mengqi/plugged\u0026#39;) Plug \u0026#39;tpope/vim-fugitive\u0026#39;, Plug \u0026#39;airblade/vim-gitgutter\u0026#39; call plug#end() 上面的命令，为vim添加了两个插件的git仓库，运行:PlugInstall，就可以安装好相应的两个插件。\n插件可以配置相对应的快捷键，例如：\nlet g:gitgutter_enabled=1 let g:gitgutter_diff_args = \u0026#39;-w\u0026#39; set updatetime=100 nnoremap \u0026lt;silent\u0026gt; \u0026lt;leader\u0026gt;d :GitGutterToggle\u0026lt;cr\u0026gt; 启动gitgutter插件；忽略空白字符的修改；更新时间为100ms；使用,d启动或关闭该插件的功能。\n其他 Add flag to CMakeList.txt: -DCMAKE_EXPORT_COMPILE_COMMANDS=1： YouCompleteMe就可以自动识别到所需要的代码文件了。 此功能由.ycm_c-c++_conf.py提供。\ncd --：可以看到terminal里面cd的目录历史。此功能由acd_func.sh提供。\n","PublishDate":"2020-02-08T18:10:46+08:00","ReadingTime":2,"RelPermalink":"/vim/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-11-13T20:39:29.161654491+08:00","Mode":436,"Name":"index.md","Size":4351},"Tags":null,"Title":"Vim","Type":"blog","Weight":0,"WordCount":239},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"git","Dir":"blog/tools/git/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/tools/git/index.md","TranslationBaseName":"index","UniqueID":"6785def9d3a07ed3de8b455abcec8f37"},"FuzzyWordCount":500,"GitInfo":{"hash":"a44513a073c4ee2eab1c5884736df50f43403d3b","abbreviatedHash":"a44513a","subject":"add online calibration chapter for vins-mono","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-03T21:03:29+08:00","commitDate":"2020-03-03T21:03:29+08:00"},"Kind":"page","Lastmod":"2020-03-03T21:03:29+08:00","Len":12604,"Name":"Git","Permalink":"https://nuhuo08.github.io/git/","Plain":"配置 SSH Key ssh-keygen -t rsa 这一步是生成了ssh的秘钥，可以建立本机与代码仓库之间的ssh链接来下载代码。\n然后将~/.ssh文件夹下的id_rsa.pub文件里的文本内容，粘贴至代码服务器里面Settings --\u0026gt; SSH keys --\u0026gt; Add。\n其他配置 git config命令实际上就是在修改仓库根目录下的.git/config文件。\n配置git提交记录里的用户名和邮箱：\ngit config user.name \u0026#34;UserName\u0026#34; git config user.email \u0026#34;Example@email.com\u0026#34; Windows盘上的文件在Ubuntu下的文件模式发生了变化，导致git status时显示所有文件都有更改。 若要忽略文件模式的变化：\ngit config core.filemode false 当加上--global命令是，修改的是全局git配置，即~/.gitconfig\ngit config --global user.name \u0026#34;UserName\u0026#34; 重要命令 Branch git checkout -b develop git branch -d develop tag git tag git tag v1.4-lw git push origin v1.4-lw git push origin --tags git tag -d v1.4-lw git push origin --delete \u0026lt;tagname\u0026gt; git checkout v1.4-lw Working Directory 假设当前有两个分支，master和develop，对应的在服务器上有origin/master和origin/develop，此外还有一个指向当前commit的隐藏的HEAD。\n可以通过git status查看当前文件的状态：\n 当文件被修改时，会发现Working Directory里的文件名是红色； 运行git add .命令后，文件被添加到Index，此时文件名是绿色； 运行git commit命令后，HEAD指向新生成新的commit，此时origin/master落后于master； 运行git push命令后，origin/master与master会同步起来，指向同一个commit。     stash git stash git stash list git stash pop git stash apply stash@{0} git stash apply --index git stash drop stash@{0} git stash save \u0026#34;guacamole sauce WIP\u0026#34; git stash apply stash^{/guacamo} 当编辑文件以后，Working Directory里面会有变红的文件名出现。若想暂时隐藏修改过的内容，可以用stash命令，将修改暂存起来，在之后需要的时候pop出来使用。\npush git remote add origin git@github.com:USERNAME/REPOSITORY.git git remote set-url origin git@github.com:USERNAME/REPOSITORY.git Send local changes in the current branch to its remote counterpart: git push\nSend local changes in a given branch to its remote counterpart: git push remote_name local_branch\nPublish the current branch to a remote repository, setting the remote branch name: git push remote_name -u remote_branch\ncherry-pick git cherry-pick f2e6f51 可以直接将某一特定commit追加到当前分支。\namend git commit --amend 若上一次提交遗漏了某些文件，或者想修改commit msg，可以使用amend命令。\nreset vs checkout checkout只会移动HEAD，而reset则会将HEAD所指向的branch一起移动，如下图：\n   merge vs rebase merge    git checkout master git merge hotfix    由于iss53在master的直接的前方，merge的时候会直接把master移动到跟iss53一起，此过程成为Fast-Forward。 而当iss53跟master分叉了的时候，会新建一个commit，将两者融合起来。\nrebase    git checkout experiment git rebase master rebase可以得到一个更加干净的代码线，上面两句话等价于git rebase master experiment。\n   git checkout master git merge experiment 然后再把master分支merge到最新状态。\nrebase的高级用法\n   git rebase --onto master server client This basically says, “Take the client branch, figure out the patches since it diverged from the server branch, and replay these patches in the client branch as if it was based directly off the master branch instead.”\n只要是server相关的都不要，剩下与client相关的都需要，追加到master上。\n由此得到的变体：\n删除连续的commit\n1---2---3---4---5---master 1---2---5---master git rebase --onto master~4 master~2 master 删除特定commit\ngit rebase --onto \u0026lt;commit-id\u0026gt;^ \u0026lt;commit-id\u0026gt; 将两个commit合并成为一个\ngit rebase -i HEAD~2 and then modify the second commit message from \u0026quot;pick\u0026quot; to \u0026quot;f\u0026quot;\n其他技巧 Modify 修改git仓库里的用户名和邮箱信息 How to change the commit author for one specific commit?\ngit config user.name \u0026#34;Username\u0026#34; git config user.email \u0026#34;Example@email.com\u0026#34; git rebase -i -p --root // and then replace pick with edit git commit --amend --author=\u0026#34;Username \u0026lt;Example@email.com\u0026gt;\u0026#34; --no-edit \u0026amp;\u0026amp; git rebase --continue git push origin master -f Compare [diff] tool = meld [difftool] prompt = false [difftool \u0026#34;meld\u0026#34;] cmd = meld \u0026#34;$LOCAL\u0026#34; \u0026#34;$REMOTE\u0026#34; 在 ~/.gitconfig 文件中添加上述配置以后，若要比较commit之间的文件差异， 可以采用如下命令打开meld对比工具进行整个工程中，有变化的文件进行可视化比较，非常方便。\ngit difftool -d b8de0b2 a532c05 改写服务器历史 git checkout --orphan temp f2e6f51 git commit -m \u0026#34;Truncated history\u0026#34; git rebase --onto temp f2e6f51 master git branch -D temp git push -f origin master git push -f会强制推送到服务器上，若推送失败，可能是该分支被保护了，一般在远程仓库的设置中可以取消保护： Settings --\u0026gt; Protected branches --\u0026gt; Unprotect\n","PublishDate":"2020-01-17T08:00:00+08:00","ReadingTime":2,"RelPermalink":"/git/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-20T16:25:45.753973734+08:00","Mode":436,"Name":"index.md","Size":6290},"Tags":null,"Title":"Git","Type":"blog","Weight":0,"WordCount":408},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"gps-ins","Dir":"blog/gps/gps-ins/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/gps/gps-ins/index.md","TranslationBaseName":"index","UniqueID":"f24c3b92f31e9d85329e4df7c2cd226d"},"FuzzyWordCount":700,"GitInfo":{"hash":"92551363d02964155614d82e78eb1e9ba2bd3d26","abbreviatedHash":"9255136","subject":"add rotation page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-02-11T22:45:53+08:00","commitDate":"2020-02-11T22:45:53+08:00"},"Kind":"page","Lastmod":"2020-02-11T22:45:53+08:00","Len":7612,"Name":"GPS/INS组合导航","Permalink":"https://nuhuo08.github.io/gps-ins/","Plain":"涉及到卡尔曼滤波，最重要的是想清楚待估计的状态量，并列出动态方程、观测方程。\n关于KF与Error-State KF，请参考Bayesian Filter。\n常用符号 待估参数：\n姿态角(roll, pitch, yaw)：\n\\[ (roll, pitch, yaw) \\]\n地理位置(latitude, longitude, height)：\n\\[ ( B , L , h) \\]\nNED系速度：\n\\[ (v_N, v_E, v_D) \\]\n子午圈、卯酉圈曲率半径：\n\\[ M=\\frac{a(1-e^2)}{(1-e^2\\sin^2 B )^{3/2}} \\\\[2mm] N=\\frac{a}{(1-e^2\\sin^2 B )^{1/2}} \\]\n角速度\\(\\omega_e=15.04107deg/h\\)：\n\\[ \\begin{aligned} \\omega_{ie}^n \u0026= \\begin{pmatrix} \\omega_e\\cos B \u00260 \u0026-\\omega_e\\sin B \\end{pmatrix}^T \\\\[2mm] \\omega_{en}^n \u0026= \\begin{pmatrix} \\dot{ L }\\cos B \\\\ -\\dot{ B } \\\\ -\\dot{ L }\\sin B \\end{pmatrix} =\\begin{pmatrix} v_e/(N+h) \\\\ -v_N/(M+h) \\\\ -v_E\\tan B /(N+h) \\end{pmatrix} \\end{aligned} \\]\n重力更新：\n\\[ g=9.7803267714\\times\\left(1-2\\frac{h}{a}\\right)\\times\\frac{1+0.001931851\\sin^2L}{(1-0.006694379\\sin^2L)^{1/2}} \\]\n旋转矩阵（r/p/y for roll/pitch/yaw）：\n\\[ C_b^n = \\begin{pmatrix} \\cos(y)*\\cos(r) + \\sin(p)*\\sin(y)*\\sin(r) \u0026\\cos(r)*\\sin(p)*\\sin(y) - \\cos(y)*\\sin(r) \u0026\\cos(p)*\\sin(y) \\\\ \\cos(p)*\\sin(r) \u0026\\cos(p)*\\cos(r) \u0026-\\sin(p) \\\\ \\cos(y)*\\sin(p)*\\sin(r) - \\cos(r)*\\sin(y) \u0026\\sin(y)*\\sin(r) + \\cos(y)*\\cos(r)*\\sin(p) \u0026\\cos(p)*\\cos(y) \\end{pmatrix} \\]\n动态方程 微分方程 速度微分方程：\n\\[ \\dot{v_n} = C_b^n \\cdot f^b + g_l^n - 2\\omega_{ie}^n \\times v^n - \\omega_{en}^n \\times v^n \\]\n位置微分方程：\n\\[ \\dot{r^n}=\\begin{pmatrix} \\dot{ B } \\\\ \\dot{ L } \\\\ \\dot{h}\\end{pmatrix} =\\begin{pmatrix} \\frac{1}{M+h} \u00260 \u00260 \\\\ 0 \u0026\\frac{1}{(N+h)\\cos B } \u00260 \\\\ 0 \u00260 \u0026-1\\end{pmatrix} \\begin{pmatrix} v_N \\\\ v_E \\\\ v_D \\end{pmatrix} \\]\n姿态微分方程：\n\\[ \\begin{aligned} \\dot{q_b^n}\u0026=\\frac{1}{2}q_b^n\\otimes\\omega_{nb}^b \\\\[2mm] \u0026=\\frac{1}{2}q_b^n\\otimes\\left( \\omega_{ib}^b - (C_b^n)^T \\omega_{in}^n \\right) \\\\[2mm] \u0026=\\frac{1}{2}q_b^n\\otimes\\left( \\omega_{ib}^b - (C_b^n)^T (\\omega_{ie}^n+\\omega_{en}^n) \\right) \\end{aligned} \\]\n等价于：\n\\[ \\dot{C_b^n}=C_b^n(\\omega_{nb}^b\\times)=C_b^n(\\omega_{ib}^b\\times)-(\\omega_{in}^n\\times)C_b^n \\]\n可参考 Rotation\n更新方程 速度更新方程：\n\\[ v_k^n = v_{k-1}^n + C_{b(k-1)}^{n(k-1)} \\cdot f^b(t_k) \\cdot (t_k-t_{k-1}) +[g_l^n-(2\\omega_{ie}^n+\\omega_{en}^n)\\times v^n(t_{k-1})] \\cdot (t_k-t_{k-1}) \\]\n位置更新方程：\n\\[ r_k^n=r_{k-1}^n+0.5\\begin{pmatrix} \\frac{1}{M+h} \u00260 \u00260 \\\\0 \u0026\\frac{1}{(N+h)\\cos B } \u00260 \\\\ 0 \u00260 \u0026-1\\end{pmatrix}(v_k^n+v_{k-1}^n)\\Delta t \\]\n姿态更新方程：\n\\[ \\omega_{nb}^b=\\omega_{ib}^b-(C_b^n)^T(\\omega_{ie}^n+\\omega_{en}^n) \\\\[2mm] q_b^n(t_k)\\approx \\left(I+\\frac{1}{2}\\left(\\mathcal{R(\\omega_{nb}^b)}\\cdot(t_k-t_{k-1})\\right)\\right)q_b^n(t_{k-1}) \\]\n误差方程 速度误差方程：\n\\[ \\begin{aligned} \\delta \\dot{v^n}\u0026=F_{vr} \\cdot \\delta r^n + F_{vv} \\cdot \\delta v^n + [C_b^n \\cdot f^b]\\times\\delta\\epsilon + C_b^n \\cdot \\delta f^b \\\\[2mm] \u0026=\\begin{pmatrix} -2v_E\\omega_e\\cos B -\\frac{v_E^2}{(N+h)\\cos^2 B } \u00260 \u0026\\frac{-v_N v_D}{(M+h)^2}+\\frac{v_E^2\\tan B }{(N+h)^2} \\\\ 2\\omega_e(v_N\\cos B -v_D\\sin B ) + \\frac{v_E v_N}{(N+h)\\cos^2 B } \u00260 \u0026\\frac{-v_E v_D}{(N+h)^2}-\\frac{v_N v_E\\tan B }{(N+h)^2} \\\\ 2v_E\\omega_e\\sin B \u00260 \u0026\\frac{v_E^2}{(N+h)^2}+\\frac{v_N^2}{(M+h)^2}-\\frac{2g}{\\sqrt{MN}+h} \\end{pmatrix} \\cdot \\delta r^n \\\\[2mm] \u0026+\\begin{pmatrix} \\frac{v_D}{M+h} \u0026-2\\omega_e\\sin B - 2\\frac{v_E\\tan B }{N+h} \u0026\\frac{v_N}{M+h} \\\\ 2\\omega_e\\sin B +\\frac{v_E\\tan B }{N+h} \u0026\\frac{v_D+v_N\\tan B }{N+h} \u00262\\omega_e\\cos B +\\frac{v_E}{N+h} \\\\ -2\\frac{v_N}{M+h} \u0026-2\\omega_e\\cos B -2\\frac{v_E}{N+h} \u00260 \\end{pmatrix}\\cdot \\delta v^n + [C_b^n \\cdot f^b]\\times\\delta\\epsilon + C_b^n \\cdot \\delta f^b \\end{aligned} \\]\n位置误差方程：\n\\[ \\begin{aligned} \\delta \\dot{r^n} \u0026= F_{rr} \\delta r^n + F_{rv} \\delta v^n \\\\[2mm] \u0026=\\begin{pmatrix} 0 \u00260 \u0026\\frac{-v_N}{(M+h)^2} \\\\ \\frac{v_E\\sin B }{(N+h)\\cos^2 B } \u00260 \u0026\\frac{-v_E}{(N+h)\\cos^2 B } \\\\0 \u00260 \u00260 \\end{pmatrix}\\delta r^n +\\begin{pmatrix} \\frac{1}{M+h} \u00260 \u00260 \\\\ 0 \u0026\\frac{1}{(N+h)\\cos B } \u00260 \\\\ 0 \u00260 \u0026-1 \\end{pmatrix} \\delta v^n \\end{aligned} \\]\n姿态误差方程：\n\\[ \\begin{aligned} \\dot{\\delta\\epsilon^n} \u0026= F_{er}\\delta r^n + F_{ev} \\delta v^n -(\\omega_{in}^n\\times)\\delta\\epsilon^n -C_b^n\\delta\\omega_{ib}^b \\\\[2mm] \u0026=\\begin{pmatrix} -\\omega_e\\sin B \u00260 \u0026\\frac{-v_E}{(N+h)^2} \\\\ 0 \u00260 \u0026\\frac{v_N}{(M+h)^2} \\\\ -\\omega_e\\cos B -\\frac{v_E}{(N+h)\\cos^2 B } \u00260 \u0026\\frac{v_E\\tan B }{(N+h)^2} \\end{pmatrix} \\delta r^n + \\begin{pmatrix} 0 \u0026\\frac{1}{N+h} \u00260 \\\\ \\frac{-1}{M+h} \u00260 \u00260 \\\\ 0 \u0026\\frac{-\\tan B }{N+h} \u00260\\end{pmatrix}\\delta v^n -(\\omega_{in}^n\\times)\\delta\\epsilon^n -C_b^n\\delta\\omega_{ib}^b \\\\[2mm] \\end{aligned} \\]\n整合在一起，可得到状态方程：\n\\[ \\begin{pmatrix} \\delta \\dot{r^n} \\\\ \\delta \\dot{v^n} \\\\ \\delta \\dot{\\epsilon^n} \\end{pmatrix} =\\begin{pmatrix} F_{rr} \u0026F_{rv} \u00260 \\\\ F_{vr} \u0026F_{vv} \u0026[(C_b^n\\cdot f^b)]\\times \\\\ F_{er} \u0026F_{ev} \u0026-(\\omega_{in}^n\\times) \\end{pmatrix} \\begin{pmatrix} \\delta r^n \\\\ \\delta v^n \\\\ \\delta \\epsilon^n \\end{pmatrix} +\\begin{pmatrix} 0 \u00260 \\\\ C_b^n \u00260 \\\\ 0 \u0026-C_b^n \\end{pmatrix} \\begin{pmatrix} \\delta f^b \\\\ \\delta \\omega_{ib}^b \\end{pmatrix} \\]\n若对陀螺仪、加速度计继续进行建模，分为白噪声的观测噪声，与随机游走的零偏之和，则：\n\\[ \\delta \\omega_{ib}^b = b_g + \\omega_g \\\\ \\dot{b_g} = \\omega_{bg} \\\\[2mm] \\delta f^b = b_a + \\omega_a \\\\ \\dot{b_a} = \\omega_{ba} \\]\n则可以得到15维的状态方程：\n\\[ \\begin{pmatrix} \\delta \\dot{r^n} \\\\ \\delta \\dot{v^n} \\\\ \\delta \\dot{\\epsilon^n} \\\\ \\dot{b_g} \\\\ \\dot{b_a} \\end{pmatrix} =\\begin{pmatrix} F_{rr} \u0026F_{rv} \u00260 \u00260 \u00260 \\\\ F_{vr} \u0026F_{vv} \u0026[(C_b^n\\cdot f^b)]\\times \u00260 \u0026C_b^n \\\\ F_{er} \u0026F_{ev} \u0026-(\\omega_{in}^n\\times) \u0026-C_b^n \u00260 \\\\ 0 \u00260 \u00260 \u00260 \u00260 \\\\ 0 \u00260 \u00260 \u00260 \u00260 \\end{pmatrix} \\begin{pmatrix} \\delta r^n \\\\ \\delta v^n \\\\ \\delta \\epsilon^n \\\\ b_g \\\\ b_a \\end{pmatrix} +\\begin{pmatrix} 0 \u00260 \u00260 \u00260 \\\\ 0 \u0026C_b^n \u00260 \u00260 \\\\ -C_b^n \u00260 \u00260 \u00260 \\\\ 0 \u00260 \u00261 \u00260 \\\\ 0 \u00260 \u00260 \u00261 \\end{pmatrix} \\begin{pmatrix} \\omega_g \\\\ \\omega_a \\\\ \\omega_{bg} \\\\ \\omega_{ba} \\end{pmatrix} \\]\n计算协方差矩阵时，采用如下公式：\n\\[ F_k \\approx I + F_t \\delta t + \\frac{1}{2}(F_t \\delta t)^2 \\\\[2mm] G_k \\approx (F_k G) Q (F_k G)^T \\delta t \\]\n观测方程 GPS 零速检测 NHC约束 速度约束 特殊处理 杆臂补偿 初始化 ","PublishDate":"2020-01-16T08:00:00+08:00","ReadingTime":4,"RelPermalink":"/gps-ins/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-11T22:41:25.560732734+08:00","Mode":436,"Name":"index.md","Size":6485},"Tags":null,"Title":"GPS/INS组合导航","Type":"blog","Weight":0,"WordCount":655},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"ros-integration","Dir":"blog/sdc-engineer/ros-integration/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/sdc-engineer/ros-integration/index.md","TranslationBaseName":"index","UniqueID":"aa1d2ffc79db6e8266c3fcb11acc1124"},"FuzzyWordCount":100,"GitInfo":{"hash":"cc0154821a2e7f26725edeed6c29eb7e070d4c52","abbreviatedHash":"cc01548","subject":"add camera page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-16T21:57:43+08:00","commitDate":"2020-03-16T21:57:43+08:00"},"Kind":"page","Lastmod":"2020-03-16T21:57:43+08:00","Len":4208,"Name":"ROS Integration","Permalink":"https://nuhuo08.github.io/ros-integration/","Plain":"自动驾驶系统结构    在繁忙的工作之余，学习完这门课 Udacity - Self-Driving Car Engineer， 虽然辛苦，但是收货很多。 对无人车上配置的传感器、涉及到的功能模块、各模块之间的交互都有了大致的了解。 更有幸的是参与了自动泊车系统的研发、重构、优化等一个几乎完整的工程项目开发周期。\n毕业课程项目    Nanodegree毕业课程设计，该图包含了项目涉及到的几个ROS Node，以及系统中流动的ROS Message。\ntl_detector    根据图像信息：\n 检测是否存在红绿灯标牌 分类是红灯还是绿灯  若检测到红灯，则将最靠近停止线的waypoint的序号发送出去。\nTODO: 增加OpenCV Image Processing \u0026amp; Deep Learning跳转链接\nwaypoint_updater    生成前面一段需要跟踪的路径点，且增加了速度属性。当前方存在红灯时，会设置waypoints的速度慢慢减少到0停止。\nwaypoint_follower 采用pure pursuit算法，计算出车辆需要输出的线速度和角速度，以geometry_msgs::TwistStamped消息发送出去。\ntwist_controller    使用PID控制器，通过brake/throttle控制车辆的加减速度，使之达到期望的线速度。\n使用YawController控制器，计算打方向盘的角度。\n控制的原理可参考 Control。\n其他 该项目没有涉及路径规划、位置确定、障碍物跟踪模块。\nPlanning 实际自动驾驶中，汽车跟踪的轨迹预先是不知道的，所以不会有Waypoint Loader模块。 需要根据用户的需求，做出正确的路径规划。\n 类似于导航软件，根据用户指定的目的地，输出一条全局路径规划。 在跟踪全局路径时，需要有局部路径规划，控制车辆轨迹的平滑稳定。  路径规划的原理可参考这两篇博客：Path Planning，ROS 路径规划\nPositioning 实际车辆在运行过程中，不会精确知道自己的位姿。定位所涉及的方法有：\n GPS/INS Odometry Visual/Lidar SLAM HD Map Matching  障碍物跟踪 融合多传感器的感知结果，预测与追踪障碍物的轨迹。\n","PublishDate":"2020-01-15T08:00:00+08:00","ReadingTime":1,"RelPermalink":"/ros-integration/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-16T21:56:12.642922275+08:00","Mode":436,"Name":"index.md","Size":2835},"Tags":null,"Title":"ROS Integration","Type":"blog","Weight":0,"WordCount":58},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"loam","Dir":"blog/slam/loam/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/slam/loam/index.md","TranslationBaseName":"index","UniqueID":"c5bc709b983a8b4272919f82cd9dbdff"},"FuzzyWordCount":2700,"GitInfo":{"hash":"8acc396f7083c55ab9b23d776d9c325283c547d3","abbreviatedHash":"8acc396","subject":"add ros-integration page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-02-02T00:44:27+08:00","commitDate":"2020-02-02T11:55:15+08:00"},"Kind":"page","Lastmod":"2020-02-02T00:44:27+08:00","Len":69553,"Name":"LOAM","Permalink":"https://nuhuo08.github.io/loam/","Plain":"点云注册 坐标系统 IMU与Lidar的坐标系：x轴向前，y轴向左，z轴向上，形成右手坐标系；\nLOAM内部坐标系：z轴向前，x轴向左，y轴向上，形成右手坐标系。\n关于坐标系统与旋转，请参考Rotation。\n重力的处理 imuHandler 需要减去重力在IMU坐标系下的分量，并将坐标系统转换成LOAM内部坐标系。\n\\[ \\begin{aligned} \\begin{pmatrix} a_x \\\\ a_y \\\\ a_z \\end{pmatrix} \u0026=R_{bw} *\\begin{pmatrix} 0 \\\\ 0 \\\\ g \\\\ \\end{pmatrix} \\\\[2mm] \u0026=R_x(-roll)*R_y(-pitch)*R_z(-yaw) *\\begin{pmatrix} 0 \\\\ 0 \\\\ g \\\\ \\end{pmatrix} \\\\[2mm] \u0026=\\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 cos(roll) \u0026 sin(roll) \\\\ 0 \u0026 -sin(roll) \u0026 cos(roll) \\end{pmatrix} *\\begin{pmatrix} cos(pitch) \u0026 0 \u0026 -sin(pitch) \\\\ 0 \u0026 1 \u0026 0 \\\\ sin(pitch) \u0026 0 \u0026 cos(pitch) \\end{pmatrix} *\\begin{pmatrix} cos(yaw) \u0026 sin(yaw) \u0026 0 \\\\ -sin(yaw) \u0026 cos(yaw) \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix} *\\begin{pmatrix} 0 \\\\ 0 \\\\ g \\\\ \\end{pmatrix} \\\\[2mm] \u0026=\\begin{pmatrix} -g\\cdot sin(pitch) \\\\ g\\cdot cos(pitch)sin(roll) \\\\ g\\cdot cos(pitch)cos(roll) \\end{pmatrix} \\end{aligned} \\]\n对应于下面的代码：\nvoid imuHandler(const sensor_msgs::Imu::ConstPtr\u0026amp; imuIn) { float accX = imuIn-\u0026gt;linear_acceleration.y - sin(roll) * cos(pitch) * 9.81; float accY = imuIn-\u0026gt;linear_acceleration.z - cos(roll) * cos(pitch) * 9.81; float accZ = imuIn-\u0026gt;linear_acceleration.x + sin(pitch) * 9.81; }  AccumulateIMUShift 将IMU坐标系下的加速度转换到World坐标系下，并按照匀加速模型，估算两时间间隔内，IMU在Word坐标系下的位置和速度。\n\\[ \\begin{aligned} \\begin{pmatrix} a_x' \\\\ a_y' \\\\ a_z' \\end{pmatrix} \u0026=R_{wb} *\\begin{pmatrix} a_x \\\\ a_y \\\\ a_z \\\\ \\end{pmatrix} \\\\[2mm] \u0026=R_y(yaw)*R_x(pitch)*R_z(roll) *\\begin{pmatrix} a_x \\\\ a_y \\\\ a_z \\\\ \\end{pmatrix} \\\\[2mm] \u0026=\\begin{pmatrix} cos(yaw) \u0026 0 \u0026 sin(yaw) \\\\ 0 \u0026 1 \u0026 0 \\\\ -sin(yaw) \u0026 0 \u0026 cos(yaw) \\end{pmatrix} *\\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 cos(pitch) \u0026 -sin(pitch) \\\\ 0 \u0026 sin(pitch) \u0026 cos(pitch) \\end{pmatrix} *\\begin{pmatrix} cos(roll) \u0026 -sin(roll) \u0026 0 \\\\ sin(roll) \u0026 cos(roll) \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix} *\\begin{pmatrix} a_x \\\\ a_y \\\\ a_z \\\\ \\end{pmatrix} \\\\[2mm] \\end{aligned} \\]\nvoid AccumulateIMUShift() { float x1 = cos(roll) * accX - sin(roll) * accY; float y1 = sin(roll) * accX + cos(roll) * accY; float z1 = accZ; float x2 = x1; float y2 = cos(pitch) * y1 - sin(pitch) * z1; float z2 = sin(pitch) * y1 + cos(pitch) * z1; accX = cos(yaw) * x2 + sin(yaw) * z2; accY = y2; accZ = -sin(yaw) * x2 + cos(yaw) * z2; }  点云的处理 校准运动畸变 为了保持一次扫描过程中，点的几何关系变化不要太剧烈，我们应该保留匀速运动变化的部分，而将多余的变化量剔除掉。\n例如，当扫描仪匀速朝一面墙运动时，形成的点云仍然共面。如果存在加速运动，形成的点云有畸变，将导致不共面。\n\\[ \\begin{aligned} \\begin{pmatrix} p_x \\\\ p_y \\\\ p_z \\end{pmatrix} \u0026=R_{bw} *\\begin{pmatrix} \\Delta p_x \\\\ \\Delta p_y \\\\ \\Delta p_z \\end{pmatrix} \\\\[2mm] \u0026=R_z(-roll)*R_x(-pitch)*R_y(-yaw) *\\begin{pmatrix} \\Delta p_x \\\\ \\Delta p_y \\\\ \\Delta p_z \\end{pmatrix} \\\\[2mm] \u0026=\\begin{pmatrix} cos(roll) \u0026 sin(roll) \u0026 0 \\\\ -sin(roll) \u0026 cos(roll) \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix} *\\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 cos(pitch) \u0026 sin(pitch) \\\\ 0 \u0026 -sin(pitch) \u0026 cos(pitch) \\end{pmatrix} *\\begin{pmatrix} cos(yaw) \u0026 0 \u0026 -sin(yaw) \\\\ 0 \u0026 1 \u0026 0 \\\\ sin(yaw) \u0026 0 \u0026 cos(yaw) \\end{pmatrix} *\\begin{pmatrix} \\Delta p_x \\\\ \\Delta p_y \\\\ \\Delta p_z \\end{pmatrix} \\\\[2mm] \\end{aligned} \\]\nvoid ShiftToStartIMU(float pointTime) { imuShiftFromStartXCur = imuShiftXCur - imuShiftXStart - imuVeloXStart * pointTime; imuShiftFromStartYCur = imuShiftYCur - imuShiftYStart - imuVeloYStart * pointTime; imuShiftFromStartZCur = imuShiftZCur - imuShiftZStart - imuVeloZStart * pointTime; float x1 = cos(imuYawStart) * imuShiftFromStartXCur - sin(imuYawStart) * imuShiftFromStartZCur; float y1 = imuShiftFromStartYCur; float z1 = sin(imuYawStart) * imuShiftFromStartXCur + cos(imuYawStart) * imuShiftFromStartZCur; float x2 = x1; float y2 = cos(imuPitchStart) * y1 + sin(imuPitchStart) * z1; float z2 = -sin(imuPitchStart) * y1 + cos(imuPitchStart) * z1; imuShiftFromStartXCur = cos(imuRollStart) * x2 + sin(imuRollStart) * y2; imuShiftFromStartYCur = -sin(imuRollStart) * x2 + cos(imuRollStart) * y2; imuShiftFromStartZCur = z2; }  处理每个激光点  每个激光点是在当前IMU坐标系下 需要先转换到World坐标系下 再转到当前帧起始IMU的坐标系下 最后去除掉上一步获得的运动畸变  \\[ \\begin{aligned} \\begin{pmatrix} p_x' \\\\ p_y' \\\\ p_z' \\end{pmatrix} \u0026= R_{b'w} * R_{wb} *\\begin{pmatrix} p_x \\\\ p_y \\\\ p_z \\\\ \\end{pmatrix} \\\\[2mm] \u0026=R_z(-roll')*R_x(-pitch')*R_y(-yaw') * R_y(yaw)*R_x(pitch)*R_z(roll) *\\begin{pmatrix} p_x \\\\ p_y \\\\ p_z \\\\ \\end{pmatrix} \\\\[2mm] \\end{aligned} \\]\nvoid TransformToStartIMU(PointType *p) { float x1 = cos(imuRollCur) * p-\u0026gt;x - sin(imuRollCur) * p-\u0026gt;y; float y1 = sin(imuRollCur) * p-\u0026gt;x + cos(imuRollCur) * p-\u0026gt;y; float z1 = p-\u0026gt;z; float x2 = x1; float y2 = cos(imuPitchCur) * y1 - sin(imuPitchCur) * z1; float z2 = sin(imuPitchCur) * y1 + cos(imuPitchCur) * z1; float x3 = cos(imuYawCur) * x2 + sin(imuYawCur) * z2; float y3 = y2; float z3 = -sin(imuYawCur) * x2 + cos(imuYawCur) * z2; float x4 = cos(imuYawStart) * x3 - sin(imuYawStart) * z3; float y4 = y3; float z4 = sin(imuYawStart) * x3 + cos(imuYawStart) * z3; float x5 = x4; float y5 = cos(imuPitchStart) * y4 + sin(imuPitchStart) * z4; float z5 = -sin(imuPitchStart) * y4 + cos(imuPitchStart) * z4; p-\u0026gt;x = cos(imuRollStart) * x5 + sin(imuRollStart) * y5 + imuShiftFromStartXCur; p-\u0026gt;y = -sin(imuRollStart) * x5 + cos(imuRollStart) * y5 + imuShiftFromStartYCur; p-\u0026gt;z = z5 + imuShiftFromStartZCur; }  特征提取 曲率计算 以某点为中心，其前后各5个点，计算10个向量的和。向量的模长表示其在该点处曲率半径。\n根据曲率的大小，将点云分为/laser_cloud_sharp， /laser_cloud_less_sharp， /laser_cloud_flat， /laser_cloud_less_flat。\n剔除异常点    激光里程计 IMU坐标系统转换 转到起始IMU坐标系 点云去除了匀速运动之外的误差，现在就可以合理的假设，上一时刻的点，与当前时刻的点，只有一个匀速运动的点位畸变。 则初始的transform为：\ntransform[3] -= imuVeloFromStartX * scanPeriod; transform[4] -= imuVeloFromStartY * scanPeriod; transform[5] -= imuVeloFromStartZ * scanPeriod;  这里定义的transform比较特殊，在理解时需要特别注意。与下文2.3节的优化相对应。\n将每个激光点坐标，按照匀速运动假设，将旋转、平移的畸变量去掉，转换到IMU起始坐标系下。\n\\[ \\begin{aligned} \\begin{pmatrix} p_x' \\\\ p_y' \\\\ p_z' \\end{pmatrix} \u0026= R_{b'b} *\\begin{pmatrix} p_x - t_x \\\\ p_y - t_y \\\\ p_z - t_z \\end{pmatrix} \\\\[2mm] \u0026=R_y(-yaw)*R_x(-pitch)*R_z(-roll) *\\begin{pmatrix} p_x - t_x \\\\ p_y - t_y \\\\ p_z - t_z \\end{pmatrix} \\\\[2mm] \\end{aligned} \\]\nvoid TransformToStart(PointType const * const pi, PointType * const po) { float s = 10 * (pi-intensity - int(pi-intensity)); float rx = s * transform[0]; float ry = s * transform[1]; float rz = s * transform[2]; float tx = s * transform[3]; float ty = s * transform[4]; float tz = s * transform[5]; float x1 = cos(rz) * (pi-x - tx) + sin(rz) * (pi-y - ty); float y1 = -sin(rz) * (pi-x - tx) + cos(rz) * (pi-y - ty); float z1 = (pi-z - tz); float x2 = x1; float y2 = cos(rx) * y1 + sin(rx) * z1; float z2 = -sin(rx) * y1 + cos(rx) * z1; po-x = cos(ry) * x2 - sin(ry) * z2; po-y = y2; po-z = sin(ry) * x2 + cos(ry) * z2; po-intensity = pi-intensity; } 转到结束IMU坐标系 在处理结束后，要将这一帧的点坐标转到IMU结束时刻下，以便下一次的帧间匹配。需要进行如下步骤：\n 转到该帧IMU起始坐标系 转到该帧IMU结束坐标系 加上最后一个点对应的匀速运动之外的畸变，并转到起始World坐标系下 最后转到结束IMU坐标系下。  \\[ TODO \\]\nvoid TransformToEnd(PointType const * const pi, PointType * const po) { float s = 10 * (pi-\u0026gt;intensity - int(pi-\u0026gt;intensity)); //rotation 1  float rx = s * transform[0]; float ry = s * transform[1]; float rz = s * transform[2]; float tx = s * transform[3]; float ty = s * transform[4]; float tz = s * transform[5]; float x1 = cos(rz) * (pi-\u0026gt;x - tx) + sin(rz) * (pi-\u0026gt;y - ty); float y1 = -sin(rz) * (pi-\u0026gt;x - tx) + cos(rz) * (pi-\u0026gt;y - ty); float z1 = (pi-\u0026gt;z - tz); float x2 = x1; float y2 = cos(rx) * y1 + sin(rx) * z1; float z2 = -sin(rx) * y1 + cos(rx) * z1; float x3 = cos(ry) * x2 - sin(ry) * z2; float y3 = y2; float z3 = sin(ry) * x2 + cos(ry) * z2; //rotation 2  rx = transform[0]; ry = transform[1]; rz = transform[2]; tx = transform[3]; ty = transform[4]; tz = transform[5]; float x4 = cos(ry) * x3 + sin(ry) * z3; float y4 = y3; float z4 = -sin(ry) * x3 + cos(ry) * z3; float x5 = x4; float y5 = cos(rx) * y4 - sin(rx) * z4; float z5 = sin(rx) * y4 + cos(rx) * z4; float x6 = cos(rz) * x5 - sin(rz) * y5 + tx; float y6 = sin(rz) * x5 + cos(rz) * y5 + ty; float z6 = z5 + tz; //rotation 3  float x7 = cos(imuRollStart) * (x6 - imuShiftFromStartX) - sin(imuRollStart) * (y6 - imuShiftFromStartY); float y7 = sin(imuRollStart) * (x6 - imuShiftFromStartX) + cos(imuRollStart) * (y6 - imuShiftFromStartY); float z7 = z6 - imuShiftFromStartZ; float x8 = x7; float y8 = cos(imuPitchStart) * y7 - sin(imuPitchStart) * z7; float z8 = sin(imuPitchStart) * y7 + cos(imuPitchStart) * z7; float x9 = cos(imuYawStart) * x8 + sin(imuYawStart) * z8; float y9 = y8; float z9 = -sin(imuYawStart) * x8 + cos(imuYawStart) * z8; //rotation 4  float x10 = cos(imuYawLast) * x9 - sin(imuYawLast) * z9; float y10 = y9; float z10 = sin(imuYawLast) * x9 + cos(imuYawLast) * z9; float x11 = x10; float y11 = cos(imuPitchLast) * y10 + sin(imuPitchLast) * z10; float z11 = -sin(imuPitchLast) * y10 + cos(imuPitchLast) * z10; po-\u0026gt;x = cos(imuRollLast) * x11 + sin(imuRollLast) * y11; po-\u0026gt;y = -sin(imuRollLast) * x11 + cos(imuRollLast) * y11; po-\u0026gt;z = z11; po-\u0026gt;intensity = int(pi-\u0026gt;intensity); }  IMU累计 AccumulateRotation 代码直接实现了将两个旋转量累加起来，得到累加后的欧拉角。代码实现效率高，但是不易读。 将旋转矩阵展开以后可以看到其相应关系。\nRwb1 = Ry(y1) * Rx(x1) * Rz(z1); Rbw2 = Ry(y2) * Rx(x2) * Rz(z2); Rwb3 = Rwb1 * Rbw2 = [ cos(y)*cos(z) + sin(x)*sin(y)*sin(z), cos(z)*sin(x)*sin(y) - cos(y)*sin(z), cos(x)*sin(y)] [ cos(x)*sin(z), cos(x)*cos(z), -sin(x)] [ cos(y)*sin(x)*sin(z) - cos(z)*sin(y), sin(y)*sin(z) + cos(y)*cos(z)*sin(x), cos(x)*cos(y)] = [ (cos(y1)*cos(z1) + sin(x1)*sin(y1)*sin(z1))*(cos(y2)*cos(z2) + sin(x2)*sin(y2)*sin(z2)) - cos(x1)*sin(y1)*(cos(z2)*sin(y2) - cos(y2)*sin(x2)*sin(z2)) - cos(x2)*sin(z2)*(cos(y1)*sin(z1) - cos(z1)*sin(x1)*sin(y1)), cos(x1)*sin(y1)*(sin(y2)*sin(z2) + cos(y2)*cos(z2)*sin(x2)) - cos(x2)*cos(z2)*(cos(y1)*sin(z1) - cos(z1)*sin(x1)*sin(y1)) - (cos(y1)*cos(z1) + sin(x1)*sin(y1)*sin(z1))*(cos(y2)*sin(z2) - cos(z2)*sin(x2)*sin(y2)), sin(x2)*(cos(y1)*sin(z1) - cos(z1)*sin(x1)*sin(y1)) + cos(x2)*sin(y2)*(cos(y1)*cos(z1) + sin(x1)*sin(y1)*sin(z1)) + cos(x1)*cos(x2)*cos(y2)*sin(y1)] [ sin(x1)*(cos(z2)*sin(y2) - cos(y2)*sin(x2)*sin(z2)) + cos(x1)*sin(z1)*(cos(y2)*cos(z2) + sin(x2)*sin(y2)*sin(z2)) + cos(x1)*cos(x2)*cos(z1)*sin(z2), cos(x1)*cos(x2)*cos(z1)*cos(z2) - cos(x1)*sin(z1)*(cos(y2)*sin(z2) - cos(z2)*sin(x2)*sin(y2)) - sin(x1)*(sin(y2)*sin(z2) + cos(y2)*cos(z2)*sin(x2)), cos(x1)*cos(x2)*sin(y2)*sin(z1) - cos(x1)*cos(z1)*sin(x2) - cos(x2)*cos(y2)*sin(x1)] [ cos(x2)*sin(z2)*(sin(y1)*sin(z1) + cos(y1)*cos(z1)*sin(x1)) - cos(x1)*cos(y1)*(cos(z2)*sin(y2) - cos(y2)*sin(x2)*sin(z2)) - (cos(z1)*sin(y1) - cos(y1)*sin(x1)*sin(z1))*(cos(y2)*cos(z2) + sin(x2)*sin(y2)*sin(z2)), (cos(z1)*sin(y1) - cos(y1)*sin(x1)*sin(z1))*(cos(y2)*sin(z2) - cos(z2)*sin(x2)*sin(y2)) + cos(x1)*cos(y1)*(sin(y2)*sin(z2) + cos(y2)*cos(z2)*sin(x2)) + cos(x2)*cos(z2)*(sin(y1)*sin(z1) + cos(y1)*cos(z1)*sin(x1)), cos(x1)*cos(x2)*cos(y1)*cos(y2) - cos(x2)*sin(y2)*(cos(z1)*sin(y1) - cos(y1)*sin(x1)*sin(z1)) - sin(x2)*(sin(y1)*sin(z1) + cos(y1)*cos(z1)*sin(x1))] 可以看到，代码与上面的公式是一一对应的。\nvoid AccumulateRotation(float cx, float cy, float cz, float lx, float ly, float lz, float \u0026amp;ox, float \u0026amp;oy, float \u0026amp;oz) { float srx = cos(lx)*cos(cx)*sin(ly)*sin(cz) - cos(cx)*cos(cz)*sin(lx) - cos(lx)*cos(ly)*sin(cx); ox = -asin(srx); float srycrx = sin(lx)*(cos(cy)*sin(cz) - cos(cz)*sin(cx)*sin(cy)) + cos(lx)*sin(ly)*(cos(cy)*cos(cz) + sin(cx)*sin(cy)*sin(cz)) + cos(lx)*cos(ly)*cos(cx)*sin(cy); float crycrx = cos(lx)*cos(ly)*cos(cx)*cos(cy) - cos(lx)*sin(ly)*(cos(cz)*sin(cy) - cos(cy)*sin(cx)*sin(cz)) - sin(lx)*(sin(cy)*sin(cz) + cos(cy)*cos(cz)*sin(cx)); oy = atan2(srycrx / cos(ox), crycrx / cos(ox)); float srzcrx = sin(cx)*(cos(lz)*sin(ly) - cos(ly)*sin(lx)*sin(lz)) + cos(cx)*sin(cz)*(cos(ly)*cos(lz) + sin(lx)*sin(ly)*sin(lz)) + cos(lx)*cos(cx)*cos(cz)*sin(lz); float crzcrx = cos(lx)*cos(lz)*cos(cx)*cos(cz) - cos(cx)*sin(cz)*(cos(ly)*sin(lz) - cos(lz)*sin(lx)*sin(ly)) - sin(cx)*(sin(ly)*sin(lz) + cos(ly)*cos(lz)*sin(lx)); oz = atan2(srzcrx / cos(ox), crzcrx / cos(ox)); }  PluginIMURotation \\[ R_x = R_{Last} * R_{Start}^{-1} * R_x \\]\nR1 = Ry(alz) * Rx(alx) * Rz(aly); R2 = Rz(-bly) * Rx(-blx) * Ry(-blz); R3 = Ry(bcz) * Rx(bcx) * Rz(bcy); R = R1 * R2 * R3 = [ cos(y)*cos(z) + sin(x)*sin(y)*sin(z), cos(z)*sin(x)*sin(y) - cos(y)*sin(z), cos(x)*sin(y)] [ cos(x)*sin(z), cos(x)*cos(z), -sin(x)] [ cos(y)*sin(x)*sin(z) - cos(z)*sin(y), sin(y)*sin(z) + cos(y)*cos(z)*sin(x), cos(x)*cos(y)] = [ (cos(bcy)*sin(bcz) - cos(bcz)*sin(bcx)*sin(bcy))*((cos(aly)*cos(alz) + sin(alx)*sin(aly)*sin(alz))*(cos(bly)*sin(blz) - cos(blz)*sin(blx)*sin(bly)) + (cos(alz)*sin(aly) - cos(aly)*sin(alx)*sin(alz))*(sin(bly)*sin(blz) + cos(bly)*cos(blz)*sin(blx)) - cos(alx)*cos(blx)*cos(blz)*sin(alz)) + (cos(bcy)*cos(bcz) + sin(bcx)*sin(bcy)*sin(bcz))*((cos(aly)*cos(alz) + sin(alx)*sin(aly)*sin(alz))*(cos(bly)*cos(blz) + sin(blx)*sin(bly)*sin(blz)) + (cos(alz)*sin(aly) - cos(aly)*sin(alx)*sin(alz))*(cos(blz)*sin(bly) - cos(bly)*sin(blx)*sin(blz)) + cos(alx)*cos(blx)*sin(alz)*sin(blz)) - cos(bcx)*sin(bcy)*(cos(blx)*cos(bly)*(cos(alz)*sin(aly) - cos(aly)*sin(alx)*sin(alz)) - cos(blx)*sin(bly)*(cos(aly)*cos(alz) + sin(alx)*sin(aly)*sin(alz)) + cos(alx)*sin(alz)*sin(blx)), - (sin(bcy)*sin(bcz) + cos(bcy)*cos(bcz)*sin(bcx))*((cos(aly)*cos(alz) + sin(alx)*sin(aly)*sin(alz))*(cos(bly)*sin(blz) - cos(blz)*sin(blx)*sin(bly)) + (cos(alz)*sin(aly) - cos(aly)*sin(alx)*sin(alz))*(sin(bly)*sin(blz) + cos(bly)*cos(blz)*sin(blx)) - cos(alx)*cos(blx)*cos(blz)*sin(alz)) - (cos(bcz)*sin(bcy) - cos(bcy)*sin(bcx)*sin(bcz))*((cos(aly)*cos(alz) + sin(alx)*sin(aly)*sin(alz))*(cos(bly)*cos(blz) + sin(blx)*sin(bly)*sin(blz)) + (cos(alz)*sin(aly) - cos(aly)*sin(alx)*sin(alz))*(cos(blz)*sin(bly) - cos(bly)*sin(blx)*sin(blz)) + cos(alx)*cos(blx)*sin(alz)*sin(blz)) - cos(bcx)*cos(bcy)*(cos(blx)*cos(bly)*(cos(alz)*sin(aly) - cos(aly)*sin(alx)*sin(alz)) - cos(blx)*sin(bly)*(cos(aly)*cos(alz) + sin(alx)*sin(aly)*sin(alz)) + cos(alx)*sin(alz)*sin(blx)), sin(bcx)*(cos(blx)*cos(bly)*(cos(alz)*sin(aly) - cos(aly)*sin(alx)*sin(alz)) - cos(blx)*sin(bly)*(cos(aly)*cos(alz) + sin(alx)*sin(aly)*sin(alz)) + cos(alx)*sin(alz)*sin(blx)) - cos(bcx)*cos(bcz)*((cos(aly)*cos(alz) + sin(alx)*sin(aly)*sin(alz))*(cos(bly)*sin(blz) - cos(blz)*sin(blx)*sin(bly)) + (cos(alz)*sin(aly) - cos(aly)*sin(alx)*sin(alz))*(sin(bly)*sin(blz) + cos(bly)*cos(blz)*sin(blx)) - cos(alx)*cos(blx)*cos(blz)*sin(alz)) + cos(bcx)*sin(bcz)*((cos(aly)*cos(alz) + sin(alx)*sin(aly)*sin(alz))*(cos(bly)*cos(blz) + sin(blx)*sin(bly)*sin(blz)) + (cos(alz)*sin(aly) - cos(aly)*sin(alx)*sin(alz))*(cos(blz)*sin(bly) - cos(bly)*sin(blx)*sin(blz)) + cos(alx)*cos(blx)*sin(alz)*sin(blz))] [ (cos(bcy)*sin(bcz) - cos(bcz)*sin(bcx)*sin(bcy))*(cos(alx)*sin(aly)*(cos(bly)*sin(blz) - cos(blz)*sin(blx)*sin(bly)) - cos(alx)*cos(aly)*(sin(bly)*sin(blz) + cos(bly)*cos(blz)*sin(blx)) + cos(blx)*cos(blz)*sin(alx)) - (cos(bcy)*cos(bcz) + sin(bcx)*sin(bcy)*sin(bcz))*(cos(alx)*cos(aly)*(cos(blz)*sin(bly) - cos(bly)*sin(blx)*sin(blz)) - cos(alx)*sin(aly)*(cos(bly)*cos(blz) + sin(blx)*sin(bly)*sin(blz)) + cos(blx)*sin(alx)*sin(blz)) + cos(bcx)*sin(bcy)*(sin(alx)*sin(blx) + cos(alx)*cos(aly)*cos(blx)*cos(bly) + cos(alx)*cos(blx)*sin(aly)*sin(bly)), (cos(bcz)*sin(bcy) - cos(bcy)*sin(bcx)*sin(bcz))*(cos(alx)*cos(aly)*(cos(blz)*sin(bly) - cos(bly)*sin(blx)*sin(blz)) - cos(alx)*sin(aly)*(cos(bly)*cos(blz) + sin(blx)*sin(bly)*sin(blz)) + cos(blx)*sin(alx)*sin(blz)) - (sin(bcy)*sin(bcz) + cos(bcy)*cos(bcz)*sin(bcx))*(cos(alx)*sin(aly)*(cos(bly)*sin(blz) - cos(blz)*sin(blx)*sin(bly)) - cos(alx)*cos(aly)*(sin(bly)*sin(blz) + cos(bly)*cos(blz)*sin(blx)) + cos(blx)*cos(blz)*sin(alx)) + cos(bcx)*cos(bcy)*(sin(alx)*sin(blx) + cos(alx)*cos(aly)*cos(blx)*cos(bly) + cos(alx)*cos(blx)*sin(aly)*sin(bly)), - sin(bcx)*(sin(alx)*sin(blx) + cos(alx)*cos(aly)*cos(blx)*cos(bly) + cos(alx)*cos(blx)*sin(aly)*sin(bly)) - cos(bcx)*cos(bcz)*(cos(alx)*sin(aly)*(cos(bly)*sin(blz) - cos(blz)*sin(blx)*sin(bly)) - cos(alx)*cos(aly)*(sin(bly)*sin(blz) + cos(bly)*cos(blz)*sin(blx)) + cos(blx)*cos(blz)*sin(alx)) - cos(bcx)*sin(bcz)*(cos(alx)*cos(aly)*(cos(blz)*sin(bly) - cos(bly)*sin(blx)*sin(blz)) - cos(alx)*sin(aly)*(cos(bly)*cos(blz) + sin(blx)*sin(bly)*sin(blz)) + cos(blx)*sin(alx)*sin(blz))] [ - (cos(bcy)*sin(bcz) - cos(bcz)*sin(bcx)*sin(bcy))*((sin(aly)*sin(alz) + cos(aly)*cos(alz)*sin(alx))*(sin(bly)*sin(blz) + cos(bly)*cos(blz)*sin(blx)) + (cos(aly)*sin(alz) - cos(alz)*sin(alx)*sin(aly))*(cos(bly)*sin(blz) - cos(blz)*sin(blx)*sin(bly)) + cos(alx)*cos(alz)*cos(blx)*cos(blz)) - (cos(bcy)*cos(bcz) + sin(bcx)*sin(bcy)*sin(bcz))*((sin(aly)*sin(alz) + cos(aly)*cos(alz)*sin(alx))*(cos(blz)*sin(bly) - cos(bly)*sin(blx)*sin(blz)) + (cos(aly)*sin(alz) - cos(alz)*sin(alx)*sin(aly))*(cos(bly)*cos(blz) + sin(blx)*sin(bly)*sin(blz)) - cos(alx)*cos(alz)*cos(blx)*sin(blz)) - cos(bcx)*sin(bcy)*(cos(blx)*sin(bly)*(cos(aly)*sin(alz) - cos(alz)*sin(alx)*sin(aly)) - cos(blx)*cos(bly)*(sin(aly)*sin(alz) + cos(aly)*cos(alz)*sin(alx)) + cos(alx)*cos(alz)*sin(blx)), (sin(bcy)*sin(bcz) + cos(bcy)*cos(bcz)*sin(bcx))*((sin(aly)*sin(alz) + cos(aly)*cos(alz)*sin(alx))*(sin(bly)*sin(blz) + cos(bly)*cos(blz)*sin(blx)) + (cos(aly)*sin(alz) - cos(alz)*sin(alx)*sin(aly))*(cos(bly)*sin(blz) - cos(blz)*sin(blx)*sin(bly)) + cos(alx)*cos(alz)*cos(blx)*cos(blz)) + (cos(bcz)*sin(bcy) - cos(bcy)*sin(bcx)*sin(bcz))*((sin(aly)*sin(alz) + cos(aly)*cos(alz)*sin(alx))*(cos(blz)*sin(bly) - cos(bly)*sin(blx)*sin(blz)) + (cos(aly)*sin(alz) - cos(alz)*sin(alx)*sin(aly))*(cos(bly)*cos(blz) + sin(blx)*sin(bly)*sin(blz)) - cos(alx)*cos(alz)*cos(blx)*sin(blz)) - cos(bcx)*cos(bcy)*(cos(blx)*sin(bly)*(cos(aly)*sin(alz) - cos(alz)*sin(alx)*sin(aly)) - cos(blx)*cos(bly)*(sin(aly)*sin(alz) + cos(aly)*cos(alz)*sin(alx)) + cos(alx)*cos(alz)*sin(blx)), sin(bcx)*(cos(blx)*sin(bly)*(cos(aly)*sin(alz) - cos(alz)*sin(alx)*sin(aly)) - cos(blx)*cos(bly)*(sin(aly)*sin(alz) + cos(aly)*cos(alz)*sin(alx)) + cos(alx)*cos(alz)*sin(blx)) + cos(bcx)*cos(bcz)*((sin(aly)*sin(alz) + cos(aly)*cos(alz)*sin(alx))*(sin(bly)*sin(blz) + cos(bly)*cos(blz)*sin(blx)) + (cos(aly)*sin(alz) - cos(alz)*sin(alx)*sin(aly))*(cos(bly)*sin(blz) - cos(blz)*sin(blx)*sin(bly)) + cos(alx)*cos(alz)*cos(blx)*cos(blz)) - cos(bcx)*sin(bcz)*((sin(aly)*sin(alz) + cos(aly)*cos(alz)*sin(alx))*(cos(blz)*sin(bly) - cos(bly)*sin(blx)*sin(blz)) + (cos(aly)*sin(alz) - cos(alz)*sin(alx)*sin(aly))*(cos(bly)*cos(blz) + sin(blx)*sin(bly)*sin(blz)) - cos(alx)*cos(alz)*cos(blx)*sin(blz))] （这个函数的作用后面还要研究下。\\(z\\)轴和\\(y\\)轴要互换以后，才跟代码对的上）\n虽然直接求解效率高，但是可读性实在太差。通过矩阵的展开、对比、分析，发现与代码一一对应。 例如srx与\\(R(2,3)\\)是相对应的。\nvoid PluginIMURotation(float bcx, float bcy, float bcz, float blx, float bly, float blz, float alx, float aly, float alz, float \u0026amp;acx, float \u0026amp;acy, float \u0026amp;acz) { float srx = -sbcx*(salx*sblx + calx*caly*cblx*cbly + calx*cblx*saly*sbly) - cbcx*cbcz*(calx*saly*(cbly*sblz - cblz*sblx*sbly) - calx*caly*(sbly*sblz + cbly*cblz*sblx) + cblx*cblz*salx) - cbcx*sbcz*(calx*caly*(cblz*sbly - cbly*sblx*sblz) - calx*saly*(cbly*cblz + sblx*sbly*sblz) + cblx*salx*sblz); acx = -asin(srx); float srycrx = (cbcy*sbcz - cbcz*sbcx*sbcy)*(calx*saly*(cbly*sblz - cblz*sblx*sbly) - calx*caly*(sbly*sblz + cbly*cblz*sblx) + cblx*cblz*salx) - (cbcy*cbcz + sbcx*sbcy*sbcz)*(calx*caly*(cblz*sbly - cbly*sblx*sblz) - calx*saly*(cbly*cblz + sblx*sbly*sblz) + cblx*salx*sblz) + cbcx*sbcy*(salx*sblx + calx*caly*cblx*cbly + calx*cblx*saly*sbly); float crycrx = (cbcz*sbcy - cbcy*sbcx*sbcz)*(calx*caly*(cblz*sbly - cbly*sblx*sblz) - calx*saly*(cbly*cblz + sblx*sbly*sblz) + cblx*salx*sblz) - (sbcy*sbcz + cbcy*cbcz*sbcx)*(calx*saly*(cbly*sblz - cblz*sblx*sbly) - calx*caly*(sbly*sblz + cbly*cblz*sblx) + cblx*cblz*salx) + cbcx*cbcy*(salx*sblx + calx*caly*cblx*cbly + calx*cblx*saly*sbly); acy = atan2(srycrx / cos(acx), crycrx / cos(acx)); float srzcrx = sbcx*(cblx*cbly*(calz*saly - caly*salx*salz) - cblx*sbly*(caly*calz + salx*saly*salz) + calx*salz*sblx) - cbcx*cbcz*((caly*calz + salx*saly*salz)*(cbly*sblz - cblz*sblx*sbly) + (calz*saly - caly*salx*salz)*(sbly*sblz + cbly*cblz*sblx) - calx*cblx*cblz*salz) + cbcx*sbcz*((caly*calz + salx*saly*salz)*(cbly*cblz + sblx*sbly*sblz) + (calz*saly - caly*salx*salz)*(cblz*sbly - cbly*sblx*sblz) + calx*cblx*salz*sblz); float crzcrx = sbcx*(cblx*sbly*(caly*salz - calz*salx*saly) - cblx*cbly*(saly*salz + caly*calz*salx) + calx*calz*sblx) + cbcx*cbcz*((saly*salz + caly*calz*salx)*(sbly*sblz + cbly*cblz*sblx) + (caly*salz - calz*salx*saly)*(cbly*sblz - cblz*sblx*sbly) + calx*calz*cblx*cblz) - cbcx*sbcz*((saly*salz + caly*calz*salx)*(cblz*sbly - cbly*sblx*sblz) + (caly*salz - calz*salx*saly)*(cbly*cblz + sblx*sbly*sblz) - calx*calz*cblx*sblz); acz = atan2(srzcrx / cos(acx), crzcrx / cos(acx)); }  观测方程 \\[ d=D(p_1) \\\\[2mm] p_1 = s R (p_2 - s t) \\]\n其中\\(D(\\cdot)\\)对应于下面介绍的点线方程和点面方程；\\(R\\)旋转矩阵中包括待估的3个欧拉角\\(\\alpha,\\beta,\\gamma\\)，\\(t\\)包括3个平移量\\(x,y,z\\)。 残差\\(d\\)与待估参数\\(X\\)的关系：\n\\[ \\frac{\\partial d}{\\partial X} = \\frac{\\partial d}{\\partial p_1} \\cdot \\frac{\\partial p_1}{\\partial X} \\]\n其中待估变量\\( X = \\begin{bmatrix} \\alpha \u0026\\beta \u0026\\gamma \u0026x \u0026y \u0026z \\end{bmatrix}^T \\)\n以\\(\\alpha\\)为例，推导Jacobian：\n\\[ \\begin{aligned} \\frac{\\partial p_1}{\\partial \\alpha} \u0026= \\frac{\\partial R}{\\partial \\alpha} \\cdot s(p_2-st) \\\\[2mm] \u0026=\\frac{\\partial \\left(R_y(-\\beta)*R_x(-\\alpha)*R_z(-\\gamma)\\right)}{\\partial \\alpha} \\cdot s(p_2-st) \\\\[2mm] \u0026= \\begin{pmatrix} -s\\cos(\\alpha s)*\\sin(\\beta s)*\\sin(\\gamma s) \u0026 s\\cos(\\alpha s)*\\cos(\\gamma s)*\\sin(\\beta s) \u0026 s\\sin(\\alpha s)*\\sin(\\beta s) \\\\ s\\sin(\\alpha s)*\\sin(\\gamma s) \u0026 -s\\cos(\\gamma s)*\\sin(\\alpha s) \u0026 s\\cos(\\alpha s) \\\\ s\\cos(\\alpha s)*\\cos(\\beta s)*\\sin(\\gamma s) \u0026 -s\\cos(\\alpha s)*\\cos(\\beta s)*\\cos(\\gamma s) \u0026 -s\\cos(\\beta s)*\\sin(\\alpha s) \\end{pmatrix} \\cdot s(p_2-st) \\end{aligned} \\]\n可以看到，上面的公式跟Lidar Odometry文件里面的\\(arx\\)是完全吻合的。对\\(\\beta\\)和\\(\\gamma\\)的求导思路完全一样，这里略去。\nfloat srx = sin(s * transform[0]); float crx = cos(s * transform[0]); float sry = sin(s * transform[1]); float cry = cos(s * transform[1]); float srz = sin(s * transform[2]); float crz = cos(s * transform[2]); float tx = s * transform[3]; float ty = s * transform[4]; float tz = s * transform[5]; float arx = (-s*crx*sry*srz*pointOri.x + s*crx*crz*sry*pointOri.y + s*srx*sry*pointOri.z + s*tx*crx*sry*srz - s*ty*crx*crz*sry - s*tz*srx*sry) * coeff.x + (s*srx*srz*pointOri.x - s*crz*srx*pointOri.y + s*crx*pointOri.z + s*ty*crz*srx - s*tz*crx - s*tx*srx*srz) * coeff.y + (s*crx*cry*srz*pointOri.x - s*crx*cry*crz*pointOri.y - s*cry*srx*pointOri.z + s*tz*cry*srx + s*ty*crx*cry*crz - s*tx*crx*cry*srz) * coeff.z;  论文中是优化轴角，而代码中是直接优化欧拉角。 按道理来说，每个点应该按照其所在的位置不同，将s设置为不同的比率，按照论文的思路也应该设置为不同的值。\n而代码中将s始终设置为1，可能是因为对Lidar Odometry的精度要求不高？后面的Lidar Mapping会进一步优化坐标。\nTODO：后面将进一步补充针对轴角做优化的公式。\n接下来分析\\(\\partial d/\\partial p_1\\)的计算过程。\n   点线方程 假设点\\(A(x_1,y_1)\\)与点\\(B(x_2,y_2)\\)构成一条直线，求点\\(O(x_0,y_0)\\)到直线\\(AB\\)的距离，则：\n\\[ d=D(O,AB) \\\\[2mm] =\\frac{\\|OA\\times OB\\|}{\\|AB\\|} \\\\[2mm] \\]\n直接将上式进行代数展开，并以\\(x\\)为例，求其Jacobian矩阵如下：\n (y1 - y2) #1 + (z1 - z2) #2 ------------------------------------------------------------------ 2 2 2 2 2 2 sqrt(#1 + #2 + #3 ) sqrt((x1 - x2) + (y1 - y2) + (z1 - z2) ) where: #1 == (x0 - x1) (y0 - y2) - (x0 - x2) (y0 - y1) #2 == (x0 - x1) (z0 - z2) - (x0 - x2) (z0 - z1) #3 == (y0 - y1) (z0 - z2) - (y0 - y2) (z0 - z1) 与代码也完全对应：\nfloat a012 = sqrt(((x0 - x1)*(y0 - y2) - (x0 - x2)*(y0 - y1)) * ((x0 - x1)*(y0 - y2) - (x0 - x2)*(y0 - y1)) + ((x0 - x1)*(z0 - z2) - (x0 - x2)*(z0 - z1)) * ((x0 - x1)*(z0 - z2) - (x0 - x2)*(z0 - z1)) + ((y0 - y1)*(z0 - z2) - (y0 - y2)*(z0 - z1)) * ((y0 - y1)*(z0 - z2) - (y0 - y2)*(z0 - z1))); float l12 = sqrt((x1 - x2)*(x1 - x2) + (y1 - y2)*(y1 - y2) + (z1 - z2)*(z1 - z2)); float la = ((y1 - y2)*((x0 - x1)*(y0 - y2) - (x0 - x2)*(y0 - y1)) + (z1 - z2)*((x0 - x1)*(z0 - z2) - (x0 - x2)*(z0 - z1))) / a012 / l12;  点面方程 \\[ d=D(O,ABC) \\\\[2mm] =\\frac{(AB\\times AC)\\cdot OA}{\\|AB \\times AC\\|} \\\\[2mm] \\]\n将数据进行代数展开，对点坐标求Jacobian，与代码也完全对应。\n建图 将地图中与当前帧有重叠的部分取出来，用KD-Tree保存。并进行滤波处理，减少计算量。 再寻找最邻近的5个点，对点云协方差矩阵进行主成分分析：\n 若这五个点分布在直线上，协方差矩阵的特征值包含一个元素显著大于其余两个，与该特征值相关的特征向量表示所处直线的方向； 若这五个点分布在平面上，协方差矩阵的特征值存在一个显著小的元素，与该特征值相关的特征向量表示所处平面的法线方向。  \\[ d=D(p_w) \\\\[2mm] \\begin{aligned} p_w \u0026= R p_L + t \\\\[2mm] \u0026=\\left(R_y(\\beta)*R_x(\\alpha)*R_z(\\gamma)\\right) \\cdot p_L + t \\\\[2mm] \\end{aligned} \\]\n以\\(\\alpha\\)为例，推导Jacobian：\n\\[ \\begin{aligned} \\frac{\\partial p_w}{\\partial \\alpha} \u0026= \\frac{\\partial R}{\\partial \\alpha} \\cdot p_L \\\\[2mm] \u0026=\\frac{\\partial \\left(R_y(\\beta)*R_x(\\alpha)*R_z(\\gamma)\\right)}{\\partial \\alpha} \\cdot p_L \\\\[2mm] \u0026= \\begin{pmatrix} \\cos(\\alpha)*\\sin(\\beta)*\\sin(\\gamma)\u0026 \\cos(\\alpha)*\\cos(\\gamma)*\\sin(\\beta)\u0026 -\\sin(\\alpha)*\\sin(\\beta) \\\\ -\\sin(\\alpha)*\\sin(\\gamma)\u0026 -\\cos(\\gamma)*\\sin(\\alpha)\u0026 -\\cos(\\alpha) \\\\ \\cos(\\alpha)*\\cos(\\beta)*\\sin(\\gamma)\u0026 \\cos(\\alpha)*\\cos(\\beta)*\\cos(\\gamma)\u0026 -\\cos(\\beta)*\\sin(\\alpha) \\end{pmatrix} \\cdot p_L \\end{aligned} \\]\n优化过程与Lidar Odometry基本类似，不再赘述。\n","PublishDate":"2020-01-14T08:00:00+08:00","ReadingTime":13,"RelPermalink":"/loam/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-02T11:55:15.241889061+08:00","Mode":436,"Name":"index.md","Size":29827},"Tags":null,"Title":"LOAM","Type":"blog","Weight":0,"WordCount":2691},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"rtk","Dir":"blog/gps/rtk/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/gps/rtk/index.md","TranslationBaseName":"index","UniqueID":"675c659dc2189b03d568a8307621398f"},"FuzzyWordCount":500,"GitInfo":{"hash":"15fa8bfe9b2760e4820778082bd992905caa6169","abbreviatedHash":"15fa8bf","subject":"update","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-01-30T11:47:38+08:00","commitDate":"2020-02-02T11:55:14+08:00"},"Kind":"page","Lastmod":"2020-01-30T11:47:38+08:00","Len":9962,"Name":"GNSS定位原理","Permalink":"https://nuhuo08.github.io/rtk/","Plain":"数据文件介绍 观测文件 观测文件记录了该观测站能够观测到的卫星及其对应的伪距、载波观测值。\n 01 9 4 9 40 0.0000000 0 7G 1G 4G 7G13G20G24G25 20532012.14648 20532011.55846 20532016.22546 107896448.4014 84075170.1284 -702.033 -547.047 21255524.69947 21255524.94445 21255529.02045 111698540.8774 87037834.1244 799.589 623.056 24648794.02245 24648792.88941 24648801.63741 129530300.6484 100932694.9344 -3425.352 -2669.144 21267718.45748 21267718.52445 21267722.00945 111762613.2534 87087766.9504 1911.882 1489.773 21900010.88847 21900009.74444 21900015.95344 115085325.1934 89676892.5064 -3011.439 -2346.579 23828505.41246 23828504.07842 23828511.81542 125219643.5474 97573763.5014 2743.177 2137.544 24104647.59546 24104646.97742 24104654.81342 126670763.8784 98704504.1444 -2800.638 -2182.275  导航文件 导航文件用来计算卫星在某一时刻的位置。\n 7 01 9 4 9 59 44.0 .394901260734D-03 .387672116631D-10 .000000000000D+00 .228000000000D+03 -.138750000000D+02 .543415492579D-08 -.101085380239D+01 -.417232513428D-06 .120551300934D-01 .368431210518D-05 .515375120926D+04 .208784000000D+06 .931322574615D-08 -.123603373253D+01 .264495611191D-06 .944765906161D+00 .300218750000D+03 -.199943296834D+01 -.870929134837D-08 -.653598653579D-10 .000000000000D+00 .113000000000D+04 .000000000000D+00 .200000000000D+01 .000000000000D+00 -.186264514923D-08 .228000000000D+03 .208799000000D+06  RTCM \u0026amp; Ntrip RTCM标准定义了参考站与移动接收机之间的通信协议。根据这个协议，可以从一串二进制实时数据流中，解译出改正数据、参考站观测值等。 下面是一段rtcm v2.3的数据样例：\n00000c00: 7f7f 5f4c 7654 7e47 404a 7f7f 5f63 645c .._LvT~G@J.._cd\\ 00000c10: 7c47 404d 7f7f 6f50 5e63 4178 7f5e 7f7f |G@M..oP^cAx.^.. 00000c20: 5f76 5473 4278 7f59 7f7f 5f7c 6d74 7c47 _vTsBx.Y.._|mt|G 00000c30: 4078 4040 6058 4153 4378 7f51 7f7f 6f6a @x@@`XASCx.Q..oj 00000c40: 594b 4078 7f7d 4040 707e 7d6c 7f47 4054 YK@x.}@@p~}l.G@T 00000c50: 7f7f 4f60 730d 0a59 767c 7f6f 5b72 6c61 ..O`s..Yv|.o[rla 00000c60: 6a56 5e6a 7f63 7c6c 7370 7a51 6e68 6462 jV^j.c|lspzQnhdb 00000c70: 546e 535b 5d62 406f 7242 6353 6c40 4d7b TnS[]b@orBcSl@M{ 00000c80: 7a5e 7647 6351 4c7f 6c43 5e73 7378 4c75 z^vGcQL.lC^ssxLu 00000c90: 535b 637b 7a55 7862 746c 7370 7454 5249 S[c{zUxbtlsptTRI 00000ca0: 4c57 5373 6c68 6f74 7863 7e55 4b50 6c70 LWSslhotxc~UKPlp Ntrip表示\u0026quot;Networked Transport for RTCM via Internet Protocol\u0026quot;。 通过因特网，例如通过手机卡上网，连接CORS服务器，并按照Ntrip规定的格式，请求所需要的改正数据，服务器便发送一串二进制实时数据流过来。\nGET /RTCM23 HTTP/1.0 User-Agent: NTRIP GNSSInternetRadio/1.4.10 Accept: */* Connection: close Authorization: Basic VXNlcjpQd2Q= NMEA NMEAS is a simple standard composed of a serial communication protocol and an ASCII messages, transmitted from a source to a series of destinies. 简而言之，NMEA就是一串文本格式的GPS定位结果等相关信息。\n$GPGGA,230331,3115.27393,N,12133.89226,E,1,09,1.0,19.31,M,1,M,,*7F 其他文件 各种高精度的误差改正文件，结合误差模型，能够将误差的影响尽量削弱。 本文仅介绍到短基线RTK，对于长基线的RTK误差估计、精密单点定位PPP需要考虑的其他误差模型， 可参考Interfaces and Protocols。\n观测方程 对于某一测站，已知测站到各个卫星的距离，各个卫星的坐标，待估参数为测站的坐标\\(X\\)，与测站的时钟误差\\(t\\)。\n单点定位 有如下关系：\n\\[ \\begin{aligned} P_r^i \u0026= \\rho_r^i + I_r^i + T_r^i + ct_r + \\epsilon_r^i \\\\ \u0026=\\sqrt{(x_r-x^s)^2+(y_r-y^s)^2+(z_r-z^s)^2} + I_r^i + T_r^i + ct_r + \\epsilon_r^i \\\\ \u0026=( \\rho_{r,0}^i + \\frac{\\partial \\rho_r^i}{\\partial x_r}\\Delta x_r ) + I_r^i + T_r^i + ( ct_{r,0} + c\\Delta t_r ) + \\epsilon_r^i \\end{aligned} \\]\n经典单点定位精度在10m左右。 其中\\(\\rho_{r,0}^i\\)为测站到第\\(i\\)颗卫星的近似距离，\\(ct_{r,0}\\)表示接收机钟差的近似值。\n由于测站坐标位置、接收机钟差需要一个初值，用带有一个角标0的符号表示，且存在待估计的小量改正数\\(\\Delta x_r\\)与\\(\\Delta t_r\\)。\n\\(I\\)与\\(T\\)分别表示电离层、对流层的影响。\\(\\epsilon\\)表示其它随机噪声。\n\\[ \\begin{bmatrix} P_r^i -\\rho_{r,0}^i -ct_{r,0} -I_r^i -T_r^i \\end{bmatrix} = \\begin{bmatrix} E_r^i \u0026 1 \\end{bmatrix} \\begin{bmatrix} \\Delta x_r \\\\ c\\Delta t_r \\end{bmatrix} \\]\n将多个卫星的观测数据累加在一起，用最小二乘，即可求解参数。\nDGPS 当有参考站的情况下，可以使用DGPS技术提高定位精度。定位精度在1m左右。\n参考站的坐标已知，\\(\\rho_b^i\\)为精确量，也不存在\\(\\Delta x_b\\)，其观测方程可以写成如下形式：\n\\[ \\begin{bmatrix} P_b^i -\\rho_b^i -ct_{b,0} -I_b^i -T_b^i \\end{bmatrix} = \\begin{bmatrix} E_b^i \u0026 1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ c\\Delta t_b \\end{bmatrix} \\]\n将两个方程组相减，实现站间单差。当参考站与流动站相聚较近时，电离层误差\\(I\\)、对流层误差\\(T\\)认为基本相等，可以消去。 从而得到单差观测方程：\n\\[ \\begin{bmatrix} P_{rb}^i -\\rho_{r,0}^i -\\rho_b^i -ct_{rb,0} \\end{bmatrix} = \\begin{bmatrix} E_r^i \u0026 1 \\end{bmatrix} \\begin{bmatrix} \\Delta x_r \\\\ c\\Delta t_{rb} \\end{bmatrix} \\]\n选取第\\(i\\)颗卫星作为参考星，剩余所有卫星分别依次与第\\(i\\)颗卫星相减，实现星间差分，消除接收机钟差的影响，得到双差观测方程：\n\\[ \\begin{bmatrix} P_{rb}^{ji} -\\rho_{r,0}^{ji} -\\rho_b^{ji} \\end{bmatrix} = \\begin{bmatrix} E_r^{ji} \\end{bmatrix} \\begin{bmatrix} \\Delta x_r \\end{bmatrix} \\]\n此时的卫星方程非常精简，大量的共同误差被消除，估计出来的测站坐标精度也比较高。 值得注意的是，对于双差观测方程，协方差矩阵是相关的。\nRTK 载波是调试信号的正弦波，在接收机稳定跟踪卫星信号以后，能够给出正弦波变化的周数。 但前面一段正弦波信息无法获得，因此存在所谓的“整周模糊度”。其双差观测方程与伪距的双差观测方程基本相同，仅需要多估计一个模糊度参数。\n\\[ \\begin{bmatrix} P_{rb}^{ji} -\\rho_{r,0}^{ji} -\\rho_b^{ji} \\\\ \\Phi_{rb}^{ji} -\\rho_{r,0}^{ji} -\\rho_b^{ji} \\end{bmatrix} = \\begin{bmatrix} E_r^{ji} \u00260 \\\\ E_r^{ji} \u0026\\lambda \\end{bmatrix} \\begin{bmatrix} \\Delta x_r \\\\ N_{rb}^{ji}\\end{bmatrix} \\]\n当基线长度大于10km时，通过双差方程并不能完全消除电离层、对流层的影响， 此时需要考虑对参与量进行估计，或通过其他的观测值线性组合进行特殊处理，这里不再做具体介绍。\n周跳探测 接收机跟踪信号过程中可能出现不稳定情况，导致出现丢失几次正弦波计数，称之为“周跳”。有多种手段进行周跳的检测。\nTODO\n模糊度解算 在得到模糊度参数的浮点解以后，需要将其还原成整数，再将整数解带入原始方程，实现测站坐标的cm级精度估计。\nTODO\n参考星选择与处理的小技巧 双差观测方程需要选择合适的参考星。在特殊情况下，参考星可能会突然消失，或者出现周跳等不稳定情况，所估计的双差模糊度也需要做特殊处理。\n对观测方程做简单的变形，可以使得参考星的处理变得简洁清晰，程序设计更加简单。\nTODO\n开源软件及学习资源 几个官网要仔细逛逛，有很多资源：\nIGS\nUNAVCO\nNavipedia\nGPS Toolbox\n不重复造轮子，在巨人的肩膀上走的更远。 T. Takasu教授写的两个开源软件，是很好的入门学习软件：\nRTKLIB\nGpsTools (GT): GPS/GNSS Precise Analysis Software\n据说把这个软件搞懂就超神了：\nGAMIT/GLOBK\n","PublishDate":"2020-01-13T08:00:00+08:00","ReadingTime":3,"RelPermalink":"/rtk/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-02T11:55:13.629948048+08:00","Mode":436,"Name":"index.md","Size":8686},"Tags":null,"Title":"GNSS定位原理","Type":"blog","Weight":0,"WordCount":474},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"sdr","Dir":"blog/gps/sdr/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/gps/sdr/index.md","TranslationBaseName":"index","UniqueID":"16b474b72bfb6fd226f35a1e635c65ce"},"FuzzyWordCount":100,"GitInfo":{"hash":"15fa8bfe9b2760e4820778082bd992905caa6169","abbreviatedHash":"15fa8bf","subject":"update","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-01-30T11:47:38+08:00","commitDate":"2020-02-02T11:55:14+08:00"},"Kind":"page","Lastmod":"2020-01-30T11:47:38+08:00","Len":8981,"Name":"Software Defined Receiver","Permalink":"https://nuhuo08.github.io/sdr/","Plain":"GPS信号组成 载波 载波即为一个个正弦波，没有任何标记，作为信号的载体发射出去。\n   信号 特点     \\(L_1\\) \\(f_1=1575.42MHz=154f_0\\)，\\(\\lambda_1 \\approx 19.0cm\\)   \\(L_2\\) \\(f_1=1227.60MHz=120f_0\\)，\\(\\lambda_2 \\approx 24.4cm\\)    其中，\\(f_0=10.23MHz\\)为原子钟所提供的基准频率。\n伪码 伪码：伪随机噪声码。对于某一颗卫星的伪码，与其他卫星的伪码互相关值为0；与自身伪码相位完全对齐时相关值为1，相位不对齐时为0。 与随机噪声的特点相似，故称为伪码。\n   信号 特点     \\(C/A\\)码 仅调制在\\(L_1\\)上，长度为1023个码片，每毫秒重复一周，码宽约293m，一个码片的时间内载波\\(L_1\\)重复1540周   \\(P码\\) 同时调制在\\(L_1\\)和\\(L_2\\)上，每7天重复一周，码宽约30m    数据码  载波L1、C/A码、数据码三者之间的长度关系\n  数据码解译出来，即为导航星历，用于计算某一时刻卫星的位置。\n   信号 特点     1帧 1500比特组成，每帧30s，分成5子帧   1子帧 300比特组成，每子帧6s，分成10字   1字 30比特组成，每字0.6s，最高位比特先被发送，6比特的奇偶校验码结束。   1比特 每比特20ms，期间\\(C/A\\)码重复20个周期     导航电文的结构\n  跟踪环路  一种典型的接收机跟踪环路\n  载波相位观测值  数字中频信号\\(s_{IF}(n)\\)与载波环所复制的载波混频相乘，其中\\(I\\)支路为正弦波，\\(Q\\)支路为余弦波：得到\\(i\\)和\\(q\\)； 与码环所复制的即时\\(C/A\\)码做相关运算：剥离\\(C/A\\)码信号，得到\\(i_P\\)和\\(q_P\\)； 进行相干积分：滤除高频信号，得到\\(I_P\\)和\\(Q_P\\)信号； 输入到载波环鉴别器，得到\\(\\phi_e\\)或\\(f_e\\)，用于调整载波数控振荡器； 输出观测量：多普勒频移、积分多普勒、载波相位测量值、导航电文数据比特。  码观测值  数字中频信号\\(s_{IF}(n)\\)与载波环所复制的载波混频相乘，其中\\(I\\)支路为正弦波，\\(Q\\)支路为余弦波：得到\\(i\\)和\\(q\\)； 与码环所复制的超前、滞后\\(C/A\\)码做相关运算：剥离\\(C/A\\)码信号，得到\\(i_E\\)、\\(q_E\\)、\\(i_L\\)、\\(q_L\\)； 进行相干积分：滤除高频信号，得到\\(I_E\\)、\\(Q_E\\)、\\(I_L\\)、\\(Q_L\\)信号； 输入到码环鉴别器，得到\\(IQ\\)支路的幅值\\(E\\)和\\(L\\)，并进行非相干积分，并得到\\(\\delta_cp\\)，用于调整\\(C/A\\)码数控振荡器； 输出观测量：码相位、伪距测量值。  基带数字信号处理 位同步 帧同步 奇偶校验与电文译码 测量值的生成  卫星发射信号时间的组成部分\n  \\[ t^{(s)}=TOW+(30w+b)\\times 0.020+\\left(c+\\frac{CP}{1023}\\right)\\times 0.001\\ (s) \\\\[2mm] \\rho (t)=c\\left(t_u(t)-t^{(s)}(t-\\tau)\\right) \\]\n信号捕获 二维搜索范围包括41个搜索频带和2046个搜索码带，搜索范围太大。 通过并行频率搜索、并行码相位搜索，可以大幅度提高搜索效率。利用傅里叶变换实现并行搜索。\n并行频率搜索  并行频率搜索捕获算法流程\n  并行码相位搜索  并行码相位搜索捕获算法流程\n  两个序列\\(x(n)\\)与\\(y(n)\\)在时域内做相关运算，相当于他们的离散傅里叶变换\\(X(k)\\)与\\(Y(k)\\)的共轭\\(\\overline{Y(k)}\\)在频域内做乘积运算。 反过来，成绩\\(X(k)\\overline{Y(k)}\\)的离散傅里叶反变换正好是接收机需要进行检测的在各个码相位处的相关值\\(\\mathcal{z}(n)\\)。\n学习资料  GPS原理与接收机设计\n   A Software-Defined GPS and Galileo Receiver: A Single-Frequency Approach\n   GPS全球定位接收机——原理与软件实现\n  GNSS-SDRLIB\n","PublishDate":"2020-01-12T08:00:00+08:00","ReadingTime":1,"RelPermalink":"/sdr/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-02T11:55:13.629948048+08:00","Mode":436,"Name":"index.md","Size":5460},"Tags":null,"Title":"Software Defined Receiver","Type":"blog","Weight":0,"WordCount":88},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"factor-graph","Dir":"blog/math/factor-graph/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/math/factor-graph/index.md","TranslationBaseName":"index","UniqueID":"38daecff3d2f657f782298d43a87f9a7"},"FuzzyWordCount":100,"GitInfo":{"hash":"728d17c99481cb14d1e8283cabb76251ed51e4e7","abbreviatedHash":"728d17c","subject":"add rtk page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-01-29T23:12:48+08:00","commitDate":"2020-02-02T11:55:13+08:00"},"Kind":"page","Lastmod":"2020-01-29T23:12:48+08:00","Len":933,"Name":"Factor Graph","Permalink":"https://nuhuo08.github.io/factor-graph/","Plain":"为什么使用因子图 通常我们并不关心观测量，只有在状态确定的情况下，讨论观测量才有意义。因此用因子图表达更突出重点，即状态变量。\n与传统优化算法的关系 通常，传统算法作用在信息矩阵上。信息矩阵对应于一个无向马尔科夫图，通过Cholesky分解LU后，可以求解变量。\n因子图直接作用在雅克比矩阵上。通过QR分解逐步消元，得到的R矩阵与上面的LU矩阵存在关系（相同？）。\n优势  可以迭代递推，不需要重新对整个雅克比矩阵QR分解 通过贝叶斯树，可以非常清晰的看到，当新的观测量出现时，哪部分矩阵会受到影响，需要重新计算。避免其他大量不受影响状态的重复计算  ","PublishDate":"2020-01-11T08:00:00+08:00","ReadingTime":1,"RelPermalink":"/factor-graph/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-02T11:55:12.961972492+08:00","Mode":436,"Name":"index.md","Size":881},"Tags":null,"Title":"Factor Graph","Type":"blog","Weight":0,"WordCount":8},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"matrix","Dir":"blog/math/matrix/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/math/matrix/index.md","TranslationBaseName":"index","UniqueID":"3615206ab9f107f87e7a76bbe545d0d2"},"FuzzyWordCount":200,"GitInfo":{"hash":"728d17c99481cb14d1e8283cabb76251ed51e4e7","abbreviatedHash":"728d17c","subject":"add rtk page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-01-29T23:12:48+08:00","commitDate":"2020-02-02T11:55:13+08:00"},"Kind":"page","Lastmod":"2020-01-29T23:12:48+08:00","Len":6147,"Name":"Matrix Decomposition","Permalink":"https://nuhuo08.github.io/matrix/","Plain":"LU \u0026amp; LDU    LDL \u0026amp; LL 只适用于对称矩阵       QR分解    Householder Method 镜像变换，For each i-th column of A, “zero out” rows i+1 and lower\n   Givens Don’t reflect; rotate instead, Introduces zeroes into A one at a time\n   Gram-Schmidt Iteratively express each new column vector as a linear combination of previous columns, plus some (normalized) orthogonal component\nSVD分解    作用 对角矩阵：对坐标轴进行缩放\n三角矩阵：切变Shear\n正交矩阵：旋转\n方程求解 LU中，LU为三角阵，递归带入求解方程\nQR中Q为正交阵，逆矩阵即转置，容易求解\nSVD可以用于求解\\(Ax=0\\)形式的方程，最小特征值对应的特征向量即为解。若方程形式为\\(Ax=b\\)，将\\(b\\)移至左侧即可。可参考ORB-SLAM2 Initialization\nSLAM中的优化理论（一）—— 线性最小二乘\nSLAM中的优化理论（二）- 非线性最小二乘\nNullSpace Let A be an m-by-n matrix with rank n. QR decomposition finds orthonormal m-by-m matrix Q and upper triangular m-by-n matrix R such that A = QR. If we define Q = [Q1 Q2], where Q1 is m-by-n and Q2 is m-by-(m-n), then the columns of Q2 form the null space of A^T.\nQR decomposition is computed either by Gram-Schmidt, Givens rotations, or Householder reflections. They have different stability properties and operation counts.\n稀疏矩阵的重排序 （1）原始稀疏矩阵，进行Cholesky分解后，存在大量非零元素8.24%\n   Original Sparse Matrix Cholesky Decomposition          （2）采用Nested Dissection Permutation方法进行排序后，再进行Cholesky分解，非零元素显著减少，仅0.68%\n   Nested Dissection Cholesky Decomposition          （3）各排序方法的比较    建议  先边缘化掉地图点，因为地图点之间一般是独立的 再边缘化掉位姿。边缘化位姿时，会造成矩阵稠密 稠密矩阵解算时，可以先进行排序，再进行Cholesky分解  SVD \u0026amp; PCA SVD vs PCA\n      ","PublishDate":"2020-01-10T08:00:00+08:00","ReadingTime":1,"RelPermalink":"/matrix/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-06-11T10:46:57.354588665+08:00","Mode":436,"Name":"index.md","Size":3414},"Tags":null,"Title":"Matrix Decomposition","Type":"blog","Weight":0,"WordCount":167},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"navigation-stack","Dir":"blog/ros/navigation-stack/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/ros/navigation-stack/index.md","TranslationBaseName":"index","UniqueID":"7816e9dc1695358c0f2914dd6c964abd"},"FuzzyWordCount":200,"GitInfo":{"hash":"d3fe3afce8b5515bef646caaf6c5964e3ff9dc4a","abbreviatedHash":"d3fe3af","subject":"add navigation-stack page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-01-27T21:52:13+08:00","commitDate":"2020-02-02T11:55:11+08:00"},"Kind":"page","Lastmod":"2020-01-27T21:52:13+08:00","Len":6907,"Name":"ROS Navigation Stack","Permalink":"https://nuhuo08.github.io/navigation-stack/","Plain":"ROS系统结构 ROS Node ROS Node: 功能模块以Node的形式，处理某一特定的任务。    ROS Master: 记录所有现存的node，保证node之间的信息交流。parameter server运行在其中，实现参数与配置信息的共享。    ROS信息交互 单向通信：一个node发布topic，一个node订阅该topic    双向通信：一个node向另一个node发送信息并请求回复，使用service    查看ROS信息 rosnode list rostopic list rosservice list rostopic info /turtle1/cmd_vel rosmsg info geometry_msgs/Twist rqt_graph    ROS安装 ROS官网教程：ROS Tutorials\n安装ROS基本功能包 由于Ubuntu默认软件源在国内访问速度较慢，建议切换到阿里云。\n安装ROS：\nsudo sh -c \u0026#39;. /etc/lsb-release \u0026amp;\u0026amp; echo \u0026#34;deb http://mirrors.ustc.edu.cn/ros/ubuntu/ `lsb_release -cs` main\u0026#34; \u0026gt; /etc/apt/sources.list.d/ros-latest.list\u0026#39; sudo apt-key adv --keyserver \u0026#39;hkp://keyserver.ubuntu.com:80\u0026#39; --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 sudo apt-get update sudo apt-get install ros-kinetic-desktop-full sudo rosdep init rosdep update echo \u0026#34;source /opt/ros/kinetic/setup.bash\u0026#34; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 由于Gazebo第一次打开时，需要联网下载模型，若网络太慢，Gazebo可能卡在启动页面一直不动。 建议手工下载Gazebo Models，并解压到/usr/share/gazebo-7/models路径下。\nIn virtual machine, Gazebo 7.0.0 doesn’t publish topic. We need to upgrade to Gazebo 7.11\nsudo sh -c \u0026#39;echo \u0026#34;deb http://packages.osrfoundation.org/gazebo/ubuntu-stable `lsb_release -cs` main\u0026#34; \u0026gt; /etc/apt/sources.list.d/gazebo-stable.list\u0026#39; wget http://packages.osrfoundation.org/gazebo.key -O - | sudo apt-key add - sudo apt-get update sudo apt-get install gazebo7 安装turtlebot导航包 When running VM on Win10, turn off hardware acceleration for 3D graphics. Otherwise Gazebo may crash.\n安装turtlebot导航包：\nsudo apt-get install ros-kinetic-turtlebot-* 导航包演示操作 Mapping 使用如下命令，可以打开Gazebo的仿真环境，看到Rviz的消息显示界面，后台的GMapping建图功能也已启动，只需要在Terminal中操作键盘，可以控制机器人在仿真环境中运动。\nroslaunch turtlebot_gazebo turtlebot_world.launch roslaunch turtlebot_gazebo gmapping_demo.launch roslaunch turtlebot_rviz_launchers view_navigation.launch roslaunch turtlebot_teleop keyboard_teleop.launch 建图完成后，通过如下命令保存建好的地图：\nmkdir ~/turtlebot_custom_maps rosrun map_server map_saver -f ~/turtlebot_custom_maps/tutorial Navigation 使用如下命令，将会启动AMCL定位功能。在Rviz中设定机器人的目标位置，结合上一步建成的地图，可以进行机器人导航。\nroslaunch turtlebot_gazebo turtlebot_world.launch roslaunch turtlebot_gazebo amcl_demo.launch map_file:=/home/user/turtlebot_custom_maps/tutorial.yaml roslaunch turtlebot_rviz_launchers view_navigation.launch 自定义机器人 Gazebo用作机器人的仿真环境，有丰富的教学资源。Gazebo Tutorials\n自定义两轮机器人 Make a Mobile Robot\n添加传感器 Creating a camera\n","PublishDate":"2020-01-09T08:00:00+08:00","ReadingTime":1,"RelPermalink":"/navigation-stack/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-02T11:55:11.066041876+08:00","Mode":436,"Name":"index.md","Size":4058},"Tags":null,"Title":"ROS Navigation Stack","Type":"blog","Weight":0,"WordCount":187},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"gmapping","Dir":"blog/ros/gmapping/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/ros/gmapping/index.md","TranslationBaseName":"index","UniqueID":"1d37db947e20bbc87d9d330c3118963a"},"FuzzyWordCount":200,"GitInfo":{"hash":"4683dbffaee4d5bf50fdefff847029bd5ae2b501","abbreviatedHash":"4683dbf","subject":"add bayesian-filter","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-02-10T22:40:25+08:00","commitDate":"2020-02-10T22:40:25+08:00"},"Kind":"page","Lastmod":"2020-02-10T22:40:25+08:00","Len":7969,"Name":"GMapping","Permalink":"https://nuhuo08.github.io/gmapping/","Plain":"基本理论 粒子滤波基本原理请参考 Particle Filter\nSLAM问题的分解 \\[ \\begin{aligned} p(x_{1:t},m|u_{1:t},z_{1:t}) \u0026= p(x_{1:t}|u_{1:t},z_{1:t}) p(m|u_{1:t},z_{1:t})\\\\ \u0026= p(x_{1:t}|u_{1:t},z_{1:t}) p(m|z_{1:t}) \\end{aligned} \\]\n将SLAM问题分解为：机器人的定位；基于已知机器人位姿的构图。\nFast-SLAM 根据贝叶斯公式，可以将机器人位姿的估计，转换成一个增量估计问题。\n\\[ \\begin{aligned} p(x_{1:t}|u_{1:t},z_{1:t}) \u0026= \\eta p(z_t|x_{1:t},u_{1:t},z_{1:t-1}) p(x_{1:t}|z_{1:t-1},u_{1,t})\\\\ \u0026= \\eta p(z_t|x_t) p(x_{1:t}|z_{1:t-1},u_{1:t})\\\\ \u0026= \\eta p(z_t|x_t) p(x_t|x_{1:t-1},z_{1:t-1},u_{1:t}) p(x_{1:t-1}|z_{1:t-1},u_{1:t})\\\\ \u0026= \\eta p(z_t|x_t) p(x_t|x_{t-1},u_{1:t}) p(x_{1:t-1}|z_{1:t-1},u_{1:t-1}) \\end{aligned} \\]\n其中，\\(p(x_{1:t-1}|z_{1:t-1},u_{1:t-1})\\)通过粒子群来表示； \\(p(x_t|x_{t-1},u_{1:t})\\)对每个粒子进行运动学模型的传播； \\(p(z_t|x_t)\\)根据观测模型计算权重。\n数据结构相关 Map template \u0026lt;class Cell, const bool debug=false\u0026gt; class Array2D{}; template \u0026lt;class Cell\u0026gt; class HierarchicalArray2D: public Array2D\u0026lt;autoptr\u0026lt; Array2D\u0026lt;Cell\u0026gt; \u0026gt; \u0026gt;{}; template \u0026lt;class Cell, class Storage, const bool isClass=true\u0026gt; class Map{}; typedef Map\u0026lt;PointAccumulator,HierarchicalArray2D\u0026lt;PointAccumulator\u0026gt; \u0026gt; ScanMatcherMap;  Array2D是一个二维数组，HierarchicalArray2D是一个Array2D的二维数组。 相当于将地图先分割成分辨率比较低的网格，只有当粒子运动到该网格时，才真正分配这个网格的内存。 网格的内存对应着分辨率高的真实的地图，用PointAccumulator来进行计数，记录激光是否通过该点，从而判断改点的状态：占据、空闲、未知。\nautoptr GMapping中自己实现了autoptr类，实现了智能指针的功能。\n运动更新 根据上一时刻的状态，结合里程计的输入量，可以得到当前时刻预估的状态。\n\\[ x_t = g_t(u_t, x_{t-1}) + \\varepsilon_t \\]\n权重计算 光束模型    使用Bresenham画线算法，进行高效的计算。 由于计算量过大、在非结构化环境中得分会突变，因此实际工程项目中很少采用此方法。\n\\[ p(z_t^k|x_t,m)=\\begin{pmatrix} z_{hit} \\\\ z_{short} \\\\ z_{max} \\\\ z_{rand} \\end{pmatrix}^T \\begin{pmatrix} p_{hit}(z_t^k|x_t,m) \\\\ p_{short}(z_t^k|x_t,m) \\\\ p_{max}(z_t^k|x_t,m) \\\\ p_{rand}(z_t^k|x_t,m) \\end{pmatrix} \\]\n似然场模型    对图像进行高斯平滑，不会出现得分突变的情况，且运算效率高，查表即可得到。是工程项目中常用的方法。\n重采样优化 里程计扩散出来的最好的粒子 若里程计信号质量误差较大，则需要大量粒子对验后分布进行模拟。由于每个粒子都携带一个地图，这将会造成巨大的内存消耗。 根据里程计的运动模型，每个粒子会扩散出很多粒子。从其中找出最好的那个粒子，其他的全去除，可以大量减少粒子数量。\n\\[ x_t^i \\sim p(x_t|u_t,x_{t-1}^i) \\\\[2mm] \\to x_t^i = \\arg \\max_{x_t}(p(z_t|x_t,m)p(x_t|u_t,x_{t-1}^i)) \\]\n抑制重采样次数 当采样次数过多时，会出现粒子耗散问题，即所有的粒子来自于少数几个粒子。\n\\[ N_{eff} = \\frac{1}{\\sum_{i = 1}^N \\left(\\tilde{w}^{(i)} \\right)^2} \\]\n当\\(N_{eff}\\)较大时，说明各粒子的差异性较小，此时不要进行重采样。反之，则应进行重采样。\n根据激光匹配估计出分布 由于激光的精度较高，可以通过激光的匹配，估计出一个高斯分布。并在此分布中进行采样，得到一系列粒子。\n建图算法 覆盖栅格建图 \\[ l(m_i|x_{1:t},z_{1:t})=l(m_i|x_t,z_t)+l(m_i|x_{1:t-1},z_{1:t-1})-l(m_i) \\]\n其中，\\(l(m_i|x_t,z_t)\\)表示会激光雷达的逆观测模型；\\(l(m_i|x_{1:t-1},z_{1:t-1})\\)表示栅格\\(m_i\\)在\\(t-1\\)时刻的状态， \\(l(m_i)\\)表示栅格\\(m_i\\)的先验值，对所有栅格都相同。\n计数建图法 \\[ m_j = \\frac{a_j}{a_j+b_j} \\]\n其中，\\(a_j\\)表示击中的次数，\\(b_j\\)表示未击中的次数。\n","PublishDate":"2020-01-08T08:00:00+08:00","ReadingTime":1,"RelPermalink":"/gmapping/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-10T10:06:42.331363394+08:00","Mode":436,"Name":"index.md","Size":4433},"Tags":null,"Title":"GMapping","Type":"blog","Weight":0,"WordCount":163},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"slam-for-dummies","Dir":"blog/slam/slam-for-dummies/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/slam/slam-for-dummies/index.md","TranslationBaseName":"index","UniqueID":"7b130c73d29bcc9f4f898e3e9e0e2917"},"FuzzyWordCount":300,"GitInfo":{"hash":"d3fe3afce8b5515bef646caaf6c5964e3ff9dc4a","abbreviatedHash":"d3fe3af","subject":"add navigation-stack page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-01-27T21:52:13+08:00","commitDate":"2020-02-02T11:55:11+08:00"},"Kind":"page","Lastmod":"2020-01-27T21:52:13+08:00","Len":1949,"Name":"SLAM for Dummies","Permalink":"https://nuhuo08.github.io/slam-for-dummies/","Plain":"TO BE CONTINUED\nhttps://zhuanlan.zhihu.com/p/32937247\n观测方程 \\[ \\underbrace{\\begin{pmatrix} r_1 \\\\ \\theta_1 \\\\ r_2 \\\\ \\theta_2 \\\\ \\vdots \\\\ r_n \\\\ \\theta_n \\end{pmatrix}}_Z = \\underbrace{\\begin{bmatrix} A_1 \u0026B_1 \u0026C_1 \u0026-A_1 \u0026-B_1 \\\\ D_1 \u0026E_1 \u0026F_1 \u0026-D_1 \u0026-E_1 \\\\ A_2 \u0026B_2 \u0026C_2 \u0026 \u0026 \u0026-A_2 \u0026-B_2 \\\\ D_2 \u0026E_2 \u0026F_2 \u0026 \u0026 \u0026-D_2 \u0026-E_2 \\\\ \u0026\\vdots \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ddots \\\\ A_n \u0026B_n \u0026C_n \u0026 \u0026 \u0026 \u0026 \u0026 \u0026-A_n \u0026-B_n \\\\ D_n \u0026E_n \u0026F_n \u0026 \u0026 \u0026 \u0026 \u0026 \u0026-D_n \u0026-E_n \\\\ \\end{bmatrix}}_H \\underbrace{\\begin{pmatrix} x_r \\\\ y_r \\\\ \\theta_r \\\\ x_1 \\\\ y_1 \\\\ x_2 \\\\ y_2 \\\\ \\vdots \\\\ x_n \\\\ y_n \\end{pmatrix}}_X \\\\[2mm] R = \\begin{pmatrix} r_c \u0026 \\\\ \u0026r_d \\end{pmatrix} \\]\n动态方程 \\[ \\underbrace{\\begin{pmatrix} x_r \\\\ y_r \\\\ \\theta_r \\end{pmatrix}}_{X_{k+1}} = \\underbrace{\\begin{bmatrix} 1 \u0026 \u0026-\\Delta y \\\\ \u00261 \u0026\\Delta x \\\\ \u0026 \u00261\\end{bmatrix}}_A \\underbrace{\\begin{pmatrix} x_r \\\\ y_r \\\\ \\theta_r \\end{pmatrix}}_{X_k} \\\\[2mm] Q = \\begin{pmatrix} c\\Delta x^2 \\\\ \u0026 c\\Delta y^2 \\\\ \u0026 \u0026c\\Delta t^2\\end{pmatrix} \\]\n新增路标点的协方差矩阵增广 landmark wrt. robot state \\[ J_{xr} = \\begin{bmatrix} 1 \u0026 \u0026-\\Delta y \\\\ \u00261 \u0026\\Delta x\\end{bmatrix} \\]\nlandmark wrt. [range, bearing] \\[ J_z = \\begin{bmatrix} \\cos(\\theta + \\Delta \\theta) \u0026-\\Delta t \\cdot \\sin(\\theta + \\Delta \\theta) \\\\ \\sin(\\theta + \\Delta \\theta) \u0026\\Delta t \\cdot \\cos(\\theta + \\Delta \\theta) \\end{bmatrix} \\]\ncovariance \\[ P^{r \\ {N+1}} = P^{rr}J_{xr}^T \\\\[2mm] P^{i \\ {N+1}} = P^{ri}J_{xr}^T \\\\[2mm] P^{{N+1} \\ {N+1}} = J_{xr}PJ_{xr}^T + J_zRJ_z^T \\]\n","PublishDate":"2020-01-07T08:00:00+08:00","ReadingTime":2,"RelPermalink":"/slam-for-dummies/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-02T11:55:11.102040558+08:00","Mode":436,"Name":"index.md","Size":1615},"Tags":null,"Title":"SLAM for Dummies","Type":"blog","Weight":0,"WordCount":231},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"non-linear","Dir":"blog/math/non-linear/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/math/non-linear/index.md","TranslationBaseName":"index","UniqueID":"c83b266721ff9902afb2091ebb79eb13"},"FuzzyWordCount":300,"GitInfo":{"hash":"728d17c99481cb14d1e8283cabb76251ed51e4e7","abbreviatedHash":"728d17c","subject":"add rtk page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-01-29T23:12:48+08:00","commitDate":"2020-02-02T11:55:13+08:00"},"Kind":"page","Lastmod":"2020-01-29T23:12:48+08:00","Len":5675,"Name":"非线性优化","Permalink":"https://nuhuo08.github.io/non-linear/","Plain":"优化方法比较    方法 特点     梯度下降法 \\(x_{i+1}=x_i-\\eta \\frac{\\partial f}{\\partial x}\\)，效率高，但可能收敛慢   牛顿法 二阶泰勒展开，计算Hessian矩阵耗时，离初值远不收敛，极小值处接近二次函数   高斯-牛顿法 仅适用于最小二乘问题，以Jacobian矩阵\\(J^TJ\\)代替\\(H\\)，离初值远不收敛，\\(J^TJ\\)近奇异不收敛   L-M法 \\(\\left(H+\\lambda I\\right)\\Sigma=-J^Tr\\)，残差增大时，放大\\(\\lambda\\)，成为梯度下降；残差减小时，减小\\(\\lambda\\)，成为高斯-牛顿    g2o g2o在ORB-SLAM2中的用法 Ceres http://ceres-solver.org/nnls_modeling.html\n对于以下代价函数：\n\\[ \\frac{1}{2} \\sum_i \\rho_i(\\parallel f_i(x_{i1}, x_{i2}, \\cdots, x_{ik}) \\parallel ^2) \\]\n在Ceres中，\\(\\rho\\)为loss function，用于减弱外点的影响；\\(f\\)为cost function，定义了残差的计算方式；\\((x_{i1}, x_{i2}, \\cdots, x_{ik})\\)为parameter block，定义了需要估计的变量；\\(\\rho_i(\\parallel f_i(x_{i1}, x_{i2}, \\cdots, x_{ik}) \\parallel ^2)\\)为residual block，定义了一个残差块。\nAddResidualBlock problem.AddResidualBlock(costfunction, lossfunction, x1, x2 ... xn)\n其中，\\(x_1, x_2, \\cdots x_n\\)要与costfunction中的变量维数要对应起来。\ncostfunction有两种典型的定义方式：\n 自己实现残差、雅可比  templateclass SizedCostFunction : public CostFunction { public: virtual bool Evaluate(double const* const* parameters, double* residuals, double** jacobians) const = 0; }; 这种情况下，需要指定残差维数、参数块维数，并自己实现Evaluate()，计算cost和jacobian。\n自己实现残差即可  template class AutoDiffCostFunction : public SizedCostFunction{ public: explicit AutoDiffCostFunction(CostFunctor* functor); // Ignore the template parameter kNumResiduals and use // num_residuals instead. AutoDiffCostFunction(CostFunctor* functor, int num_residuals); }; 这种情况下，不再需要自己计算jacobian。只需要定义CostFunctor，计算残差，实现operator()函数。例如：\nclass MyScalarCostFunctor { MyScalarCostFunctor(double k): k_(k) {} template bool operator()(const T* const x , const T* const y, T* e) const { e[0] = k_ - x[0] * y[0] - x[1] * y[1]; return true; } private: double k_; }; AddParameterBlock ceres::LocalParameterization *local_parameterization = new PoseLocalParameterization(); problem.AddParameterBlock(para_Pose[i], SIZE_POSE, local_parameterization); problem.AddParameterBlock(para_SpeedBias[i], SIZE_SPEEDBIAS); Sometimes the parameters \\(x\\) can overparameterize a problem. In that case it is desirable to choose a parameterization to remove the null directions of the cost.\nCeres在VINS-MONO中的用法 Factor VINS 中用 IMUFactor 表示 IMU 的 cost function，用 ProjectionFactor 表示图像重投影误差的 cost function。其中定义了对各个参数块的残差、雅可比。\nMarginalizationFactor 表达了先验残差的更新方式。在Evaluate()函数中，实现了如下更新： \nResidualBlockInfo 为了进行 Schur，在 cost function 外面包了一层 ResidualBlockInfo。因为在原生Ceres中，一旦调用 problem.AddResidualBlock(costfunction, lossfunction, x1, x2 ... xn)，便不再能干预内部处理流程。\n在这个自定义的 ResidualBlockInfo 的 Evaluate() 中，调用了每个 cost function 原生的 Evaluate()，获得残差、雅可比，然后将 loss function 的功能也在此调用，组装好以后，留给 MarginalizationInfo 做进一步处理。\nMarginalizationInfo addResidualBlockInfo() 处理优化变量、待边缘化变量\npreMarginalize()\nmarginalize() 并行化线程，进行舒尔补计算\n","PublishDate":"2020-01-06T08:00:00+08:00","ReadingTime":2,"RelPermalink":"/non-linear/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-02T11:55:12.961972492+08:00","Mode":436,"Name":"index.md","Size":4932},"Tags":null,"Title":"非线性优化","Type":"blog","Weight":0,"WordCount":234},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"vins-mono","Dir":"blog/slam/vins-mono/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/slam/vins-mono/index.md","TranslationBaseName":"index","UniqueID":"0c4a8ac17f16aede809877d1eac1a13f"},"FuzzyWordCount":700,"GitInfo":{"hash":"a44513a073c4ee2eab1c5884736df50f43403d3b","abbreviatedHash":"a44513a","subject":"add online calibration chapter for vins-mono","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-03T21:03:29+08:00","commitDate":"2020-03-03T21:03:29+08:00"},"Kind":"page","Lastmod":"2020-03-03T21:03:29+08:00","Len":13987,"Name":"VINS-MONO","Permalink":"https://nuhuo08.github.io/vins-mono/","Plain":"代码流程图    预积分的协方差 预积分值可以作为一种观测量，约束两个时刻状态间的关系。为了确定预积分值的精度（协方差），需要求解出其递推关系。\n预积分公式推导 \\(b_k^a\\)和\\(b_k^g\\)作为随机游走噪声，在推导\\(k \\sim k+1\\)时认为是常数！不像\\(w\\)和\\(a\\)，要添加\\(n_k^g\\)和\\(n_k^a\\)噪声进去\n\\[ \\begin{aligned} \\omega\u0026=\\frac{1}{2}( (\\omega^{b_k}+n_k^g-b_k^g) + (\\omega^{b_{k+1}}+n_{k+1}^g-b_k^g) ) \\\\[2mm] q_{b_ib_{k+1}}\u0026=q_{b_ib_k}\\otimes\\begin{bmatrix}1 \\\\ \\frac{1}{2}\\omega\\delta{t}\\end{bmatrix} \\\\[2mm] a\u0026=\\frac{1}{2}( q_{b_ib_k}(a^{b_k}+n_k^a-b_k^a) + q_{b_ib_{k+1}}(a^{b_{k+1}}+n_{k+1}^a-b_k^a) ) \\\\[2mm] \\beta_{b_ib_{k+1}}\u0026=\\beta_{b_ib_k}+a\\delta{t} \\\\[2mm] \\alpha_{b_ib_{k+1}}\u0026=\\alpha_{b_ib_k}+\\beta_{b_ib_k}\\delta{t}+\\frac{1}{2}a\\delta{t}^2 \\\\[2mm] b_{k+1}^a\u0026=b_k^a+n_{b_k^a}\\delta{t} \\\\[2mm] b_{k+1}^g\u0026=b_k^g+n_{b_k^g}\\delta{t} \\\\[2mm] \\end{aligned} \\]\n写成矩阵形式：\n\\[ \\begin{bmatrix}\\alpha_{b_ib_{k+1}} \\\\ \\theta_{b_ib_{k+1}} \\\\ \\beta_{b_ib_{k+1}} \\\\ b_{k+1}^a \\\\ b_{k+1}^g\\end{bmatrix} =F*\\begin{bmatrix}\\alpha_{b_ib_{k}} \\\\ \\theta_{b_ib_{k}} \\\\ \\beta_{b_ib_{k}} \\\\ b_{k}^a \\\\ b_{k}^g\\end{bmatrix} +G*\\begin{bmatrix}n_k^a \\\\ n_k^g \\\\ n_{k+1}^a \\\\ n_{k+1}^g \\\\ n_{k}^a \\\\ n_{k}^g \\end{bmatrix} \\]\n\\[ \\begin{aligned} F\u0026=\\begin{bmatrix}I \u0026f_{12} \u0026I\\delta{t} \u0026-\\frac{1}{4}(q_{b_ib_k}+q_{b_ib_{k+1}})\\delta{t}^2 \u0026f_{15}\\\\ 0 \u0026I-[\\omega]_{\\times} \u00260 \u00260 \u0026-I\\delta{t}\\\\ 0 \u0026f_{32} \u0026I \u0026-\\frac{1}{2}(q_{b_ib_k}+q_{b_ib_{k+1}})\\delta{t} \u0026f_{35}\\\\ 0 \u00260 \u00260 \u0026I \u00260\\\\ 0 \u00260 \u00260 \u00260 \u0026I \\end{bmatrix} \\\\[2mm] G\u0026=\\begin{bmatrix}\\frac{1}{4}q_{b_ib_k}\\delta{t}^2 \u0026g_{12} \u0026\\frac{1}{4}q_{b_ib_{k+1}}\\delta{t}^2 \u0026g_{14} \u00260 \u00260 \\\\ 0 \u0026\\frac{1}{2}I\\delta{t} \u00260 \u0026\\frac{1}{2}I\\delta{t} \u00260 \u00260\\\\ \\frac{1}{2}q_{b_ib_k}\\delta{t} \u0026g_{32} \u0026\\frac{1}{2}q_{b_ib_{k+1}}\\delta{t} \u0026g_{34} \u00260 \u00260\\\\ 0 \u00260 \u00260 \u00260 \u0026I\\delta{t} \u00260\\\\ 0 \u00260 \u00260 \u00260 \u00260 \u0026I\\delta{t}\\end{bmatrix} \\\\[2mm] f_{12}\u0026=-\\frac{1}{4}( R_{b_ib_k}[a^{b_k}-b_k^a]_\\times\\delta{t}^2 + R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times(I-[\\omega]_\\times\\delta{t})\\delta{t}^2) \\\\[2mm] f_{32}\u0026=-\\frac{1}{2}( R_{b_ib_k}[a^{b_k}-b_k^a]_\\times\\delta{t} + R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times(I-[\\omega]_\\times\\delta{t})\\delta{t}) \\\\[2mm] f_{15}\u0026=-\\frac{1}{4}(R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times\\delta{t}^2)(-\\delta{t}) \\\\[2mm] f_{35}\u0026=-\\frac{1}{2}(R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times\\delta{t})(-\\delta{t}) \\\\[2mm] g_{12}\u0026=g_{14}=-\\frac{1}{4}(R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times\\delta{t}^2)(\\frac{1}{2}\\delta{t}) \\\\[2mm] g_{32}\u0026=g_{34}=-\\frac{1}{2}(R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times\\delta{t})(\\frac{1}{2}\\delta{t}) \\end{aligned} \\]\n终极大矩阵 将所有值带进去并展开，得到原始等式\n\\[ \\begin{aligned} q_{b_ib_{k+1}}\u0026=q_{b_ib_k}\\otimes\\begin{bmatrix}1 \\\\ \\frac{1}{2}\\{\\frac{1}{2}( (\\omega^{b_k}+n_k^g-b_k^g) + (\\omega^{b_{k+1}}+n_{k+1}^g-b_k^g) )\\}\\delta{t}\\end{bmatrix} \\\\[2mm] \\beta_{b_ib_{k+1}}\u0026=\\beta_{b_ib_k}+\\{\\frac{1}{2}( q_{b_ib_k}(a^{b_k}+n_k^a-b_k^a) + \\{q_{b_ib_k}\\otimes\\begin{bmatrix}1 \\\\ \\frac{1}{2}\\{\\frac{1}{2}( (\\omega^{b_k}+n_k^g-b_k^g) + (\\omega^{b_{k+1}}+n_{k+1}^g-b_k^g) )\\}\\delta{t}\\end{bmatrix}\\}(a^{b_{k+1}}+n_{k+1}^a-b_k^a) )\\}\\delta{t} \\\\[2mm] \\alpha_{b_ib_{k+1}}\u0026=\\alpha_{b_ib_k}+\\beta_{b_ib_k}\\delta{t}+\\frac{1}{2}\\{\\frac{1}{2}( q_{b_ib_k}(a^{b_k}+n_k^a-b_k^a) + \\{q_{b_ib_k}\\otimes\\begin{bmatrix}1 \\\\ \\frac{1}{2}\\{\\frac{1}{2}( (\\omega^{b_k}+n_k^g-b_k^g) + (\\omega^{b_{k+1}}+n_{k+1}^g-b_k^g) )\\}\\delta{t}\\end{bmatrix}\\}(a^{b_{k+1}}+n_{k+1}^a-b_k^a) )\\}\\delta{t}^2 \\\\[2mm] b_{k+1}^a\u0026=b_k^a+n_{b_k^a}\\delta{t} \\\\[2mm] b_{k+1}^g\u0026=b_k^g+n_{b_k^g}\\delta{t} \\end{aligned} \\]\n矩阵形式\n\\[ \\begin{aligned} \\begin{bmatrix}\\alpha_{b_ib_{k+1}} \\\\ \\theta_{b_ib_{k+1}} \\\\ \\beta_{b_ib_{k+1}} \\\\ b_{k+1}^a \\\\ b_{k+1}^g\\end{bmatrix} \u0026=\\begin{bmatrix}I \u0026-\\frac{1}{4}( R_{b_ib_k}[a^{b_k}-b_k^a]_\\times\\delta{t}^2 + R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times(I-[\\omega]_\\times\\delta{t})\\delta{t}^2) \u0026I\\delta{t} \u0026-\\frac{1}{4}(q_{b_ib_k}+q_{b_ib_{k+1}})\\delta{t}^2 \u0026-\\frac{1}{4}(R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times\\delta{t}^2)(-\\delta{t})\\\\ 0 \u0026I-[\\omega]_{\\times} \u00260 \u00260 \u0026-I\\delta{t}\\\\ 0 \u0026-\\frac{1}{2}( R_{b_ib_k}[a^{b_k}-b_k^a]_\\times\\delta{t} + R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times(I-[\\omega]_\\times\\delta{t})\\delta{t}) \u0026I \u0026-\\frac{1}{2}(q_{b_ib_k}+q_{b_ib_{k+1}})\\delta{t} \u0026-\\frac{1}{2}(R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times\\delta{t})(-\\delta{t})\\\\ 0 \u00260 \u00260 \u0026I \u00260\\\\ 0 \u00260 \u00260 \u00260 \u0026I \\end{bmatrix} *\\begin{bmatrix}\\alpha_{b_ib_{k}} \\\\ \\theta_{b_ib_{k}} \\\\ \\beta_{b_ib_{k}} \\\\ b_{k}^a \\\\ b_{k}^g\\end{bmatrix}\\\\ \u0026+\\begin{bmatrix}\\frac{1}{4}q_{b_ib_k}\\delta{t}^2 \u0026-\\frac{1}{4}(R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times\\delta{t}^2)(\\frac{1}{2}\\delta{t}) \u0026\\frac{1}{4}q_{b_ib_{k+1}}\\delta{t}^2 \u0026-\\frac{1}{4}(R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times\\delta{t}^2)(\\frac{1}{2}\\delta{t}) \u00260 \u00260 \\\\ 0 \u0026\\frac{1}{2}I\\delta{t} \u00260 \u0026\\frac{1}{2}I\\delta{t} \u00260 \u00260\\\\ \\frac{1}{2}q_{b_ib_k}\\delta{t} \u0026-\\frac{1}{2}(R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times\\delta{t})(\\frac{1}{2}\\delta{t}) \u0026\\frac{1}{2}q_{b_ib_{k+1}}\\delta{t} \u0026-\\frac{1}{2}(R_{b_ib_{k+1}}[a^{b_{k+1}}-b_k^a]_\\times\\delta{t})(\\frac{1}{2}\\delta{t}) \u00260 \u00260\\\\ 0 \u00260 \u00260 \u00260 \u0026I\\delta{t} \u00260\\\\ 0 \u00260 \u00260 \u00260 \u00260 \u0026I\\delta{t}\\end{bmatrix} *\\begin{bmatrix}n_k^a \\\\ n_k^g \\\\ n_{k+1}^a \\\\ n_{k+1}^g \\\\ n_{k}^a \\\\ n_{k}^g \\end{bmatrix} \\end{aligned} \\]\n观测方程 观测方程，也就是状态量中的某种约束关系。一旦数学表达式列出来，求解就会顺其自然。\n相机 观测方程：\n\\[ \\begin{aligned} P_{w_l}\u0026=R_{b_i}^w(R_c^b\\frac{1}{\\lambda_l}\\pi_c^{-1}(\\begin{bmatrix}\\mu_l^{c_i}\\\\\\nu_l^{c_i}\\end{bmatrix})+p_c^b)+p_{b_i}^w \\\\[2mm] P_{w_l}\u0026=R_{b_j}^w(R_c^bP_l^{c_j}+p_c^b)+p_{b_j}^w \\\\[2mm] P_l^{c_j}\u0026=R_b^c\\{R_w^{b_j}[R_{b_i}^w(R_c^b\\frac{1}{\\lambda_l}\\overline{P}_l^{c_i}+p_c^b)+p_{b_i}^w-p_{b_j}^w]-p_c^b\\} \\end{aligned} \\]\n转换成矩阵形式：\n\\[ P_l^{c_j}=\\begin{bmatrix} R_b^cR_w^{b_j} \\\\ -R_b^cR_w^{b_j}R_{b_i}^w(R_c^b\\frac{1}{\\lambda_l}\\overline{P}_l^{c_i}+p_c^b)^{\\wedge} \\\\ -R_b^cR_w^{b_j} \\\\ R_b^c\\{R_w^{b_j}[R_{b_i}^w(R_c^b\\frac{1}{\\lambda_l}\\overline{P}_l^{c_i}+p_c^b)+p_{b_i}^w-p_{b_j}^w]\\}^\\wedge \\\\ R_b^c(R_w^{b_j}R_{b_i}^w-I_{3\\times3}) \\\\ -R_b^cR_w^{b_j}R_{b_i}^wR_c^b(\\frac{1}{\\lambda_l}\\overline{P}_l^{c_i})^{\\wedge}+(R_b^cR_w^{b_j}R_{b_i}^wR_c^b\\frac{1}{\\lambda_l}\\overline{P}_l^{c_i})^{\\wedge}+\\{R_b^c[R_w^{b_j}(R_{b_i}^wp_c^b+p_{b_i}^w-p_{b_j}^w)-p_c^b]\\}^{\\wedge} \\\\ -R_b^cR_w^{b_j}R_{b_i}^wR_c^b\\frac{1}{\\lambda_l^2}\\overline{P}_l^{c_i} \\end{bmatrix}^T *\\begin{bmatrix} p_{b_i}^w \\\\ q_{b_i}^w \\\\ p_{b_j}^w \\\\ q_{b_j}^w \\\\ p_c^b \\\\ q_c^b \\\\ \\lambda_l \\end{bmatrix} \\]\nIMU 观测方程：\n\\[ \\gamma_B=\\begin{bmatrix} R_w^{b_k}(p_{b_{k+1}}^w-p_{b_k}^w-\\nu_{b_k}^w\\Delta{t_k}+\\frac{1}{2}g^w\\Delta{t_k^2})-\\alpha_{b_{k+1}}^{b_k} \\\\ 2[\\gamma_{b_{k+1}}^{b_k}{\\otimes}{q_{b_k}^w}^{-1}\\otimes{q_{b_{k+1}}^w}] \\\\ R_w^{b_k}(\\nu_{b_{k+1}}^w-\\nu_{b_k}^w+g^w\\Delta{t_k})-\\beta_{b_{k+1}}^{b_k} \\\\ b_{a_{b_{k+1}}}-b_{a_{b_k}} \\\\ b_{\\omega_{b_{k+1}}}-b_{\\omega_{b_k}} \\end{bmatrix} \\]\n转换成矩阵形式：\n\\[ \\gamma_B=\\begin{bmatrix} -R_w^{b_k} \u00260 \u00260 \u00260 \u00260 \\\\ [R_w^{b_k}(p_{b_{k+1}}^w-p_{b_k}^w-\\nu_{b_k}^w\\Delta{t_k}+\\frac{1}{2}g^w\\Delta{t_k^2})]^\\wedge \u0026-\\mathcal{L}[{q_{b_{k+1}}^w}^{-1}\\otimes{q_{b_k}^w}]\\mathcal{R}[\\gamma_{b_{k+1}}^{b_k}] \u0026[R_w^{b_k}(\\nu_{b_{k+1}}^w-\\nu_{b_k}^w+g^w\\Delta{t_k})]^\\wedge \u00260 \u00260\\\\ -R_w^{b_k}\\Delta{t} \u00260 \u0026-R_w^{b_k} \u00260 \u00260\\\\ -\\mathcal{J}_{b_a}^\\alpha \u00260 \u0026-\\mathcal{J}_{b_a}^\\beta \u0026-I \u00260 \\\\ -\\mathcal{J}_{b_\\omega}^\\alpha \u0026-\\mathcal{L}[{q_{b_{k+1}}^w}^{-1}\\otimes{q_{b_k}^w}\\otimes\\gamma_{b_{k+1}}^{b_k}]\\mathcal{J}_{b_\\omega}^\\gamma \u0026-\\mathcal{J}_{b_\\omega}^\\beta \u00260 \u0026-I \\\\ R_w^{b_k} \u00260 \u00260 \u00260 \u00260 \\\\ 0 \u0026\\mathcal{L}[{\\gamma_{b_{k+1}}^{b_k}}^{-1}\\otimes{q_{b_{k}}^w}^{-1}\\otimes{q_{b_{k+1}}^w}] \u00260 \u00260 \u00260\\\\ 0 \u00260 \u0026R_w^{b_k} \u00260 \u00260\\\\ 0 \u00260 \u00260 \u0026I \u00260\\\\ 0 \u00260 \u00260 \u00260 \u0026I \\end{bmatrix}^T *\\begin{bmatrix} p_{b_k}^w \\\\ q_{b_k}^w \\\\ v_{b_k}^w \\\\ b_{a_k} \\\\ b_{\\omega_k} \\\\ p_{b_{k+1}}^w \\\\ q_{b_{k+1}}^w \\\\ v_{b_{k+1}}^w \\\\ b_{a_{k+1}} \\\\ b_{\\omega_{k+1}} \\end{bmatrix} \\]\n在线标定 相机与IMU外参标定 利用对极几何原理，估算出连续两帧图像之间的旋转矩阵\\(R\\)，根据手眼标定公式：\n\\[ q_{b_k b_{k+1}} \\otimes q_{bc} = q_{bc} \\otimes q_{c_k c_{k+1}} \\\\[2mm] \\left([q_{b_k b_{k+1}}]_L - [q_{c_k c_{k+1}}]_R\\right)q_{bc}=Q^k_{k+1} \\cdot q_{bc} = 0 \\]\n对应于CalibrationExRotation()函数，即可估算出相机与IMU外参。\n想法： 这一步估算出来的外参精度应该并不高，因为两帧间的旋转矩阵精度不高，且会受到陀螺仪bias的影响。 这一部分误差将会被吸收到下一步的bias估计值中。\nBias估计 为了更精细的标定bias，需要采用SFM的方法：\n relativePose 找到视察足够大的两帧，求解位姿 SolveFrameByPnP 求解每帧图片的位姿 triangulateTwoFrames 三角化地图点 triangulatePoint 三角化剩余点 Ceres 优化点和位姿  求解出所有图像帧的位姿，进行Bias估计：\n\\[ \\arg \\min_{\\delta b_g} \\sum_{k \\in B} \\| 2 \\lfloor q_{c_0 b_{k+1}}^{-1} \\otimes q_{c_0 b_k} \\otimes q_{b_k b_{k+1}} \\rfloor_{xyz} \\|^2 \\\\[2mm] q_{b_k b_{k+1}} \\approx \\hat{q}_{b_k b_{k+1}} \\otimes \\begin{bmatrix} 1 \\\\ \\frac{1}{2}J^q_{b_g} \\delta b_g \\end{bmatrix} \\]\nPVQ参数优化 P: 图像与IMU的位置对齐，仅缺少一个尺度s\nV: 每帧图像时刻对应的IMU的速度\nQ: 外参已对齐，缺少初始的绝对姿态，即初始重力的方向\n预积分公式重温：\n\\[ \\begin{aligned} p_{wb_j}\u0026=p_{wb_i}+v_i^w\\Delta t - \\frac{1}{2}g^w\\Delta t^2 + q_{wb_i}\\int\\int_{t\\in[i,j]}(q_{b_i b_t}a^{b_t})\\delta t^2 \\\\[2mm] v_j^w\u0026=v_i^w - g^w\\Delta t + q_{wb_i}\\int_{t\\in[i,j]}(q_{b_i b_t}a^{b_t})\\delta t \\\\[2mm] q_{wb_j}\u0026=q_{wb_i}\\int_{t\\in[i,j]}q_{b_i b_t}\\otimes\\begin{bmatrix}0 \\\\ \\frac{1}{2}w^{b_t} \\end{bmatrix} \\delta t \\end{aligned} \\]\n其中位置、速度的预积分中，包含了我们需要估计的所有参数。 以位置、速度的预积分作为观测值，列出如下方程：\n\\[ \\begin{aligned} \\begin{bmatrix} \\alpha_{b_i b_j} \\\\ \\beta_{b_i b_j} \\end{bmatrix}= \\begin{bmatrix} q_{b_i w}(p_{w b_j} - p_{w b_i} -v_i^w\\Delta t + \\frac{1}{2} g^w \\Delta t^2) \\\\ q_{b_i w}(v_j^w - v_i^w + g^w \\Delta t) \\end{bmatrix}= H \\cdot \\begin{bmatrix} v_k^{b_k} \\\\ v_{k+1}^{b_{k+1}} \\\\ g^{c_0} \\\\ s\\end{bmatrix} + n \\end{aligned} \\]\n即可进行最小二乘求解了。\n优化绝对位姿 对重力方向进行如下建模：\n\\[ \\hat g^{c_0} = \\|g\\| \\cdot \\hat{\\bar{g}}^{c_0} + w_1 \\vec{b_1} + w_2 \\vec{b_2} \\]\n重新进行优化，可以得到更精确的重力向量方向，即初始状态的绝对位姿。\n求解 使方程满秩可求解 信息矩阵 \\(H\\) 不满秩\n 用LM方法求解，会导致H满秩 --\u0026gt; 解在空间中整体变化 添加先验约束，增加系统可观性。例如固定第一个相机，\\(H_{[11]}+=I\\) 添加超强先验，使得对应的信息矩阵巨大\\(H_{[11]}=\\infty\\)，就能使得\\(\\Delta{x}=H^{-1}b=0\\) 设定对应雅克比矩阵为 0，则\\(H_{[11]}=0\\)，\\(b_{[1]}=0\\)。则在求解时，\\((0+\\lambda{I})\\Delta{x}=0\\)  舒尔补    更新先验残差 舒尔补之后的状态量的雅克比不再更新，当状态更新时，残差值需要同步更新。\n\\[ \\begin{aligned} b_p^{'}\u0026=b_p+\\frac{\\partial{b_p}}{\\partial{x_p}}\\delta{x_p}\\\\ \u0026=b_p+\\frac{\\partial{(-J^T\\Sigma^{-1}r)}}{\\partial{x_p}}\\delta{x_p}\\\\ \u0026=b_p-\\Lambda_p\\delta{x_p} \\end{aligned} \\]\nCeres在VINS-MONO中的使用 Ceres的具体用法，及其在VINS-MONO中的用法，请参考如下文章： non-linear\n","PublishDate":"2020-01-05T08:00:00+08:00","ReadingTime":3,"RelPermalink":"/vins-mono/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-03T20:43:43.505468315+08:00","Mode":436,"Name":"index.md","Size":11968},"Tags":null,"Title":"VINS-MONO","Type":"blog","Weight":0,"WordCount":634},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"orb-slam2","Dir":"blog/slam/orb-slam2/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/slam/orb-slam2/index.md","TranslationBaseName":"index","UniqueID":"750d5dc9106c12cc575da461ae8af27a"},"FuzzyWordCount":600,"GitInfo":{"hash":"728d17c99481cb14d1e8283cabb76251ed51e4e7","abbreviatedHash":"728d17c","subject":"add rtk page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-01-29T23:12:48+08:00","commitDate":"2020-02-02T11:55:13+08:00"},"Kind":"page","Lastmod":"2020-01-29T23:12:48+08:00","Len":13215,"Name":"ORB-SLAM2","Permalink":"https://nuhuo08.github.io/orb-slam2/","Plain":"Tracking Initialization SearchForInitialization --\u0026gt; Initialize(RANSAC) --\u0026gt; GlobalBundleAdjustemnt --\u0026gt; ComputeSceneMedianDepth\nSearchForInitialization:\nGetFeaturesInArea --\u0026gt; DescriptorDistance --\u0026gt; ComputeThreeMaxima\nORB特征\nOriented FAST关键点：\n 比较像素点周围圆上的像素间亮度的差异 非极大值抑制，在一定区域内仅保留响应极大值的角点，避免太集中 对角点计算Harris响应值，仅保留前N个具有最大响应值的角点 构建金字塔，在金字塔每一层检测角点。实现尺度不变 灰度质心法，连接图像块的几何中心与质心。实现旋转不变  BRIEF描述子：\n 随机选点并比较灰度，组成128维的二进制数组 使用Hamming distance作为度量，即不同位数的个数  F矩阵\nhttps://zhuanlan.zhihu.com/p/61614421\n在求解F和H矩阵之前，应该首先进行特征点归一化，保证坐标均值为0，一阶绝对矩为1。(MVG P67，归一化才能消除坐标变换的影响)\n设\\(p1\\)，\\(p2\\)为像素坐标，可知：\n\\[ p_2 = K (RP + t) \\\\[2mm] p_1 = KP \\]\n从上述\\(p1\\)，\\(p2\\)的关系式出发，导出：\n\\[ (K^{-1} p_2)^T t^{\\wedge} K^{-1} p_2 = 0 = p_2^T K^{-T} t^{\\wedge} R K^{-1} p_1 = p_2^T F p_1 \\]\n一对匹配的像素点可以写1个方程，考虑到尺度等价性，使用八点法即可求解\\(F\\)矩阵。\nTODO: 由基础矩阵F分解出R和t\n多余的话\nopencv中，cv::findFundamentalMat()如果选择8点法，则是直接将所有点进行最小二乘计算，没有外点剔除功能。\nhttps://stackoverflow.com/questions/25251676/opencv-findfundamentalmat-very-unstable-and-sensitive/48394798\nH矩阵\n平面方程为：\n\\[ aX + bY + cZ + d = 0 \\\\[2mm] -\\frac{n^TP}{d} = -1 \\]\n依旧从\\(p1\\)，\\(p2\\)的关系式出发，导出：\n\\[ p_2 = K (RP + t \\cdot (-\\frac{n^TP}{d})) = K (R - \\frac{tn^T}{d}) K^{-1} p_1 = Hp_1 \\]\n一对匹配的像素点可以写2个方程，因此4对匹配特征点即可求解\\(H\\)矩阵。\nTODO: 由单应矩阵H恢复出R和t\nF与H的评分\n\\[ S_M = \\sum_i\\{ \\rho_M\\left(d_{cr}^2\\left(x_c^i,x_r^i,M\\right)\\right)+ \\rho_M\\left(d_{rc}^2\\left(x_c^i,x_r^i,M\\right)\\right) \\} \\\\[2mm] \\rho_M\\left(d^2\\right)=\\begin{cases} \\Gamma - d^2, \u0026\\text{if } d^2 T_M\\end{cases} \\]\n其中，\\(M\\)为\\(H\\)或者\\(F\\)。\\(T_M\\)为距离阈值，根据95%的\\(\\chi^2\\)测试设置。 \\(T_H=5.99\\)（两个自由度），\\(T_F=3.84\\)（1个自由度）。这里假设标准差为1个像素。\n\\(\\Gamma\\) is defined equal to \\(T_H\\) so that both models score equally for the same d in their inlier region, again to make the process homogeneous.\n\\[ R_H=\\frac{S_H}{S_H+S_F} \\]\nselect the homography if \\(R_H0.45\\), which adequately captures the planar and low parallax cases. Otherwise, we select the fundamental matrix.\n三角化\nhttps://blog.csdn.net/weixin_43795395/article/details/93769148\nhttps://www.cnblogs.com/yepeichu/p/10792899.html\n已知匹配的像素点，及两帧图像的变换关系，则：\n\\[ x = PX \\\\[2mm] x' = P'X \\]\n根据\\(x^\\wedge PX = 0\\)性质，可得到如下方程：\n\\[ AX = \\begin{bmatrix} xp^{3T}-p^{1T} \\\\ yp^{3T}-p^{2T} \\\\ x'p'^{3T}-p'^{1T} \\\\ y'p'^{3T}-p'^{2T} \\end{bmatrix} X = 0 \\]\n对矩阵\\(A\\)进行SVD分解，可知：\n\\[ J(y) = \\min \\|Ax\\| = \\min \\|UDV^Tx\\| = \\min \\|DV^Tx\\| \\]\n由于对角阵\\(D\\)是矩阵\\(A\\)的奇异值从大到小降序排列而成，因此\\(J(y)\\) 的最小值在\\(D\\)矩阵奇异值最小的地方取到。可知：\n\\[ V^Tx = y = [0, 0, 0, 1]^T \\\\[2mm] x = Vy \\]\n于是，\\(x\\)的解就变成了正交矩阵\\(V\\)的最后一列的列向量。\n多余的话——解方程\nhttp://eigen.tuxfamily.org/dox/group__LeastSquares.html\n对于方程：\n\\[ Mx = b \\]\n可以使用最小二乘解\\(x = (M^T M)^{-1} M^T b\\)，或者利用QR分解\\(x = R^{-1} Q^T b\\)。\n将b移到左边，并设最后一个参数为1，可转换成如下方程：\n\\[ Mx = 0 \\]\n可以通过SVD分解，解对应于\\(M\\)最小特征值对应的特征向量。关于\\(M\\)与\\(M^T M\\)的SVD分解的关系， 可以参考matrix。\nTracking TrackWithMotionModel\nSearchByProjection --\u0026gt; PoseOptimization\nSearchByProjection:\nGetFeaturesInArea --\u0026gt; DescriptorDistance\nTrackWithReferenceKeyFrame\nSearchByBow --\u0026gt; PoseOptimization\nSearchByBow:\nFeatureVector --\u0026gt; DescriptorDistance --\u0026gt; ComputeThreeMaxima\nRelocalization\nSearchByBow --\u0026gt; EPnP(RANSAC) --\u0026gt; PoseOptimization --\u0026gt; SearchByProjection --\u0026gt; PoseOptimization\nEPnP:\nhttps://zhuanlan.zhihu.com/p/59070440\n 3D点的齐次坐标被表示为4个控制点齐次坐标的线性组合，然后将其作为已知量拿到相机坐标系下使用。 结合上一步，将相机坐标系下的空间点坐标，转换成4个控制点在摄像机坐标系下的坐标的线性组合，并结合对应的像素点坐标，建立方程，从而解算出控制点在摄像机坐标系下的坐标。 最后根据4个控制点，将所有的3D点在摄像机坐标系下的坐标恢复出来。接着采用ICP方法，求解出R和t。  ICP:\n 计算两组点的质心位置，然后计算每个点的去质心坐标  \\[ q_i = p_i - p \\\\[2mm] q_i' = p_i' - p' \\]\n求取R  \\[ W = \\sum_{i=1}^n q_i q_i'^T = U \\Sigma V^T \\\\[2mm] R = UV^T \\]\n求取t  \\[ t = p - R p' \\]\n\n题外话———未知对应关系的ICP：\n 根据距离最小寻找对应点 根据对应点，计算R和t 对点云进行转换，计算误差 重新寻找对应点，不断迭代，直至误差小于某一个值  属于EM算法的一种，待求变量为\\( [R | t] \\)，隐变量为点的对应关系。先固定第一个变量，优化另一个；再固定另一个，优化第一个变量。通过多次优化后，两个变量都达到最优值。\nUpdateLocalMap\nSearchByProjection --\u0026gt; PoseOptimization\nLocalMapping ComputeBow --\u0026gt; SearchForTriangulation --\u0026gt; LocalBA\nSearchForTriangulation:\nFeatureVector --\u0026gt; DescriptorDistance --\u0026gt; CheckDistEpipolarLine --\u0026gt; ComputeThreeMaxima\n关于优化中的卡方分布外点剔除\nhttps://zhuanlan.zhihu.com/p/58556978\n高斯白噪声的平方服从卡方分布，有几个观测量就代表几个自由度。\nLoopClosing TF-IDF TF: Term Frequency, 指某个特征在单幅图像中出现的频率。\n\\[ TF_i = \\frac{n_i}{n} \\]\nIDF: Inverse Document Frequency, 指单词在字典中出现的频率越高，则分类图像时区分度越高。\n\\[ IDF_i = \\log \\frac{n}{n_i} \\]\nComputeSim3 SearchByBow --\u0026gt; sim3(RANSAC) --\u0026gt; SearchBySim3 --\u0026gt; OptimizeSim3 --\u0026gt; SearchByProjection\n当两个姿态比较接近时，sim3求解不出有效值。这也是闭环成功后，后续很长一段时间里，不再进行闭环的原因。\nsim3:\n\nLoopClosing OptimizeEssentialGraph --\u0026gt; RunGlobalBundleAdjustment\nOptimization 点与位姿优化\n\\[ \\xi^* = \\arg \\min_\\xi \\frac{1}{2} \\sum_{i=1}^n {\\| u_i - \\frac{1}{s} K \\exp(\\xi^\\wedge) P_i \\|}_2^2 \\\\[2mm] P' = TP = RP + t \\\\[2mm] \\begin{bmatrix} u \\\\ v \\end{bmatrix} = \\begin{bmatrix}f_x \u00260 \u0026c_x \\\\ 0 \u0026f_y \u0026c_y\\end{bmatrix} \\begin{bmatrix}\\frac{X'}{Z'} \\\\ \\frac{Y'}{Z'}\\end{bmatrix} \\]\n回环（采用左扰动）\n实际ORB-SLAM的Pose Graph是采用的Sim3变换。此处仅推导SE(3)上的公式。\n\\[ \\begin{aligned} e_{ij} \u0026= \\ln (T_{ij}^{-1} T_i^{-1} T_j)^\\vee \\\\[2mm] \u0026= \\ln (T_{ij}^{-1} T_i^{-1} \\exp((-\\xi_i)^\\wedge) T_j)^\\vee \\\\[2mm] \u0026= \\ln (T_{ij}^{-1} T_i^{-1} T_j \\exp((-Ad(T_j^{-1})\\delta\\xi_i)^\\wedge))^\\vee \\\\[2mm] \u0026= \\ln (\\exp(e_{ij}^\\wedge) \\exp((-Ad(T_j^{-1})\\delta\\xi_i)^\\wedge))^\\vee \\\\[2mm] \u0026= \\mathcal{J}_r^{-1}(e_{ij}) (-Ad(T_j^{-1})\\delta\\xi_i) + e_{ij} \\\\[2mm] \\frac{ \\partial{e_{ij}} }{ \\partial{\\delta\\xi_i} } \u0026= -\\mathcal{J}_r^{-1}(e_{ij}) Ad(T_j^{-1}) \\end{aligned} \\]\n同理可得：\n\\[ \\frac{ \\partial{e_{ij}} }{ \\partial{\\delta\\xi_j} } = \\mathcal{J}_r^{-1}(e_{ij}) Ad(T_j^{-1}) \\]\n有以下近似关系：\n\\[ \\mathcal{J}_r^{-1}(e_{ij}) \\approx I + \\frac{1}{2} \\begin{bmatrix} \\phi_e^\\wedge \u0026\\rho_e^\\wedge \\\\ 0 \u0026\\phi_e^\\wedge \\end{bmatrix} \\]\nBowVector \u0026amp; FeatureVector    BowVector存储着叶子节点，信息最细微，仅用在DetectRelocalizationCandidates()函数中，用来选取备选帧。\nFeatureVector存储着倒数第4层的节点，信息比较粗糙，用在各种SearchBy*函数中，用来加速特征点的匹配。\nFeatureVector --\u0026gt; FClass 计算特征向量之间的距离，用于加速特征点匹配\nBowVector --\u0026gt; ScoringObject 计算单词之间的分数，用于匹配回环关键帧\nHKmeasStep --\u0026gt; createWords --\u0026gt; setNodeWeights\n先使用Kmeans++分为分层node；再将最后一层编码为word；最后每张图片对某个word计数最多加一次，计算权值\ng2o 采用se3表达参数；\n首先进行块分解，BlockSolver默认使用舒尔补消除变量;\n之后进行线性求解。其中LinearSolverDense直接进行Cholesky分解，LinearSolverEigen需要调用Eigen的稀疏Cholesky分解，且默认不reordering。因为在Schur之后，矩阵比较稠密，reordering影响不大；\nVeterx: oplusImpl\nEdge: ComputeError \u0026amp; linearizeOplus\nhttps://zhuanlan.zhihu.com/p/100522179\n","PublishDate":"2020-01-04T08:00:00+08:00","ReadingTime":3,"RelPermalink":"/orb-slam2/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-02T11:55:12.961972492+08:00","Mode":436,"Name":"index.md","Size":9592},"Tags":null,"Title":"ORB-SLAM2","Type":"blog","Weight":0,"WordCount":559},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"msckf","Dir":"blog/slam/msckf/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/slam/msckf/index.md","TranslationBaseName":"index","UniqueID":"20bee235d2984684431c97569aafb493"},"FuzzyWordCount":700,"GitInfo":{"hash":"bf7621240467f86da60feffc5bd1fe617e26440c","abbreviatedHash":"bf76212","subject":"add move_base page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-03-15T14:08:34+08:00","commitDate":"2020-03-15T14:08:34+08:00"},"Kind":"page","Lastmod":"2020-03-15T14:08:34+08:00","Len":7642,"Name":"MSCKF","Permalink":"https://nuhuo08.github.io/msckf/","Plain":"前端跟踪  根据IMU给出的旋转量，假设相机发生了纯旋转，估算下一帧特征点的位置； 使用LK光流法，进一步优化特征点的位置； 判断是否为纯旋转。若不是纯旋转，则使用RANSAC方法，随机选2个点，估算出最优的平移量； 将图像分成网格，每个网格最多4个特征点，保证特征点均匀分布。  QR分解 \\[ A_{2m \\times 3} = Q_{2m \\times 2m}R_{2m \\times 3} = \\begin{bmatrix} B_{2m \\times 3} \u0026C_{2m \\times (2m - 3)} \\end{bmatrix} \\begin{bmatrix} D_{3 \\times 3} \\\\ 0_{(2m - 3) \\times 3} \\end{bmatrix} \\]\n其中，\\(Q\\) 为正交矩阵，每一列代表一个基向量，与除了自身以外的其他基向量的点积都为0。Where \\(B\\) and \\(C\\) are unitary matrices whose columns form bases for the range and nullspace of \\(A\\).\n\\[ {C^T}_{(2m-3) * 2m} A_{2m \\times 3} = \\begin{bmatrix} 0_{(2m-3) \\times 3} \u0026I_{(2m-3) \\times (2m - 3)} \\end{bmatrix} \\begin{bmatrix} D_{3 \\times 3} \\\\ 0_{(2m - 3) \\times 3} \\end{bmatrix} = 0_{(2m-3) \\times 3} \\]\n\\(C\\)称为\\(A\\)的左零空间，当左乘\\(C^T\\)以后，整个矩阵都变为0。\n\\[ {B^T}_{3 * 2m} A_{2m \\times 3} = \\begin{bmatrix} I_{3 \\times 3} \u00260_{3 \\times (2m - 3)} \\end{bmatrix} \\begin{bmatrix} D_{3 \\times 3} \\\\ 0_{(2m - 3) \\times 3} \\end{bmatrix} = D_{3 \\times 3} \\]\n当左乘\\(B^T\\)以后，仅重要信息被保留下来为\\(D\\)\n状态量 当前IMU状态\\(15\\)维，加上滑窗内\\(N\\)帧图像，每个相机位姿6维，共计\\(15+6N\\)\n\\[ {\\hat{X}}_k = \\begin{bmatrix} ^I_G\\bar{q} \\\\ {b_g} \\\\ {^Gv_I} \\\\ {b_a} \\\\ {^Gp_I} \\\\ {^{C_1}_G\\hat{\\bar{q}}} \\\\ ^G\\hat{p}_{C_1} \\\\ \\vdots \\\\ {^{C_N}_G\\hat{\\bar{q}}} \\\\ ^G\\hat{p}_{C_N} \\end{bmatrix} \\]\n状态增广 当增加第\\(N+1\\)个新的相机位姿时，状态向量需要增广。\n\\[ \\begin{bmatrix} ^I_G\\bar{q}^T \\\\ {b_g}^T \\\\ {^Gv_I}^T \\\\ {b_a}^T \\\\ {^Gp_I}^T \\\\ {^{C_1}_G\\hat{\\bar{q}}}^T \\\\ ^G\\hat{p}_{C_1}^T \\\\ \\vdots \\\\ {^{C_N}_G\\hat{\\bar{q}}}^T \\\\ ^G\\hat{p}_{C_N}^T \\\\ {^{C_{N+1}}_G\\hat{\\bar{q}}}^T \\\\ ^G\\hat{p}_{C_{N+1}}^T \\end{bmatrix} = \\underbrace{\\begin{bmatrix} I \u00260 \u00260 \u00260 \u00260 \u00260 \u00260 \u0026\\cdots \u00260 \u00260\\\\ 0 \u0026I \u00260 \u00260 \u00260 \u00260 \u00260 \u0026\\cdots \u00260 \u00260\\\\ 0 \u00260 \u0026I \u00260 \u00260 \u00260 \u00260 \u0026\\cdots \u00260 \u00260\\\\ 0 \u00260 \u00260 \u0026I \u00260 \u00260 \u00260 \u0026\\cdots \u00260 \u00260\\\\ 0 \u00260 \u00260 \u00260 \u0026I \u00260 \u00260 \u0026\\cdots \u00260 \u00260\\\\ 0 \u00260 \u00260 \u00260 \u00260 \u0026I \u00260 \u0026\\cdots \u00260 \u00260\\\\ 0 \u00260 \u00260 \u00260 \u00260 \u00260 \u0026I \u0026\\cdots \u00260 \u00260\\\\ \u0026 \u0026 \u0026 \u0026\\vdots \\\\ 0 \u00260 \u00260 \u00260 \u00260 \u00260 \u00260 \u0026\\cdots \u0026I \u00260\\\\ 0 \u00260 \u00260 \u00260 \u00260 \u00260 \u00260 \u0026\\cdots \u00260 \u0026I\\\\ C(^C_I\\bar{q}) \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026\\cdots \u00260 \u00260 \\\\ \\lfloor C_{\\hat{q}}^T p_C \\times \\rfloor \u00260 \u00260 \u0026 0 \u0026I \u00260 \u00260 \u0026\\cdots \u00260 \u00260 \\end{bmatrix}}_A * \\begin{bmatrix} ^I_G\\bar{q}^T \\\\ {b_g}^T \\\\ {^Gv_I}^T \\\\ {b_a}^T \\\\ {^Gp_I}^T \\\\ {^{C_1}_G\\hat{\\bar{q}}}^T \\\\ ^G\\hat{p}_{C_1}^T \\\\ \\vdots \\\\ {^{C_N}_G\\hat{\\bar{q}}}^T \\\\ ^G\\hat{p}_{C_N}^T \\end{bmatrix} \\]\n对应的协方差矩阵也需要进行传播。 \\( P_{k|k} = A P_{k|k} A^T \\)\n多余的话\n关于协方差增广，可以与 slam for dummies 进行对比学习。在该文中，新的特征点与当前的机器人位姿、激光观测量都有关系，其协方差为：\n\\[ P^{N+1 \\ N+1} = J_{xr} P J_{xr}^T + J_z R J_z^T \\]\n三角化点 将相机坐标当作已知值，优化共同观测到的某个特征点坐标\n\\[ h = \\begin{pmatrix} h_0 \\\\ h_1 \\\\ h_2 \\end{pmatrix} = R \\begin{pmatrix} \\frac{X}{Z} \\\\ \\frac{Y}{Z} \\\\ 1 \\end{pmatrix} + \\frac{1}{Z} t = R \\begin{pmatrix} \\alpha \\\\ \\beta \\\\ 1 \\end{pmatrix} + \\rho t \\\\ z = \\begin{pmatrix} \\frac{h_0}{h_2} \\\\ \\frac{h_1}{h_2} \\end{pmatrix} \\]\n由此得到雅可比矩阵：\n\\[ \\begin{aligned} J \u0026= \\frac{\\partial e_i}{\\partial(\\alpha, \\beta, \\rho)} = -\\frac{\\partial z}{\\partial h} \\begin{bmatrix} \\frac{\\partial h}{\\partial \\alpha} \u0026 \\frac{\\partial h}{\\partial \\beta} \u0026 \\frac{\\partial h}{\\partial \\rho} \\end{bmatrix} \\\\ \u0026= -\\begin{bmatrix} \\frac{1}{h_2} \u0026 0 \u0026 -\\frac{h_0}{h_2^2} \\\\ 0 \u0026 \\frac{1}{h_2} \u0026 -\\frac{h_1}{h_2^2} \\end{bmatrix} \\begin{bmatrix} R\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} \u0026 R\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} \u0026 t \\end{bmatrix} \\\\ \\end{aligned} \\]\n观测模型 特征点坐标是根据相机坐标计算出来的，而观测量误差同时与特征点和相机的坐标误差相关。\n\\[ ^{C_i} p_j = \\begin{bmatrix} ^{C_i} \\hat X_j \\\\ ^{C_i} \\hat Y_j \\\\ ^{C_i} \\hat Z_j \\end{bmatrix} =C(^{C_i} _G \\hat q)(^G \\hat p _{j} - ^G \\hat p _{C_i}) \\\\ \\hat z_i^{(j)} = \\begin{bmatrix} \\frac{^{C_i} \\hat X_j}{^{C_i} \\hat Z_j} \\\\ \\frac{^{C_i} \\hat Y_j}{^{C_i} \\hat Z_j} \\end{bmatrix} \\]\n对相机位姿、特征点位置的误差求雅可比：\n\\[ \\begin{aligned} r_i^{(j)} \u0026\\approx \\frac{\\partial z_i^{(j)}}{\\partial ^{C_i} p_j} \\frac{\\partial ^{C_i} p_j}{\\partial X_{C_i}} \\tilde X + \\frac{\\partial z_i^{(j)}}{\\partial ^{C_i} p_j} \\frac{\\partial ^{C_i} p_j}{\\partial ^Gp_j} {^G}{\\tilde{p}_{j}} \\\\ \u0026= \\begin{bmatrix} \\frac{1}{^{C_i} \\hat Z_j} \u0026 0 \u0026 -\\frac{^{C_i} \\hat X_j}{^{C_i} \\hat Z_j} \\\\ 0 \u0026 \\frac{1}{^{C_i} \\hat Z_j} \u0026 -\\frac{^{C_i} \\hat Y_j}{^{C_i} \\hat Z_j} \\end{bmatrix} \\begin{bmatrix} \\lfloor {^{C_i} \\hat p _{j}}_\\times \\rfloor \u0026 -C(^{C_i} _G \\hat q) \\end{bmatrix} \\tilde X + \\begin{bmatrix} \\frac{1}{^{C_i} \\hat Z_j} \u0026 0 \u0026 -\\frac{^{C_i} \\hat X_j}{^{C_i} \\hat Z_j} \\\\ 0 \u0026 \\frac{1}{^{C_i} \\hat Z_j} \u0026 -\\frac{^{C_i} \\hat Y_j}{^{C_i} \\hat Z_j} \\end{bmatrix} \\begin{bmatrix} C(^{C_i} _G \\hat q) \\end{bmatrix} {^G}{\\tilde{p}_{j}} \\end{aligned} \\]\n精华：将观测到该特征点的多个相机观测值累积到一起形成大型矩阵，并将观测量误差投影到相机坐标误差雅可比矩阵的左零空间中，消去特征点坐标误差。由此，观测量误差仅与相机坐标误差相关！\n\\[ \\begin{aligned} r^{(j)} \u0026\\simeq H_X^{(j)} \\tilde{X} + H_f^{(j)} {^G}{\\tilde{p}_{f_j}} + n^{(j)} \\\\ r_o^{(j)} = A^T r^{(j)} \u0026\\simeq A^T H_X^{(j)} \\tilde{X} + A^Tn^{(j)} = H_o^{(j)} \\tilde{X} ^{(j)} + n_o^{(j)} \\end{aligned} \\]\n滤波更新 使用QR分解，仅保留观测值中的有效信息。\n\\[ \\begin{aligned} r_o \u0026= \\begin{bmatrix} Q_1 \u0026Q_2 \\end{bmatrix} \\begin{bmatrix} T_H \\\\ 0 \\end{bmatrix} \\tilde{X} + n_o \\\\[2mm] r_n \u0026= Q_1^Tr_o = T_H \\tilde{X} + n_n \\end{aligned} \\]\n滑窗的特殊性 MSCKF采用的是滤波方法，维护的是协方差，当要边缘化一个变量时，直接将其对应的行和列去掉即可！\n这与其他基于图优化的SLAM算法有显著区别。图优化SLAM需要维护H矩阵，即信息矩阵。信息矩阵的某一变量的边际概率，需要进行舒尔补操作！\n","PublishDate":"2020-01-03T08:00:00+08:00","ReadingTime":4,"RelPermalink":"/msckf/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-03-15T14:07:38.259579335+08:00","Mode":436,"Name":"index.md","Size":6576},"Tags":null,"Title":"MSCKF","Type":"blog","Weight":0,"WordCount":685},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"amcl","Dir":"blog/ros/amcl/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/ros/amcl/index.md","TranslationBaseName":"index","UniqueID":"f453833cc0b7c5facd4816615a6d3ac6"},"FuzzyWordCount":200,"GitInfo":{"hash":"4683dbffaee4d5bf50fdefff847029bd5ae2b501","abbreviatedHash":"4683dbf","subject":"add bayesian-filter","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-02-10T22:40:25+08:00","commitDate":"2020-02-10T22:40:25+08:00"},"Kind":"page","Lastmod":"2020-02-10T22:40:25+08:00","Len":6364,"Name":"AMCL","Permalink":"https://nuhuo08.github.io/amcl/","Plain":"ROS-AMCL    粒子滤波基本原理请参考 Particle Filter\n粒子聚类 对外输出的机器人状态不应该是某一个最好的粒子，因为很有可能某些粒子的值都非常接近，可能会引起频繁的粒子切换，导致输出的结果来回跳变。\n基于此考虑， 应该对相似的粒子进行聚类。将最好的那一簇粒子的统计状态作为输出的机器人状态。\nKD-Tree 当涉及到距离查找时，作为算法工程师，我们应该首先想到KD-Tree。树的叶子节点是每一个粒子，而非叶子节点则保存的是该节点的分叉判断的标准，小于此分叉判断标准的在左边，大于此分叉标准的在右边。\n查询的基本思路：首先通过二叉树搜索（比较待查询节点和分裂节点的分裂维的值，小于等于就进入左子树分支，等于就进入右子树分支直到叶子结点），顺着“搜索路径”很快能找到最近邻的近似点，也就是与待查询点处于同一个子空间的叶子结点；然后再回溯搜索路径，并判断搜索路径上的结点的其他子结点空间中是否可能有距离查询点更近的数据点，如果有可能，则需要跳到其他子结点空间中去搜索（将其他子结点加入到搜索路径）。重复这个过程直到搜索路径为空。\n   聚类 循环遍历每一个叶子节点，在叶子节点周围的 +-1 范围内的粒子都归为一类。例如在AMCL中，每个粒子周围27个粒子若有相连的，就将它们全部连成一片，形成一簇粒子。\n粒子滤波改进 为了防止机器人被绑架，出现粒子收敛于某一错误的地方，需要进行粒子滤波的改良。\n粒子注入 我们来考虑如下的式子：\n\\[ x_1 = x + 0.1(y-x) \\\\[2mm] x_2 = x + 0.9(y-x) \\]\n对于上面两个式子，展开以后我们可以发现：\\(x_1\\) 主要受到 \\(x\\) 的影响，而 \\(x_2\\) 主要受到 \\(y\\) 的影响。若粒子收敛于正确的状态，则 \\(y\\) 是准确的，\\(x_2\\) 将会比 \\(x_1\\) 更大，此时不需要注入粒子。若粒子收敛于错误的地方，则 \\(y\\) 不准确，此时 \\(x_1\\) 受到 \\(y\\) 的影响较小，\\(x_1\\) 更准确，此时便需要注入粒子。\n而这正是AMCL里面slow和fast参数产生的效果。\nKLD自适应 KLD的计算属于数理统计的知识，可参考论文1。这里进行直观的解释。\n例如，某一粒子权值很大。当我们进行100次采样，可能都采样到的是同一个粒子，此时粒子的个数始终保持为1。而KLD计算出来的需要采样的次数，是粒子个数的函数。因此，当粒子数保持为1时，KLD计算出来的次数为某一定值，而采样次数持续在增加，到某一时间点，便超过了需要的采样次数。\n而当粒子权值都接近时，假设我们采样了100次，每次采样出来的粒子都不同，此时粒子的个数一直增长到100。此时的KLD也随着粒子的个数增长到一个比较大的值。采样的次数虽然持续增加，但是始终超过不了KDL计算出来的次数。此种情况下采样仍将继续。\n距离计算 计算每个粒子的权重时，我们需要计算观测到的障碍物与地图中的障碍物的距离差异。差异越大，权值越小。当某次观测的障碍物全部与地图上的障碍物匹配上了，则差异为0，权值极大。因此，在地图的初始阶段，我们需要计算地图上任一点位置到最近障碍物的距离。这就是似然场模型。\n直接计算 遍历每一个点，计算每一个点到每个障碍物的距离并取最小值。此方法进行了重复计算，效率较低。\n高效算法 从障碍物出发，向外膨胀一个单位。当所有障碍物膨胀完以后，从膨胀出来的地方出发，继续向外膨胀一个单位。此方法没有冗余计算，且实现的代码简洁。\nAMCL参数解读 min_particles / max_particles / kld_err / kld_z : 用来限制粒子数量\nupdate_min_d / update_min_a / resample_interval : 限制冲采样条件\nrecovery_alpha_slow / recovery_alpha_fast : 动态调整粒子数量\ninitial_pose_xya / initial_cov_xxyyaa : 初始位置及其协方差\nodom_alpha1234 : 里程计运动模型误差系数\n参考资料 http://www.robots.ox.ac.uk/~cvrg/hilary2005/adaptive.pdf\nhttps://blog.csdn.net/Mark_SLAM/article/details/81266527\nhttps://zhuanlan.zhihu.com/p/28137335\nhttps://zhuanlan.zhihu.com/p/59411695\nhttps://zhuanlan.zhihu.com/p/59663340\nhttps://zhuanlan.zhihu.com/p/61908381\nudacity robot\ngithub particle filter\n","PublishDate":"2020-01-02T08:00:00+08:00","ReadingTime":1,"RelPermalink":"/amcl/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-10T10:05:12.43864996+08:00","Mode":436,"Name":"index.md","Size":4902},"Tags":null,"Title":"AMCL","Type":"blog","Weight":0,"WordCount":105},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"hugo-website","Dir":"blog/tools/hugo-website/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"blog/tools/hugo-website/index.md","TranslationBaseName":"index","UniqueID":"27183decc678898fbd825d96c0f31f67"},"FuzzyWordCount":200,"GitInfo":{"hash":"a532c055524d39d8899137f1f3d73e1e16fc7067","abbreviatedHash":"a532c05","subject":"add comment section","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-02-07T21:59:49+08:00","commitDate":"2020-02-07T21:59:49+08:00"},"Kind":"page","Lastmod":"2020-02-07T21:59:49+08:00","Len":3187,"Name":"Hugo搭建网站","Permalink":"https://nuhuo08.github.io/hugo-website/","Plain":"申请Github账号 Github私人博客仓库 新建Hugo_Blogs仓库，此仓库保存个人的markdown源文件等。可设置为private仓库。\nGithub Pages 新建username.github.io的仓库，此仓库保存Hugo生成出来的html文件等。https://username.github.io/即为最终的个人博客地址。必须设置为public仓库。\n安装Hugo Hugo Tutorial\nBinary Package\n新建私人博客文件夹 创建网站文件夹 新建网站文件夹，并用hugo生成基本网站文件\nmkdir MyWebsite \u0026amp;\u0026amp; cd MyWebsite hugo new site . 链接Github私人博客仓库 添加git源，保存私人的markdown源文件\ngit init git remote add origin https://github.com/username/Hugo_Blogs.git 添加并使用新的theme git submodule add https://github.com/nuhuo08/uswds-hugo-theme.git themes/uswds-hugo-theme git submodule update --remote --merge cp themes/uswds-hugo-theme/exampleSite/config.yaml . 修改配置 设置 utterances，链接到username/username.github.io仓库，开启utterance修改Issue的权限。\n在config.yaml文件中，修改params.utter.repo属性为username/username.github.io；\n修改baseURL属性为https://username.github.io/\n编辑网页 链接Github Pages 为了能够使用git submodule，需要先在仓库里添加点文件，之后再把它删掉。\nmkdir public \u0026amp;\u0026amp; cd public \u0026amp;\u0026amp; touch abc git remote add origin https://github.com/username/username.github.io.git git add . git commit -m \u0026quot;abc\u0026quot; git push orign master cd .. \u0026amp;\u0026amp; rm -rf public 然后再添加submodule，继续进行下一步。\ncd MyWebsite git submodule add https://github.com/username/username.github.io.git public 创建第一个网页 mkdir content/blog vi content/blog/my-first-blog.md 生成并本机预览网页 hugo hugo server -D 将改动上传至2个Git仓库 发布网页 hugo # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` cd MyWebsite/public git add . git commit git push origin master 保存私人博客源文件 cd MyWebsite git add . git commit git push origin master ","PublishDate":"2020-01-01T08:00:00+08:00","ReadingTime":1,"RelPermalink":"/hugo-website/","Section":"blog","Stat":{"IsDir":false,"ModTime":"2020-02-07T21:25:02.764089465+08:00","Mode":436,"Name":"index.md","Size":2368},"Tags":null,"Title":"Hugo搭建网站","Type":"blog","Weight":0,"WordCount":140},{"Aliases":null,"File":{"BaseFileName":"index","ContentBaseName":"about","Dir":"about/","Ext":"md","Lang":"en","LogicalName":"index.md","Path":"about/index.md","TranslationBaseName":"index","UniqueID":"8576ec274c98b3831668a172fa632d80"},"FuzzyWordCount":100,"GitInfo":{"hash":"21f2f18c7b9283baf992e6ff1419c73a1a13d764","abbreviatedHash":"21f2f18","subject":"add amcl page","authorName":"nuhuo08","authorEmail":"845776955@qq.com","authorDate":"2020-01-25T18:24:08+08:00","commitDate":"2020-02-02T11:55:08+08:00"},"Kind":"page","Lastmod":"2020-01-25T18:24:08+08:00","Len":850,"Name":"About","Permalink":"https://nuhuo08.github.io/about/","Plain":"转眼已2020年，自己马上也要30了。三十而立，却一直没有可见的成绩。见过很多优秀的人，对自己的无所作为愈加愤怒。\n昨天晚上重读中央文献出版社的《毛泽东传》，看到这样一句话：\n\r\r毛泽东第一次进入中国共产党的领导核心，这时他三十岁，刚好是“而立”之年。\r\r慢慢的开始接受自己的平凡。不过，虽身不能至，然心向往之。从今天开始整理自己的私人网站，总结以前学过的各种知识， 记录自己的生活点滴与感悟，权当作一点点慰藉吧。\n\r\rTo learn, read; To know, write; To master, teach.\r\r做一点事，发一点光，写一点博客，找一点意义。\n","PublishDate":"2020-01-01T00:00:00Z","ReadingTime":1,"RelPermalink":"/about/","Section":"","Stat":{"IsDir":false,"ModTime":"2020-02-04T17:11:25.283417297+08:00","Mode":436,"Name":"index.md","Size":855},"Tags":null,"Title":"About","Type":"page","Weight":0,"WordCount":15}],"site":{"BaseURL":"https://nuhuo08.github.io","IsMultiLingual":false,"IsServer":false,"Language":{"Lang":"en","LanguageName":"","Title":"","Weight":0,"Disabled":false,"ContentDir":"","Cfg":{}},"LastChange":"2020-04-03T15:28:26+08:00","RSSLink":"https://nuhuo08.github.io/index.xml","Title":"XiaoWu"}}
